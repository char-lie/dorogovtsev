\chapter{Основы}
\section{Методы оценок параметров распределения}
\xsample --- независимые одинаково распределённые случайные величины
с неизвестной функцией распределения $F$.
Часто говорят, что \xsample --- выборка из распределения $F$
объёма $n$.
\index{функция распределения!неизвестная}

Цель --- найти $F$ или сказать что-то о её свойствах.

\subsection{Эмпирическая функция распределения}
\index{функция распределения!эмпирическая}
\index{функция распределения!выборочная}
\begin{definition}[Эмпирическая функция распределения]
  Эмпирической (выборочной) функцией распределения,
  построенной по выборке \xsample, называется функция
  $$\cdfn{x}=\frac{1}{n}\cdot \sum_{k=1}^n
  \indicator{x_k\le x}$$
\end{definition}

\begin{example}[Эмпирическая функция распределения]
  \label{ex:empiricalDistributionFunction}
  Возьмём выборку $0.5$, $0.2$, $0.1$, $0.2$.

  Для удобства выстроим числа в порядке их возрастания:
  $0.1$, $0.2$, $0.2$, $0.5$.

  Видим, что слева от $0.1$ эмпирическая функция распределения будет равна
  нулю.

  В точке $0.1$ произойдёт скачок на $\frac{1}{4}$, так как только один
  элемент выборки не превышает это значение.

  В точке $0.2$ будет скачок на $\frac{2}{4}$, а значение самой функции
  будет равно $\frac{3}{4}$, так как есть три элемента, не превышающих
  значение $0.2$ --- один равный $0.1$ и два равных $0.2$.

  Последний скачок произойдёт в точке $0.5$ и тут функция достигнет
  значения $1$, так как нет элемента выборки, превышающего
  $0.5$.

  Эмпирическая функция будет выглядеть так, как показано на
  рисунке \ref{fig:tikz:empiricalDistributionFunction}.
\end{example}

\begin{figure}
  \center\includestandalone[]{tikz/empiricalDistributionFunction}
  \caption{Эмпирическая функция распределения для примера
    \ref{ex:empiricalDistributionFunction}}
  \label{fig:tikz:empiricalDistributionFunction}
\end{figure}

Неизвестная функция распределения $\cdf{x}$ может быть сколь угодно
точно восстановлена по выборке достаточно большого объёма.
%\cite[стр.~25]{BorovkovMS}.

\begin{theorem}\label{theorem:distributionFunction:empiricalToCumulative}
  \index{теорема!о восстановлении!неизвестной функции распределения}
  \begin{equation*}
    \forall x \in \mathbb{R}: \qquad \cdfn{x} \acovergence \cdf{x}
  \end{equation*}
\end{theorem}
\begin{proof}[Идея доказательства]
Вспомним, чему равна эмпирическая функция распределения
\begin{equation*}
  \cdfn{x} = \frac{1}{n} \cdot \sum_{k=1}^n \indicator{x_k\le x}.
\end{equation*}

Заметим, что индикаторы $\indicator{x_k\le x}$
являются независимыми одинаково распределёнными случайными величинами,
а функцию распределения $\cdf{x}$ можно записать следующим образом
\begin{equation*}
  \cdf{x}
  = \Probability{x_1\le x}
  = \mean{\indicator{x_1\le x}}
\end{equation*}

%Так как эмпирическая функция распределения является
%средним арифметическим индикаторов, то по усиленному закону больших чисел
По усиленному закону больших чисел
\begin{equation*}
  \cdfn{x}
  = \frac{1}{n} \cdot \sum_{k=1}^n \indicator{x_k\le x}
    \acovergence \mean{\indicator{x_1}}
  = \cdf{x}
\end{equation*}

Теорема доказана.
\end{proof}

%Также можно доказать более сильную теорему \cite{IvchenkoMA}.
В приведённом утверждении речь шла о сходимости $F_n$ к $F$ в фиксированной
точке.
Однако можно проверить, что $F_n$ сходятсяя к $F$ слабо как функции
распределения.

\begin{theorem}
  \label{theorem:convergenceFProbability}
  \begin{equation*}
    \probability{F_n \Covergence{} F} = 1
  \end{equation*}
\end{theorem}

\subsection{Гистограмма}
\label{subsection:histogram}
\tikzstyle{int}=[draw, fill=blue!20, minimum size=2em]
\tikzstyle{init} = [pin edge={to-,thin,black}]

Как можно попытаться отследить плотность распределения?
Допустим, $F$ имеет хорошую (непрерывную) плотность.
Как тогда из $F$ получить $p$?
Мы знаем, что $F'=p$, но производная функции $F_n$ почти везде будет равна нулю
как производная ступенчатой функции.
С другой стороны
\begin{equation*}
  \cdf{b}-\cdf{a}=\int\limits_a^b \pdf{x} dx.
\end{equation*}
Положим $a=x$ и введём $\Delta_x=b-x$
$$\cdf{x+\Delta_x}-\cdf{x}=\int\limits_x^{x+\Delta_x} \pdf{y} dy$$
Делим обе части на $\Delta_x$
\begin{equation*}
  \frac{1}{\Delta_x}\cdot\int\limits_x^{x+\Delta_x} \pdf{y} dy
   = \frac{\cdf{x+\Delta_x}-\cdf{x}}{\Delta_x}
\end{equation*}
Несложно заметить, что при достаточно малых значениях $\Delta_x$
получаем плотность распределения $\pdf{x}$
\begin{equation*}
  \frac{\Delta\cdf{x}}{\Delta_x} \xrightarrow[]{\Delta_x\to 0}
    \frac{d\cdf{x}}{dx}
  =\pdf{x}
\end{equation*}
Значит, можем заменить $\pdf{x}$ не производной, а такой разностью
\begin{equation*}
  \pdf{x}\approx\frac{\cdf{x+\Delta_x}-\cdf{x}}{\Delta_x}
\end{equation*}
Это соображение легло в основу построения гистограммы.
Разобьём числовую прямую на $m+1$ полуинтервалов (два из них бесконечные)
точками $a_1 < \dots < a_m$.
\begin{comment}
Возьмём $m$ полуинтервалов на числовой прямой
$I_j=\left(a_{j-1},a_j\right], i=\overline{1,m}$
таких, каждое значение выборки попадает в свой интервал.
Для этого определим пару свойств точек, ограничивающих эти интервалы:
\begin{enumerate}
  \item Каждая следующая точка строго правее (больше) предыдущей
    (так как зачем нам одинаковые точки?)
    $$a_0<a_1<\dots<a_m$$
  \item Каждое значение выборки должно попадать ровно в один полуинтервал.
    Очевидно, что данные полуинтервалы $I_j$ не пересекаются между собой.
    Значит, осталось потребовать, чтобы
    крайнее левое значение было меньше минимального значения из выборки,
    а крайнее правое --- не меньше максимального
    $$a_0<min\left(X\right)\le max\left(X\right)\le a_m$$
\end{enumerate}

Введём функцию $q\left(y\right)$
$$q\left(y\right)
=\sum_{j=1}^m \frac{\cdf{a_j}-\cdf{a_{j-1}}}{a_j-a_{j-1}}
  \cdot\indicator{y\in I_j}$$
\end{comment}
Определим последовательность функций $q_n\left(y\right)$,
заменив $\cdf{x}$ на $\cdfn{x}$ в предыдущем определении
\begin{equation}\label{eq:histogram_start}
q_n\left(y\right)
=\sum_{j=1}^m \frac{\cdfn{a_j}-\cdfn{a_{j-1}}}{a_j-a_{j-1}}
  \cdot\indicator{y\in I_j}
\end{equation}
Отметим, что $q_n$ сходится к $q$ почти наверное, так как сходятся почти
наверное функции распределения согласно теореме
\ref{theorem:distributionFunction:empiricalToCumulative}
$$q_n\left(y\right)\acovergence q\left(y\right)$$
Функция $q$ в свою очередь сходится к $p$, так как приблизительно равна
производной, а при бесконечно большом количестве интервалов их длины
становятся бесконечно малыми
$$q\left(y\right)\covergencen{m}{}\pdf{y}$$
\begin{comment}
Функция $q_n$ называется гистограммой.
\index{гистограмма}
Избавимся от $a_j$ в формуле, а для этого вспомним, чему равно $\cdfn{x}$
$$\cdfn{x}=\frac{1}{n}\cdot \sum_{k=1}^n
\indicator{x_k\le x}$$

Теперь посмотрим, чему равна разность $\cdfn{a_j}-\cdfn{a_{j-1}}$,
которая, как мы видим, является вероятностью того,
что $x$ попало в отрезок $I_j$
\begin{align*}
  \cdfn{a_j}-\cdfn{a_{j-1}}=\\
  =\frac{1}{n}\cdot \sum_{k=1}^n
    \indicator{x_k\le a_j}-\frac{1}{n}\cdot \sum_{k=1}^n
    \indicator{x_k\le a_{j-1}}
\end{align*}

Сгруппируем слагаемые и получим чуть более компактную запись разности
\begin{eqnarray}\label{eq:cdfn_difference}
  \cdfn{a_j}-\cdfn{a_{j-1}}=\nonumber\\
  =\frac{1}{n}\cdot \sum_{k=1}^n
    \left[\indicator{x_k\le a_j}-\indicator{x_k\le a_{j-1}}\right]
\end{eqnarray}

Рассмотрим возможные значения индикаторов

Если оба индикатора равны единице,
это значит, что $x_k$ не больше $a_j$ и не больше $a_{j-1}$.
Поскольку $a_{j-1}\le a_j$, то можно обойтись тем, что $x\le a_{j-1}$
\begin{align*}
  \begin{cases}
    \indicator{x_k\le a_j}=1\\
    \indicator{x_k\le a_{j-1}}=1\\
    a_{j-1} < a_j
  \end{cases}
  \Rightarrow
  \begin{cases}
    x_k\le a_j\\
    x_k\le a_{j-1}\\
    a_{j-1} < a_j
  \end{cases}
  \\\Rightarrow
    x_k\le a_{j-1} < a_j
  \Rightarrow
    x_k\le a_{j-1}
\end{align*}

Такая ситуация,
что $x$ больше, чем $a_j$, но не больше, чем $a_{j-1}$, невозможна,
так как $a_{j-1}$ не больше, чем $a_j$,
а признать возможной такое положение дел ($a_j<x_k\le a_{j-1}$)
означало бы то, что $a_j<a_{j-1}$
\begin{align*}
  \begin{cases}
    \indicator{x_k\le a_j}=0\\
    \indicator{x_k\le a_{j-1}}=1\\
    a_{j-1} < a_j
  \end{cases}
  &\Rightarrow
  \begin{cases}
    x_k>a_j\\
    x_k\le a_{j-1}\\
    a_{j-1} < a_j
  \end{cases}
  \\&\Rightarrow
  \begin{cases}
    a_j<x_k\le a_{j-1}\\
    a_{j-1} < a_j
  \end{cases}
\end{align*}


Если оба индикатора равны нулю,
то это значит, что $x$ строго больше как $a_j$, так и $a_{j-1}$.
Опять же, поскольку $a_{j-1}\le a_j$, то достаточно сказать, что $x>a_j$.
\begin{align*}
  \begin{cases}
    \indicator{x_k\le a_j}=0\\
    \indicator{x_k\le a_{j-1}}=0\\
    a_j > a_{j-1}
  \end{cases}
  \Rightarrow
  \begin{cases}
    x_k>a_j\\
    x_k>a_{j-1}\\
    a_j > a_{j-1}
  \end{cases}
  \\\Rightarrow
    x_k>a_j > a_{j-1}
  \Rightarrow
    x_k>a_j
\end{align*}

Если же $x$ больше, чем $a_{j-1}$, но не больше, чем $a_j$,
то $x$ попадает в полуинтервал $\left(a_{j-1},a_j\right]$
\begin{align*}
  \begin{cases}
    \indicator{x_k\le a_j}=1\\
    \indicator{x_k\le a_{j-1}}=0\\
    a_j > a_{j-1}
  \end{cases}
  \Rightarrow
  \begin{cases}
    x_k\le a_j\\
    x_k>a_{j-1}\\
    a_j > a_{j-1}
  \end{cases}
  \\\Rightarrow
    a_{j-1}<x_k\le a_j
\end{align*}

Вспомним формулу \eqref{eq:cdfn_difference}
\begin{align*}
  \cdfn{a_j}&-\cdfn{a_{j-1}}=\\
  &=\frac{1}{n}\cdot \sum_{k=1}^n
  \left[\indicator{x_k\le a_j}-\indicator{x_k\le a_{j-1}}\right]
\end{align*}

Очевидно, что нас интересуют те пары, разность которых не равна нулю.
Это значит, что те случаи, когда $x>a_j$ или $x\le a_{j-1}$, нас не интересуют.
Поскольку такой случай, что $a_j<x\le a_{j-1}$ невозможен, то его тоже отбросим.
Значит, остался только тот вариант,
когда $x$ попадает в полуинтервал $\left(a_{j-1},a_j\right]$
$$\frac{1}{n}\cdot \sum_{k=1}^n
    \left[\indicator{x_k\le a_j}-\indicator{x_k\le a_{j-1}}\right]
  =\frac{1}{n}\cdot \sum_{k=1}^n \indicator{x_k\in \left(a_{j-1},a_j\right]}
$$

Видим знакомые полуинтервалы $\left(a_{j-1},a_j\right]=I_j$. Воспользуемся этим
$$\frac{1}{n}\cdot \sum_{k=1}^n \indicator{x_k\in \left(a_{j-1},a_j\right]}
=\frac{1}{n}\cdot \sum_{k=1}^n \indicator{x_k\in I_j}$$

Получаем компактную запись для разности функций распределения
\begin{equation}\label{eq:cdfn_difference_final}
\cdfn{a_j}-\cdfn{a_{j-1}}
=\frac{1}{n}\cdot \sum_{k=1}^n \indicator{x_k\in I_j}
\end{equation}


Вернёмся к уравнению \eqref{eq:histogram_start}
$$
q_n\left(y\right)
=\sum_{j=1}^m \frac{\cdfn{a_j}-\cdfn{a_{j-1}}}{a_j-a_{j-1}}
  \cdot\indicator{y\in I_j}
  $$

Воспользовавшись тем,
что $\left(a_j-a_{j-1}\right)$ --- длина полуинтервала $I_j$,
а разность $\cdfn{a_j}-\cdfn{a_{j-1}}$ была только что переписана
через индикаторы, получаем такую формулу
\begin{equation}\label{eq:histogramPreFinal}
  q_n\left(y\right)
    =\sum_{j=1}^m\frac{1}{n}\sum_{k=1}^n
      \indicator{x_k\in I_j}\cdot\frac{1}{\left|I_j\right|}
      \cdot \indicator{y \in I_j}
\end{equation}
\end{comment}
\begin{definition}[Гистограмма]\index{гистограмма}
  Гистограммой выборки \xsample называется функция
  \begin{equation*}
    q_n\left(y\right)
    =\sum_{j=1}^m \frac{\nu_j}{n\cdot\left|I_j\right|}
      \cdot \indicator{y\in I_j}
  \end{equation*}
\end{definition}

$\nu_j$ --- количество элементов выборки, попавших в полуинтервал $I_j$
\begin{equation*}
  \nu_j = \sum_{k=1}^{n} \indicator{x_k \in I_j}.
\end{equation*}

Значит, гистограмма также может быть записана в следующем виде
$$q_n\left( y \right)
  = \frac{1}{n} \cdot \sum_{j=1}^{m} \left\{
    \frac{\indicator{y \in I_j}}{\left| I_j \right|}
    \cdot \sum_{k=1}^{n} \indicator{x_k\in I_j} \right\}$$
\begin{comment}
Упростим формулу \eqref{eq:histogramPreFinal}, введя функцию
$\nu_j\left(X\right)$ \cite[стр.~68]{BorovkovMS},
которая считает количество элементов выборки $X=x_1, \dots, x_n$,
попавших в интервал $I_j$.
Это будет сумма индикаторов того, что элемент $x_k$ попал в $I_j$

$$\nu_j\left(X\right)
=\sum_{x\in X} \indicator{x\in I_j}
=\sum_{k=1}^n \indicator{x_k\in I_j}$$

Поскольку $\indicator{y\in I_j}$ зависит от $j$ и не зависит от $k$,
то его можно перенести во внешнюю сумму. Получаем следующую формулу
$$q_n\left(y\right)
=\sum_{j=1}^m \frac{\nu_j\left(X\right)}{n\cdot\left|I_j\right|}
  \cdot \indicator{y\in I_j}$$

У этой суммы только один ненулевой элемент,
так как $y$ может попасть только в один полуинтервал.
Тогда обозначим номер отрезка, в который попал $y$, через $k$ ($y\in I_k$),
а функцию $q_n\left(y\right)$ запишем как $q_n^k$
\begin{equation}\label{eq:histogram_borovkov}
  q_n^k = \frac{\nu_k\left(X\right)}{n\cdot\left|I_k\right|}
\end{equation}


Что мы тут видим?

Теперь $k$ --- номер столбика гистограммы. В математическом смысле это
номер интересующего нас полуинтервала --- того, в который попал $y$.

Высота столбика --- значение функции на определённом полуинтервале ---
пропорциональна количеству элементов, попавших в этот отрезок, что логично.

Делителю $\left|I_k\right|$ отведена особая роль --- он предотвращает
искажение гистограммы, когда длины отрезков разные; когда они одинаковые,
можно вынести длину как нормирующий множитель. То есть, чем длиннее отрезок,
тем ниже столбик, так как элементы более размазаны по отрезку, что тоже логично.

Представим, что значение функции --- это высота прямоугольника,
а длина отрезка --- его ширина (графически это изображается именно так).
Тогда отношение количества элементов, попавших в полуинтервал,
к количеству всех элементов выборки (вероятность того, что случайно взятый
элемент из выборки попадёт в $k$-ый отрезок \cite[стр.~24]{BorovkovMS}),
является площадью прямоугольника. Воспользовавшись формулой
\eqref{eq:histogram_borovkov}, получаем равенство
$$S_k
  = q_n^k \cdot \left| I_k \right|
  = \frac{\nu_k\left(X\right)}{n}=\probabilityn{x\in I_k}$$

Если устремить количество полуинтервалов к бесконечности ($m\to\infty$),
то каждый полуинтервал будет сжиматься в точку.
При этом вероятность попадания $x$ в отрезок будет стремиться
к вероятности попадания $x$ в точку $y$.
Введём обозначения $|I_j|=\delta$, $I_j=\Delta_y$
$$\probabilityn{x=y}
\approx\probabilityn{x\in\Delta_y}=q_n\left(y\right)\cdot\delta,
\qquad m\to\infty$$

Очень напоминает ситуацию с плотностью распределения
непрерывной случайной величины $\xi$
$$\probability{\xi=x}\approx\pdf{x}\cdot\delta,\qquad\delta\to 0$$

Нужно отметить, что количество элементов выборки
должно стремиться к бесконечности ($n\to\infty$),
так как плотность может быть лишь у непрерывных случайных величин.
Чем больше будет элементов,
тем плотнее они будут стоять на числовой прямой.
\end{comment}
\subsection{Оценка неизвестных параметров}
Пусть \xsample --- выборка из распределения $F_\theta$,
\index{неизвестный параметр}
где $\theta$ --- неизвестный параметр из множества $\Theta$.

\begin{example}
  Имеем нормальное распределение с известной дисперсией $\sigma^2 = 1$
  и неизвестным математическим ожиданием $a$ --- $N\left(a,1\right)$.
  Тогда $\theta$ --- математическое ожидание $a$, а множество неизвестных
  параметров будет множеством действительных чисел $\Theta = \mathbb{R}$.
\end{example}
\begin{example}
  Есть нормальное распределение, в котором неизвестны оба параметра.
  Тогда $\theta$ будет парой $\left( a,\sigma^2 \right)$,
  а $\Theta$ будет декартовым произведением $\mathbb{R} \times \mathbb{R_+}$.
\end{example}

Цель данного пункта --- предложить процедуры построения функций от выборки,
значения которых будут заменять неизвестные параметры.

\index{статистика}
\begin{definition}[Статистика]
  \label{def:statistic}
  Статистикой называют функцию $S$ от выборки
  $X=\left(x_1,x_2,\dots,x_n\right)$
  \begin{align*}
    S\left(X\right) = S\left(x_1, x_2, \dots, x_n\right)
  \end{align*}
\end{definition}
\index{оценка}
\begin{definition}[Оценка]Статистику,
  значение которой заменяет неизвестный параметр,
  называют оценкой этого параметра
\end{definition}
\begin{example}\label{example:bernulliEstimator}
  Возьмём выборку из распределения Бернулли,
  то есть $\left\{x_i\right\}$ --- набор одинаково распределённых
  независимых случайных величин, причём
  \begin{align*}
  x_i=
  \begin{cases}
    1,&p\\
    0,&1-p
  \end{cases}
  \end{align*}
  Неизвестным параметром будет величина $p$
  \begin{equation*}
    \theta = p \in \left[ 0; 1 \right] = \Theta
  \end{equation*}
  Рассмотрим разные оценки $\hat{p}$
  \begin{align*}
    \hat{p}_1&=\frac{1}{n}\sum_{k=1}^n x_k\\
    \hat{p}_2&=x_1\\
    \hat{p}_3&=
      \frac{2}{n}\sum_{k=1}^{\left\lfloor \frac{n}{2} \right\rfloor} x_k
  \end{align*}
\end{example}

\begin{remark}
Поскольку $\hat{p}$ --- случайная величина, то может оказаться,
что она не равна настоящему параметру $p$
$$\Probability{\hat{p}=p}=0$$
\end{remark}

\begin{definition}[Состоятельная оценка]
  \index{оценка!состоятельная}
  Оценка $\hat{\theta}$ называется состоятельной,
  если стремится к истинному значению $\theta$ по вероятности
  $$\hat{\theta}\pcovergence\theta$$
\end{definition}

\begin{definition}[Сильно состоятельная оценка]
  \index{оценка!сильно состоятельная}
  Оценка $\hat{\theta}$ называется сильно состоятельной,
  если она стремится к истинному значению $\theta$ почти наверное
  $$\hat{\theta}\acovergence\theta$$
\end{definition}

\begin{example}
  Оценка $\hat{p}_1$ из примера \ref{example:bernulliEstimator}
  является сильно состоятельной.
\end{example}

\begin{definition}[Несмещённая оценка]
  \label{def:estimatorBias}
  \index{оценка!несмещённая}
  Оценка $\hat{\theta}$ несмещённая, если
  \begin{equation*}
    \forall\theta\in\Theta: \qquad \meanof{\theta}{\hat{\theta}} = \theta
  \end{equation*}
\end{definition}

\begin{remark}
  Несмещённая оценка существует не всегда
\end{remark}

\begin{example}
  Пусть \xsample --- выборка из распределени Бернулли
  \begin{equation*}
    x_k =
    \begin{cases}
      1,& p \\
      0,& 1-p
    \end{cases}
  \end{equation*}
  Обозначим сумму элементов выборки $S_n$
  \begin{equation*}
    S_n = x_1 + \dots + x_n
  \end{equation*}
  Тогда $S_n$ --- количество единиц, а $n-S_n$ --- количество нулей,
  встретившихся в выборке.
  Не существует несмещённой оценки для $e^p$.
  Для проверки предположим противное.
  Пусть $\hat{\theta}$ --- несмещённая оценка для $e^p$
  \begin{equation*}
    \hat{\theta} = f\left( x_1, \dots, x_n \right)
  \end{equation*}
  Тогда справедливо следующее равенство
  \begin{equation*}
    \forall p \in \left[ 0; 1 \right]:\qquad
    \meanof{p}{f\left( x_1, \dots, x_n \right)}
    = e^p
  \end{equation*}
  Или
  \begin{equation*}
    \sum_{x_i \in \left\{ 0, 1 \right\}} f\left( x_1, \dots, x_n \right)
      \cdot p^{S_n} \cdot \left( 1 - p \right)^{n - S_n}
    = e^p
  \end{equation*}
  Слева стоит полином степени не выше $n$, который не может совпадать на
  интервале $\left( 0; 1 \right)$ с показательной функцией.
  То есть, не существует несмещённой оценки для $e^p$.
\end{example}

\begin{definition}[Оптимальная оценка]
  Несмещённая оценка $\hat{\theta}\in K$ называется оптимальной
  \begin{comment}
  \footnote{В учебнике Боровкова А. А.
  ``Математическая статистика'' оценка, удовлетворяющая этим условиям,
  носит название \textbf{эффективная оценка} \cite[стр.~130]{BorovkovMS},
  но у нас этот термин будет использоваться далее в другом смысле}
  \end{comment}
  в классе квадратично интегрируемых оценок $K$,
  если для всякой другой несмещённой оценки $\tilde{\theta}\in K$
  \begin{equation*}
    \forall\theta\in\Theta:\qquad
    \dispersionof{\theta}{\hat{\theta}} \le \dispersionof{\theta}{\tilde{\theta}}
  \end{equation*}
  или же
  \begin{equation*}
    \forall\theta\in\Theta:\qquad
    \meanof{\theta}{\left(\hat{\theta} - \theta\right)^2}
    \le \meanof{\theta}{\left( \tilde{\theta} - \theta \right)^2}.
  \end{equation*}
\end{definition}

\subsection{Выборочные оценки. Метод моментов}
\index{метод!моментов}
Как правило, неизвестный параметр может быть выражен через моменты
распределения. Например:

\begin{enumerate}
  \item Нормальное распределение $N\left(a,\sigma^2\right)$.
    В нём параметр $a$ является средним,
    а параметр $\sigma^2$ --- дисперсией
  \item Пуассоновское распределение $Poi\left(\lambda\right)$.
    Тут параметр $\lambda$ является и средним, и дисперсией
  \item Экспоненциальное распределение $Exp\left(\lambda\right)$.
    $\frac{1}{\lambda}$ --- среднее,
    $\frac{1}{\lambda^2}$ --- дисперсия
\end{enumerate}

Заменяя моменты распределения выборочными, можно получать оценки
соответствующих параметров.
В общем случае рецепт построения оценки параметра $\theta$ выглядит так.
Пусть $\varphi$ --- непрерыввная функция на $\mathbb{R}$, рассмотрим интеграл
\begin{equation*}
  \integrall{\mathbb{R}}{d\cdfof{\theta}{x}}{\varphi\left( x \right)}
  = g\left( \theta \right)
\end{equation*}
как функцию $\theta$.

Заменяя $F_{\theta}$ эмпирической функцией распределения, получим уравнение
на оценку $\hat{\theta}$
\begin{equation}\label{eq:unknown_parameter}
  g\left(\hat{\theta}\right)
    =\int\limits_{\mathbb{R}}\varphi\left(x\right)d\cdfn{x},
\end{equation}

\begin{example}
  Если $\theta$ --- среднее, то $\varphi\left(x\right)=x$
  \begin{equation*}
    \integral{-\infty}{+\infty}{\cdfof{\theta}{x}}{x}
    = \theta
    = g\left(\theta\right)
  \end{equation*}
  и после замены $F_\theta$ на $F_n$ получим $\hat{\theta} = \overline{x}$.
\end{example}
\begin{theorem}[Оценка метода моментов]
  \index{теорема!оценка метода моментов}
  \index{метод!моментов!оценка}
  %\cite[с.~87]{BorovkovMS}
  Пусть $\varphi$ такова, что $g$ --- монотонная и непрерыввная функция.
  Тогда оценка
  \begin{equation*}
    \hat{\theta}
    = g^{-1}\left( \integrall{\mathbb{R}}{d\cdfn{x}}{
      \varphi\left( x \right)} \right)
  \end{equation*}
  существует и является сильно состоятельной.
\end{theorem}
\begin{proof}
  Поскольку функция $g$ непрерывна и монотонна,
  то она имеет обратную $g^{-1}$.
  Применим обратную функцию к обеим частям уравнения
  \eqref{eq:unknown_parameter}
  \begin{equation*}
    \hat{\theta}
    = g^{-1}\left( \integrall{\mathbb{R}}{d\cdfn{x}}{\varphi\left( x \right)}
        \right)
  \end{equation*}

  Воспользуемся теоремой \ref{theorem:convergenceFProbability} о слабой
  сходимости эмпирической функции распределения к настоящей с вероятностью $1$
  \begin{equation*}
    \integrall{\mathbb{R}}{d\cdfn{x}}{\varphi\left( x \right)}
    \acovergence \integrall{\mathbb{R}}{d\cdfof{\theta}{x}}{
        \varphi\left( x \right)}
  \end{equation*}

  Функция $g^{-1}$ непрерывна, следовательно,
  \begin{equation*}
  \hat{\theta}
  = g^{-1}\left( \integrall{\mathbb{R}}{
    d\cdfn{x}}{\varphi\left( x \right)} \right)
  \acovergence
    g^{-1}\left( \integrall{\mathbb{R}}{
      d\cdfof{\theta}{x}}{\varphi\left( x \right)} \right)
  = \theta
  \end{equation*}

  Теорема доказана.
\end{proof}

Примерами интегралов по эмпирической функции распределения, часто встречающимся
на практике, являются выборочные моменты.

\begin{definition}[Выборочное среднее]
  \index{выборочное среднее}
  Выборочное средние обозначается через $\overline{x}$
  и считается по следующей формуле
  \begin{equation*}
    \overline{x}
    = \integrall{\mathbb{R}}{d\cdfn{x}}{x}
    = \frac{1}{n} \cdot \sum_{k=1}^{n} x_k
  \end{equation*}
\end{definition}

\begin{definition}[Выборочная дисперсия]
  \index{выборочная дисперсия}
  Выборочная дисперсия $\overline{\sigma^2}$
  считается по формуле
  \begin{equation*}
    \overline{\sigma^2}
    = \frac{1}{n-1} \cdot \sum_{k=1}^n \left( x_k-\overline{x} \right)^2
  \end{equation*}
\end{definition}

\begin{remark}
  Очень полезным является равенство
  \begin{equation*}
    \sum_{k=1}^{n} \left( x_k - \overline{x} \right)^2
    = \sum_{k=1}^{n} \left( x_k^2 - \overline{x}^2 \right)
  \end{equation*}
\end{remark}
\begin{proof}[Вывод равенства]
  Сначала нужно раскрыть квадрат суммы и выделить выборочное среднее
  \begin{equation*}
    \sum_{k=1}^{n} \left( x_k - \overline{x} \right)^2
    = \sum_{k=1}^{n} x_k^2 - 2 \cdot \sum_{k=1}^{n} x_k \cdot \overline{x}
      + \sum_{k=1}^{n} \overline{x}^2
    = \sum_{k=1}^{n} x_k^2 - 2 \cdot n \cdot \overline{x}^2
      + \sum_{k=1}^{n} \overline{x}^2
  \end{equation*}
  Затем сгруппировать всё под одной суммой
  \begin{equation*}
    \sum_{k=1}^{n} x_k^2 - 2 \cdot n \cdot \overline{x}^2
      + n \cdot \overline{x}^2
    = \sum_{k=1}^{n} \left( x_k^2 - \overline{x}^2 \right)
  \end{equation*}
\end{proof}

\begin{remark}
  Оценка метода моментов является сильно состоятельной, но ничего не говорится
  о её несмещённости.
\end{remark}

Если воспользоваться лишь методом моментов, то оценка дисперсии будет выглядеть
так
\begin{equation*}
  \widehat{\sigma^2}
  = \integrall{\mathbb{R}}{dF_n\left( x \right)}{x^2}
    - \left( \integrall{\mathbb{R}}{dF_n\left( x \right)}{x} \right)^2
  = \frac{1}{n} \cdot \sum_{k=1}^n \left( x_k-\overline{x} \right)^2
\end{equation*}
Посчитаем математическое ожидание этой оценки
\begin{equation*}
  \mean{\widehat{\sigma^2}}
  = \frac{1}{n} \cdot \mean{\sum_{k=1}^n \left( x_k-\overline{x} \right)^2}
  = \frac{1}{n} \cdot \sum_{k=1}^{n} \mean{x_k^2}
    - \frac{1}{n} \cdot \sum_{k=1}^{n} \mean{\overline{x}^2}
  = \mean{x_1^2} - \mean{\overline{x}^2}
\end{equation*}
Введём дисперсию выборочного среднего, чтобы легче считалось
\begin{equation*}
  \mean{x_1^2} - \mean{\overline{x}^2}
  = \mean{x_1^2} - \dispersion{\overline{x}}
    - \left( \mean{\overline{x}} \right)^2
  = \mean{x_1^2} - \dispersion{\overline{x}} - \left( \mean{x_1} \right)^2
\end{equation*}
Дальше выделяем дисперсию $x_1$ и смотрим, что получается
\begin{equation*}
  \mean{x_1^2} - \dispersion{\overline{x}} - \left( \mean{x_1} \right)^2
  = \dispersion{x_1} - \frac{1}{n^2} \cdot \dispersion{\sum_{k=1}^{n} x_k}
  = \frac{n-1}{n} \cdot \dispersion{x_1}
\end{equation*}

То есть, чтобы оценка была несмещённой, нужно умножить её на $\frac{n}{n-1}$,
--- тогда математическое ожидание оценки дисперсии будет равно самой дисперсии.
Именно так и поступим
\begin{equation*}
  \overline{\sigma^2}
  = \frac{n}{n-1} \cdot \widehat{\sigma_2}
  = \frac{n}{n-1} \cdot \frac{1}{n}
    \cdot \sum_{k=1}^n \left( x_k-\overline{x} \right)^2
  = \frac{1}{n-1} \cdot \sum_{k=1}^n \left( x_k-\overline{x} \right)^2
\end{equation*}

Оценка дисперсии, полученная методом моментов, называется смещённой выборочной
дисперсией, а оптимизированная оценка $\overline{\sigma^2}$ называется
несмещённой выборочной дисперсией.

\section{Свойства оценок}
\subsection{Неравенство Рао-Крамера}
\begin{theorem}[Колмогорова (теорема единственности)]
  \index{теорема!Колмогорова}
  \index{теорема!единственности}
  \label{theorem:Kolmogorov}
  Оптимальная оценка единственная или её нет вообще
\end{theorem}
\begin{proof}
  Допустим,
  есть две разные оптимальные и несмещённые оценки $\theta_1$ и $\theta_2$.
  Тогда по определению для любой несмещённой оценки $\hat{\theta}$ будет
  \begin{align*}
    \forall\theta\in\Theta:\qquad
    \begin{cases}
      \dispersionof{\theta}{\theta_1}
        \le\dispersionof{\theta}{\hat{\theta}}\\
      \dispersionof{\theta}{\theta_2}
        \le\dispersionof{\theta}{\hat{\theta}}
    \end{cases}
  \end{align*}

  Поскольку неравенство выполняется
  для каждой несмещённой оценки $\hat{\theta}$,
  а оценки $\theta_1$ и $\theta_2$ являются несмещёнными,
  то можем их и поставить в неравенство в роли $\hat{\theta}$

  \begin{align*}
    \forall\theta\in\Theta:\qquad
    \begin{cases}
      \dispersionof{\theta}{\theta_1}
        \le\dispersionof{\theta}{\theta_2}\\
      \dispersionof{\theta}{\theta_2}
        \le\dispersionof{\theta}{\theta_1}
    \end{cases}
  \end{align*}
  А это возможно только если дисперсии этих оценок равны.
  Обозначим эту дисперсию через $\sigma^2\left(\theta\right)$

  $$\dispersionof{\theta}{\theta_1}
    =\dispersionof{\theta}{\theta_2}
    =\sigma^2\left(\theta\right)$$
  Возьмём несмещённую оценку $\tilde{\theta}$,
  равную среднеарифметическому оценок $\theta_1$ и $\theta_2$
  $$\tilde{\theta}=\frac{1}{2}\cdot\theta_1+\frac{1}{2}\cdot\theta_2$$
  Тогда по определению $\theta_1$ и $\theta_2$ получаем,
  что дисперсия новой оценки не меньше, чем у оптимальных
  \begin{equation}\label{eq:estimator_ge}
    \dispersionof{\theta}{\tilde{\theta}}\ge\sigma^2\left(\theta\right)
  \end{equation}
  Посчитаем дисперсию оценки $\tilde{\theta}$
  \begin{align*}
  \dispersionof{\theta}{\tilde{\theta}}
    &=\meanof{\theta}{\left( \tilde{\theta}-\theta \right)^2}
    =\meanof{\theta}{\left[ \frac{1}{2}\cdot\left( \theta_1-\theta \right)
      +\frac{1}{2}\cdot\left( \theta_2-\theta \right) \right]^2}=\\
    &=\frac{1}{4}\cdot\dispersionof{\theta}{\theta_1}
      +\frac{1}{4}\cdot\dispersionof{\theta}{\theta_2}
      +\frac{1}{2}\cdot\meanof{\theta}
        {\left[ \left( \theta_1-\theta \right)
          \cdot\left( \theta_2-\theta \right) \right]}
  \end{align*}
  Воспользуемся неравенством Коши%(частный случай неравенства Гёльдера)
  \begin{eqnarray}\label{eq:koshi_eq}
    \meanof{\theta}{\left[ \left( \theta_1-\theta \right)
      \cdot\left( \theta_2-\theta \right) \right]}
    \le\sqrt{\meanof{\theta}{\left( \theta_1-\theta \right)^2}
      \cdot\meanof{\theta}{\left( \theta_2-\theta \right)^2}}=\\
    =\sqrt{\dispersionof{\theta}{\theta_1}
      \cdot\dispersionof{\theta}{\theta_2}}
    =\sqrt{\sigma_1^2\cdot\sigma_2^2}\nonumber
  \end{eqnarray}
  Вернёмся к вычислению дисперсии оценки $\tilde{\theta}$
  \begin{align*}
    \frac{1}{4}\cdot\dispersionof{\theta}{\theta_1}
      +\frac{1}{4}\cdot\dispersionof{\theta}{\theta_2}
      +\frac{1}{2}\cdot\meanof{\theta}
        {\left[ \left( \theta_1-\theta \right)
          \cdot\left( \theta_2-\theta \right) \right]}\le\\
    \le\frac{1}{2}\cdot\sigma^2\left( \theta \right)
      +\frac{1}{2}\cdot\sqrt{\sigma^2\left( \theta \right)
        \cdot\sigma^2\left( \theta \right)}
    =\sigma^2\left( \theta \right)
  \end{align*}
  То есть, дисперсия оценки $\tilde{\theta}$ не больше дисперсии
  введённой оптимальной оценки
  \begin{equation}\label{eq:estimator_le}
    \dispersionof{\theta}{\tilde{\theta}}\le\sigma^2\left(\theta\right)
  \end{equation}
  Воспользовавшись неравенствами
  \eqref{eq:estimator_ge} и \eqref{eq:estimator_le}, получаем равенство
  $$\dispersionof{\theta}{\tilde{\theta}}=\sigma^2\left(\theta\right)$$
  Это значит, что в неравенстве \eqref{eq:koshi_eq}
  в данном случае тоже выходит равенство
  $$\meanof{\theta}{\left[ \left( \theta_1-\theta \right)
      \cdot\left( \theta_2-\theta \right) \right]}
    =\sqrt{\meanof{\theta}{\left( \theta_1-\theta \right)^2}}
      \cdot\sqrt{\meanof{\theta}{\left( \theta_2-\theta \right)^2}}$$

  Для дальнейших размышлений вспомним аналогию с векторами,
  а именно смысл равенства в неравенстве Коши
  для скалярного произведения векторов
  $$\vec{a}\cdot\vec{b}
    =\left|\vec{a}\right|\cdot\left|\vec{b}\right|
      \cdot\cos{\left(\widehat{\vec{a},\vec{b}}\right)}
    =\sqrt{\vec{a}^2}\cdot\sqrt{\vec{b}^2}
      \cdot\cos{\left(\widehat{\vec{a},\vec{b}}\right)}$$
  Скалярное произведение двух векторов равно произведению их модулей
  только тогда, когда они сонаправлены
  $$\left(\widehat{\vec{a},\vec{b}}\right)=0
    \Rightarrow \vec{a}\cdot\vec{b}
    =\sqrt{\vec{a}^2}\cdot\sqrt{\vec{b}^2}$$
  Положим математическое ожидание нормой,
  а $\theta_1-\theta$ и $\theta_2-\theta$ векторами
  пространства случайных величин.
  Получаем, что нормы и направления этих векторов совпадают
  \begin{align*}
    &\meanof{\theta}{\left[ \left( \theta_1-\theta \right)
      \cdot\left( \theta_2-\theta \right) \right]}
    =\sqrt{\meanof{\theta}{\left( \theta_1-\theta \right)^2}}
      \cdot\sqrt{\meanof{\theta}{\left( \theta_2-\theta \right)^2}}\\
    &\Rightarrow\left(\widehat{\theta_1-\theta,\theta_2-\theta}\right)\\
    \end{align*}
  Это значит, что они равны,
  что противоречит предположению о том, что они разные
  \begin{align*}
    \begin{cases}
      \left(\widehat{\theta_1-\theta,\theta_2-\theta}\right)=0\\
      \meanof{\theta}{\left( \theta_1-\theta \right)^2}
        =\meanof{\theta}{\left( \theta_2-\theta \right)^2}
    \end{cases}
    \Rightarrow \theta_1-\theta=\theta_2-\theta\\
    \Rightarrow\theta_1=\theta_2
  \end{align*}
  Теорема доказана
\end{proof}

\begin{remark}\label{remark:doubleDiff}
  Для дальнейших действий будем считать, что функция распределения
  $\cdfof{\theta}{x}$ имеет плотность $\pdf{x,\theta}$,
  которая дважды дифференцируема по $\theta$ и её можно дифференцировать под
  знаком интеграла.\footnote{Подробнее с дифференцированием под знаком
  интеграла Римана можно почитать во втором томе курса дифференциального и
  интегрального исчисления Фихтенгольца
  \cite[с.~712]{Fichtenholz2}.

  Для тех, кто интересуется интегралом Лебега, прямой путь в книгу
  Дороговцева по общей теории меры и интеграла \cite[с.~102]{DorogovtsevIT}}

  \begin{equation*}
    \frac{\partial}{\partial \theta}\integrall{\Delta}{dx}{\pdf{x, \theta}}
    = \integrall{\Delta}{dx}{\frac{\partial}{\partial \theta}\pdf{x, \theta}}
  \end{equation*}
\end{remark}

Отметим, что выборка $\left( x_1, \dots, x_n \right)$ имеет плотность
распределения, так как является случайным вектором в $\mathbb{R}^n$,
все координаты которого --- независимые одинаково распределённые случайные
величины, иммеющие плотность.

\begin{definition}[Функция правдоподобия]
  \label{def:likehoodFunction}
  \index{функция!правдоподобия}
  Плотность распределения выборки называется функцией правдоподобия
  \begin{equation*}
    L\left( \vec{x}, \theta \right) = \prod_{k=1}^n \pdf{x_k, \theta}
  \end{equation*}
\end{definition}

Прологарифмировав функцию правдоподобия, получим сумму
\begin{equation*}
  \ln{L\left( \vec{x}, \theta \right)}
  = \sum_{k=1}^n \ln{\pdf{x_k, \theta}}
\end{equation*}
Это сумма независимых одинаково распределённых случайных величин.
Воспользовавшись законом больших чисел, можем сказать,
что
\begin{equation*}
  \ln{L\left( \vec{x}, \theta \right)}
  = n\cdot\frac{\ln{\pdf{x_1, \theta}} + \dots + \ln{\pdf{x_n, \theta}}}{n}
  \approx n\cdot\meanof{\theta}{\ln{\pdf{x_1, \theta}}}
\end{equation*}
при больших $n$.


\begin{definition}[Вклад выборки]\label{def:defU}
  \index{вклад выборки}
  Вклад выборки --- частная производная по параметру $\theta$
  от логарифма функции правдоподобия
  $$U\left( \vec{x},\theta \right)
      =\frac{\partial}{\partial\theta}\ln{L\left(\vec{x},\theta\right)}$$
\end{definition}

\begin{remark}\label{remark:defU}
  Рекомендуется запомнить ещё две записи вклада выборки, так как они нам
  дальше пригодятся.

  Первая:
  \begin{align*}
    U\left( \vec{x},\theta \right)
    = \sum_{k=1}^n\frac{\partial}{\partial\theta}\ln{\pdf{x_k,\theta}}
  \end{align*}

  Вторая:
  $$U\left( \vec{x},\theta \right)
    =\frac{\frac{\partial}{\partial\theta}L\left(\vec{x},\theta\right)}
      {L\left(\vec{x},\theta\right)}$$
\end{remark}
\textit{Откуда это взялось}
Первая формула следует непосредственно из определения функции правдоподобия
$$U\left( \vec{x},\theta \right)
    =\frac{\partial}{\partial\theta}\ln{L\left(\vec{x},\theta\right)}
    =\sum_{k=1}^n
      \frac{\partial}{\partial\theta}\cdot\ln{\pdf{x_k,\theta}}$$

Чтобы получить вторую запись, нужно взять производную.
Вспоминаем, как правильно дифференцировать сложные функции
\cite[с.~226]{Fichtenholz1}, \cite[с.~133]{DorogovtsevMA}
$$\frac{\partial}{\partial x} \ln{f\left( x \right)}
  = \frac{1}{f\left( x \right)}
    \cdot \frac{\partial}{\partial x} f\left( x \right)$$
И считаем
$$U\left( \vec{x},\theta \right)
  =\frac{\partial}{\partial\theta}\ln{L\left(\vec{x},\theta\right)}
  =\frac{\frac{\partial}{\partial\theta}L\left(\vec{x},\theta\right)}
    {L\left(\vec{x},\theta\right)}$$

\begin{lemma}\label{remark:expectationU}
  Математическое ожидание вклада выборки равно нулю
  \begin{equation*}
    \meanof{\theta}{U\left( \vec{x}, \theta \right)} = 0
  \end{equation*}
\end{lemma}
\begin{proof}
Посчитаем математическое ожидание вклада выборки

\begin{align*}
  \meanof{\theta}{U\left( \vec{x}, \theta \right)}
    = \integral{\mathbb{R}^n}{}{\vec{u}}
      {U\left( \vec{u}, \theta \right)
        \cdot L\left( \vec{u}, \theta \right)}
    = \integral{\mathbb{R}^n}{}{\vec{u}}
      {\frac{\frac{\partial}{\partial\theta}L\left(\vec{x}, \theta\right)}
        {L\left(\vec{x}, \theta\right)}
        \cdot L\left( \vec{u}, \theta \right)} = \\
    = \integral{\mathbb{R}^n}{}{\vec{u}}{\frac{\partial}{\partial\theta}
      L\left( \vec{u}, \theta \right)}
\end{align*}
Воспользовавшись предположением о том,
что функция распределения дважды дифференцируема,
вынесем производную за знак интеграла
\begin{align*}
  \meanof{\theta}{U\left( \vec{x},\theta \right)}
    &=\frac{\partial}{\partial\theta}
      \integral{\mathbb{R}^n}{}{\vec{u}}{L\left( \vec{u},\theta \right)}
\end{align*}
Так как $L$ --- плотность распределения, то
\begin{equation*}
  \integral{\mathbb{R}^n}{}{\vec{u}}{L\left( \vec{u}, \theta \right)} = 1
\end{equation*}
и соответственно
\begin{equation*}
  \meanof{\theta}{U\left( \vec{x}, \theta \right)} = 0
\end{equation*}
\end{proof}

\begin{comment}
\begin{remark}\label{remark:partialLikelihoodNull}
  Частная производная по параметру $\theta$ от функции правдоподобия
  $L\left( \vec{u},\theta \right)$ равна нулю.
\end{remark}
\begin{proof}
  Выше у нас было равенство
  $$\frac{\partial}{\partial\theta}
    \integral{\mathbb{R}^n}{}{\vec{u}}{L\left( \vec{u},\theta \right)}=0$$

  Так как производную можем заносить под знак интеграла
  (согласно замечанию \ref{remark:doubleDiff}), то получаем такое равенство
  $$\integral{\mathbb{R}^n}{}{\vec{u}}{
    \frac{\partial}{\partial\theta}L\left( \vec{u},\theta \right)}=0$$

  Поскольку интеграл не зависит от $\theta$,
  то такое возможно лишь в том случае, когда производная равна нулю
  $$\frac{\partial}{\partial\theta}L\left( \vec{u},\theta \right)=0$$
\end{proof}
\end{comment}

\begin{definition}[Количество информации Фишера]
  \label{def:fisherInformation}
  \index{количество информации Фишера}
  Математическое ожидание квадрата вклада выборки называется
  количеством информации Фишера
  $$I_n\left(\theta\right)=
    \meanof{\theta}{U\left( \vec{x},\theta \right)^2}$$
\end{definition}
\begin{remark}
  Между математическим ожиданием квадрата вклада выборки и второй производной
  функции правдоподобия существует такое соотношение
  \begin{equation*}
    \meanof{\theta}{U\left( \vec{x},\theta \right)^2}
    = - \meanof{\theta}{
      \frac{\partial^2}{\partial\theta^2}
      \ln{L\left( \vec{x},\theta \right)}}
  \end{equation*}
\end{remark}
\begin{proof}
  Будем доказывать справа налево
  \begin{align*}
  - \Meanof{\theta}{
    \frac{\partial^2}{\partial \theta^2}
    \ln{L\left( \vec{x}, \theta \right)}}
  = - \Meanof{\theta}{
    \frac{\partial}{\partial\theta}
    \frac{\frac{\partial}{\partial\theta}L\left(\vec{x},\theta\right)}
      {L\left(\vec{x},\theta\right)}} = \\
  = -\Meanof{\theta}{
    \frac{\frac{\partial^2}{\partial\theta^2}
      L\left(\vec{x},\theta\right)\cdot L\left(\vec{x},\theta\right)-
        \left[\frac{\partial}{\partial\theta}
          L\left(\vec{x},\theta\right)\right]^2
      }
      {L\left(\vec{x},\theta\right)^2}} = \\
  = - \Meanof{\theta}{
    \frac{\frac{\partial^2}{\partial\theta^2}
      L\left(\vec{x},\theta\right)}
      {L\left(\vec{x},\theta\right)}}
    + \meanof{\theta}{
      \left(\frac{\frac{\partial}{\partial\theta}
        L\left(\vec{x},\theta\right)}
        {L\left(\vec{x},\theta\right)}\right)^2}
  \end{align*}
  Математическое ожидание вклада выборки равно нулю, а это значит, что
  \begin{equation*}
   - \meanof{\theta}{\frac{\partial^2}{\partial\theta^2}
      \ln{L\left( \vec{x},\theta \right)}}
   = \meanof{\theta}{\left[\frac{\frac{\partial}{\partial\theta}
      L\left(\vec{x},\theta\right)}{L\left(\vec{x},\theta\right)}\right]^2}
  \end{equation*}
  Воспользовавшись замечанием \ref{remark:defU} и переписав равенство в другом
  виде, получаем
  \begin{equation*}
    \meanof{\theta}{U\left( \vec{x},\theta \right)^2}
    = - \meanof{\theta}{
      \frac{\partial^2}{\partial\theta^2}
      \ln{L\left( \vec{x},\theta \right)}}
  \end{equation*}
\end{proof}

\begin{example}
  Пускай \xsample --- выборка из нормального распределения с
  параметрами $\theta$ и $\sigma^2$.
  Неизвестный параметр --- математическое ожидание.
  Тогда количество информации
  \begin{equation*}
    I_n\left( \theta \right)
    = \meanof{\theta}{U\left( \vec{x}, \theta \right)^2}
    = \meanof{\theta}{\left( \sum_{k=1}^{n} \frac{\partial}{\partial\theta}
      \ln{\pdf{x_k, \theta}} \right)^2}
    = \Dispersionof{\theta}{\sum_{k=1}^{n} \frac{\partial}{\partial\theta}
      \ln{\pdf{x_k, \theta}}}
  \end{equation*}
  Случайные величины $x_k$ независимы и распределены одинаково, а это значит,
  что
  \begin{equation*}
    \Dispersionof{\theta}{\sum_{k=1}^{n} \frac{\partial}{\partial\theta}
      \ln{\pdf{x_k, \theta}}}
    = n \cdot I_1\left( \theta \right)
    = n \cdot \meanof{\theta}{\left( \frac{\partial}{\partial \theta}
      \ln{\pdf{x_1, \theta}} \right)^2}
  \end{equation*}
  Производная логарифма плотности нормального распределения в данном случае
  считается просто
  \begin{equation*}
    \frac{\partial}{\partial \theta} \ln{\pdf{x, \theta}}
    = \frac{\partial}{\partial \theta} \left[
        \ln{\frac{1}{\sqrt{2 \cdot \pi} \cdot \sigma}}
        - \frac{\left( x - \theta \right)^2}{2 \cdot \sigma^2} \right]
    = \frac{x - \theta}{\sigma^2}
  \end{equation*}
  Получаем результат
  \begin{equation*}
    I_n\left( \theta \right) = n \cdot I_1\left( \theta \right)
    = n \cdot \Meanof{\theta}{\frac{\left( x_1 - \theta \right)^2}{\sigma^4}}
    = n \cdot \frac{\dispersionof{\theta}{x_1}}{\sigma^4}
    = \frac{n}{\sigma^2}
  \end{equation*}

  То есть, объём получаемой информации растёт линейно с увеличением длины
  выборки а в данном примере --- ещё и обратно пропорционально дисперсии.
\end{example}

Количество информации позволяет оценить точность,
с которой можем получить параметр $\theta$.

\begin{theorem}[Неравенство Рао-Крамера]
  \label{theorem:Rao-Kramer}
  \index{неравенство!Рао-Крамера}
  Пусть $\hat{\theta}$ --- несмещённая оценка параметра $\theta$.
  Тогда имеет место неравенство
  \begin{equation*}
    \forall\theta\in\Theta:\qquad
    \dispersionof{\theta}{\hat{\theta}}
    \ge\frac{1}{I_n\left(\theta\right)}
  \end{equation*}
\end{theorem}
\begin{proof}
  Выпишем, чему равно математическое ожидание оценки $\hat{\theta}$
  $$\begin{cases}
    \meanof{\theta}{\hat{\theta}}
      &=\theta\\
    \meanof{\theta}{\hat{\theta}}
      &=\integral{\mathbb{R}^n}{}{\vec{u}}{
        \hat{\theta}\left( \vec{u} \right)
          \cdot L\left( \vec{u},\theta \right)}
    \end{cases}
    \Rightarrow
    \theta=\integral{\mathbb{R}^n}{}{\vec{u}}{
        \hat{\theta}\left( \vec{u} \right)
          \cdot L\left( \vec{u},\theta \right)}$$
  Продифференцируем с двух сторон полученное для $\theta$ равенство
  по параметру $\theta$
  \begin{equation*}
    \frac{\partial}{\partial \theta}\theta
    = \frac{\partial}{\partial \theta}\integral{\mathbb{R}^n}{}{\vec{u}}{
      \hat{\theta}\left( \vec{u} \right)
        \cdot L\left( \vec{u},\theta \right)}
  \end{equation*}
  Левая часть равенства превращается в единицу,
  а справа происходит дифференцирование под знаком интеграла.
  Также помним, что оценка $\theta\left( \vec{u} \right)$
  не зависит от параметра $\theta$.
  Это значит, что производную нужно брать только от функции правдоподобия
  \begin{equation*}
    1 = \integral{\mathbb{R}^n}{}{\vec{u}}{\hat{\theta}\left( \vec{u} \right)
      \cdot \frac{\partial}{\partial \theta}L\left( \vec{u},\theta \right)}
  \end{equation*}
  Далее нам нужно получить вклад выборки.
  Для этого умножим и поделим подынтегральное выражение
  на функцию правдоподобия
  \begin{equation*}
   \integral{\mathbb{R}^n}{}{\vec{u}}{\hat{\theta}\left( \vec{u} \right)
    \cdot \frac{\partial}{\partial \theta}L\left( \vec{u},\theta \right)}
  = \integral{\mathbb{R}^n}{}{\vec{u}}{\hat{\theta}\left( \vec{u} \right)
    \cdot \frac{
      \frac{\partial}{\partial \theta}L\left( \vec{u},\theta \right)}
      {L\left( \vec{u},\theta \right)}
        \cdot L\left( \vec{u},\theta \right)}
  \end{equation*}
  Видим, что дробь под интегралом --- производная логарифма
  функции правдоподобия, которая является вкладом выборки
  \begin{equation*}
    \integral{\mathbb{R}^n}{}{\vec{u}}{\hat{\theta}\left( \vec{u} \right)
      \cdot \frac{
        \frac{\partial}{\partial \theta}L\left( \vec{u},\theta \right)}
        {L\left( \vec{u},\theta \right)}
          \cdot L\left( \vec{u},\theta \right)}
    = \integral{\mathbb{R}^n}{}{\vec{u}}{\hat{\theta}\left( \vec{u} \right)
      \cdot
        U\left( \vec{x},\theta \right)
          \cdot L\left( \vec{u},\theta \right)}
  \end{equation*}
  У нас есть математическое ожидание произведения оценки и вклада выборки,
  которое равно единице
  \begin{equation}\label{eq:rao_kramer}
    1 = \Meanof{\theta}{\hat{\theta}\cdot U\left( \vec{x},\theta \right)}
  \end{equation}
  Помним, что математическое ожидание вклада выборки равно нулю.
  Значит, умножение его на константу ничего не меняет
  \begin{equation*}
    \meanof{\theta}{U\left( \vec{x},\theta \right)}=0
    \Rightarrow 
    \theta\cdot\meanof{\theta}{U\left( \vec{x},\theta \right)}
    = \Meanof{\theta}{\theta\cdot U\left(\vec{x},\theta\right)}
    = 0
  \end{equation*}
  Воспользовавшись полученным результатом, вернёмся к равенству
  \eqref{eq:rao_kramer}.
  Отнимем от обеих частей ноль (то есть, полученное только что выражение)
  \begin{equation*}
    1 = \Meanof{\theta}{\hat{\theta}\cdot U\left( \vec{x},\theta \right)}
      - \Meanof{\theta}{\theta\cdot U\left(\vec{x},\theta\right)}
  \end{equation*}
  Получаем равенство
  \begin{equation*}
    1 = \Meanof{\theta}{\left(\hat{\theta}-\theta\right)
    \cdot U\left( \vec{x},\theta \right)}
  \end{equation*}
  Воспользовавшись неравенством Коши, узнаём
  произведение корней дисперсии и количества информации больше, чем единица
  \begin{equation}\label{eq:rao_kramer_koshi}
    \begin{split}
    1 = \meanof{\theta}{
      \left[\left(\hat{\theta}-\theta\right)
        \cdot U\left( \vec{x},\theta \right)\right]} \le \\
    \le \sqrt{\meanof{\theta}{
      \left(\hat{\theta}-\theta\right)^2}}
      \cdot\sqrt{\meanof{\theta}{U\left( \vec{x},\theta \right)^2}}
    = \sqrt{\dispersionof{\theta}{\hat{\theta}}}
      \cdot\sqrt{I_n\left(\theta\right)}
    \end{split}
  \end{equation}
  Возводим обе части неравенства в квадрат и делим на количество информации
  \begin{equation*}
    \dispersionof{\theta}{\hat{\theta}} \ge \frac{1}{I_n\left( \theta \right)}
  \end{equation*}
  Неравенство доказано.
\end{proof}
\begin{remark}
  Иногда нужно оценивать не сам параметр, а функцию параметра.
  Тогда, если $\alpha$ --- несмещённая оценка для $f\left(\theta\right)$,
  справедливо следующее неравенство
  \begin{equation*}
    \forall \theta \in \Theta:\qquad
    \dispersionof{\theta}{\alpha}
    \ge \frac{\left| f'\left( \theta \right) \right|}{I_n\left( \theta \right)}
  \end{equation*}
\end{remark}

\subsection{Метод максимального правдоподобия}
У нас есть нижняя оценка точности,
с которой можно отыскать желаемую оценку, а это значит,
что точнее определить просто не получится
и нужно стремиться к равенству в неравенстве Рао-Крамера.

\begin{definition}[Эффективная оценка]\index{оценка!эффективная}
  Оценка $\hat{\theta}$,
  для которой в неравенстве Рао-Крамера стоит равенство,
  называется эффективной
  \begin{equation*}
    \forall \theta \in \Theta: \qquad
    \dispersionof{\theta}{\hat{\theta}} = \frac{1}{I_n\left( \theta \right)}
  \end{equation*}
\end{definition}

Выясним, какими свойствами должна обладать плотность,
чтобы можно было получить эффективную оценку.
Для этого в неравенстве Рао-Крамера нужно рассмотреть случай равенства
(так как в этом случае оценка будет самой точной)
\begin{equation*}
  \dispersionof{\theta}{\hat{\theta}}=\frac{1}{I_n\left(\theta\right)}
\end{equation*}
Рассмотрим неравенство \eqref{eq:rao_kramer_koshi} и выясним,
в каком случае в нём будет стоять знак равенства
\begin{equation*}
  1
  = \meanof{\theta}{
    \left[\left( \hat{\theta} - \theta \right)
      \cdot U\left( \vec{x}, \theta \right)\right]}
  = \sqrt{\meanof{\theta}{
    \left(\hat{\theta}-\theta\right)}^2}
    \cdot \sqrt{\meanof{\theta}{U\left( \vec{x}, \theta \right)^2}}
\end{equation*}
Снова проводим аналогию с векторами и видим,
что скалярное произведение (математическое ожидание произведения)
векторов
(функций от параметра $\theta$:
$f_1\left( \theta \right)=\hat{\theta}-\theta$ и
$f_2\left( \theta \right)=U\left( \vec{x},\theta \right)$)
равно произведению их норм (корней математических ожиданий квадратов).
Это в свою очередь означает,
что угол между этими векторами (функциями) равен нулю,
а сами функции являются линейными комбинациями друг друга.
Значит, есть такая функция $k\left( \theta \right)$, что
$f_2\left( \theta \right)$ равняется произведению
$f_1\left( \theta \right)$ и $k\left( \theta \right)$.
\begin{align*}
  U\left( \vec{x},\theta \right)
    &=\left( \hat{\theta}-\theta \right)\cdot k\left( \theta \right)\\
  \frac{\partial}{\partial\theta}\ln{L\left( \vec{x},\theta \right)}
    &=\hat{\theta}\cdot k\left( \theta \right)
      -\theta\cdot k\left( \theta \right)\\
  \partial\ln{L\left( \vec{x},\theta \right)}
    &=\hat{\theta}\left( \vec{x} \right)
        \cdot k\left( \theta \right)\cdot\partial\theta
      -\theta\cdot k\left( \theta \right)\cdot\partial\theta
\end{align*}
Проинтегрируем обе части равенства
\begin{align*}
  \integralp{}{}{\ln{L\left( \vec{x},\theta \right)}}{}
    &=\hat{\theta}\left( \vec{x} \right)
        \cdot \integralp{}{}{\theta}{k\left( \theta \right)}
      -\integralp{}{}{\theta}{\theta\cdot k\left( \theta \right)}
\end{align*}
Получим следующее равенство
\begin{align*}
  \ln{L\left( \vec{x},\theta \right)}+c_1\left( \vec{x} \right)
    =\hat{\theta}\left( \vec{x} \right)
        \cdot \left[ a\left( \theta \right)+c_2\right]
      -\left[b^*\left( \theta \right)+c_3\right]
\end{align*}
Сгруппируем константы и введём замену
$b\left( \theta \right)=-b^*\left( \theta \right)$
\begin{equation*}
  \ln{L\left( \vec{x}, \theta \right)}
  = \hat{\theta}\left( \vec{x} \right)\cdot a\left( \theta \right)
    +b\left( \theta \right) + c\left( \vec{x} \right)
\end{equation*}
Избавимся от логарифма слева, а для этого возьмём экспоненту от обеих частей
равенства
\begin{equation*}
  L\left( \vec{x}, \theta \right)
  = \exp{\left\{\hat{\theta}\left( \vec{x} \right)\cdot a\left( \theta \right)
    + b\left( \theta \right) + c\left( \vec{x} \right)\right\}}
\end{equation*}
При $n = 1$ получим такую плотность распределения
\begin{equation*}
  \pdf{x_1,\theta}
  = \exp{\left\{\hat{\theta}\left( x_1 \right) \cdot a_1\left( \theta \right)
    + b_1\left( \theta \right) + c_1\left( x_1 \right)\right\}}
\end{equation*}
В таком случае функция правдоподобия имеет вид
\begin{align*}
  &L\left( \vec{x},\theta \right)
  =\prod_{k=1}^n\pdf{x_1,\theta}=\\
  &=\exp{\left\{\sum_{k=1}^n \hat{\theta}\left(x_k\right)\cdot a_1\left(\theta\right)
    +n\cdot b_1\left( \theta \right)
    +\sum_{k=1}^n c_1\left( x_k \right)\right\}}
\end{align*}
Отметим, что в этом случае оценка $\hat{\theta}\left( \vec{x} \right)$
является суммой оценок по каждой координате (случайной величине)
\begin{equation*}
  \hat{\theta}\left( \vec{x} \right)
  = \sum_{k=1}^n \hat{\theta}\left( x_k \right)
\end{equation*}

\begin{definition}[Экспоненциальное распределение]
  \label{def:exponentialDistribution}
  \index{распределение!экспоненциальное}
  \index{экспоненциальное!распределение}
  Распределения следующего вида называются экспоненциальными
  $$\pdf{x,\theta}
    =\exp{\left\{\hat{\theta}\left(x\right)\cdot a\left(\theta\right)
      +b\left( \theta \right)+c\left( x \right)\right\}}$$
\end{definition}

Подведём итог предыдущих размышлений.

\begin{affirmation}
  \label{affirmation:efficientEstimator:exponentialExsistance}
  \index{эффективная оценка}
  \index{экспоненциальное!распределение!эффективная оценка}
  \index{распределение!экспоненциальное!эффективная оценка}
  Для экспоненциальных распределений существует эффективная оценка.
\end{affirmation}

Попробуем найти рецепт выяснения эффективной оценки. Начнём с примера
\begin{example}
  Есть выборка \xsample из нормального распределения
  с неизвестным математическим ожиданием $N\left( \theta,1 \right)$.
  Тогда плотность распределения $k$-ой случайной величины будет следующей
  $$\pdf{x_k}
    =\frac{1}{\sqrt{2\cdot\pi}}
      \cdot exp{\left\{-\frac{\left(x_k-\theta\right)^2}{2}\right\}}$$
  Её логарифм, очевидно, имеет такой вид
  $$\ln{\pdf{x_k}}
    =\ln{\frac{1}{\sqrt{2\cdot\pi}}}
      -\frac{\left(x_k-\theta\right)^2}{2}$$
  Теперь выпишем логарифм функции правдоподобия
  \begin{align*}
    \ln{L\left( \vec{x}, \theta \right)}
    = \sum_{k=1}^n \ln{\pdf{x_k}}
    = \sum_{k=1}^n \ln{\frac{1}{\sqrt{2 \cdot \pi}}}
      - \sum_{k=1}^n \frac{\left(x_k - \theta \right)^2}{2} = \\
    = n \cdot \ln{\frac{1}{\sqrt{2 \cdot \pi}}}
      - \sum_{k=1}^n \frac{\left(x_k - \theta \right)^2}{2}
  \end{align*}
  Преобразуем
  \begin{align*}
    \ln{L\left( \vec{x},\theta \right)}
    = n \cdot \ln{\frac{1}{\sqrt{2 \cdot \pi}}} - \sum_{k=1}^n \frac{x_k^2}{2}
      + \sum_{k=1}^n x_k \cdot \theta - \frac{n \cdot \theta^2}{2}, \\
    \sum_{k=1}^n x_k \cdot \theta
    = \left( \frac{1}{n} \cdot \sum_{k=1}^n x_k \right) \cdot \theta \cdot n
    = \overline{x} \cdot \theta \cdot n, \\
    \ln{L\left( \vec{x}, \theta \right)}
    = n \cdot \ln{\frac{1}{\sqrt{2 \cdot \pi}}} - \sum_{k=1}^n \frac{x_k^2}{2}
      + \overline{x} \cdot \theta \cdot n - \frac{n \cdot \theta^2}{2}
  \end{align*}
  Сгруппировав множители при $n$, получаем
  \begin{equation*}
  \ln{L\left( \vec{x}, \theta \right)}
  = n \cdot \ln{\frac{1}{\sqrt{2 \cdot \pi}}} - \sum_{k=1}^n \frac{x_k^2}{2}
    - n \cdot \frac{\theta^2 - 2 \cdot \overline{x} \cdot \theta}{2}
  \end{equation*}
  Добавим и вычтем в числителе дроби выборочное среднее
  \begin{equation*}
    \ln{L\left( \vec{x},\theta \right)}
    = n \cdot \ln{\frac{1}{\sqrt{2 \cdot \pi}}} -\sum_{k=1}^n \frac{x_k^2}{2}
      - n \cdot \frac{\theta^2 - 2 \cdot \overline{x} \cdot \theta
      + \left( \overline{x}^2 - \overline{x}^2 \right)}{2}
  \end{equation*}
  В результате получим
  \begin{equation*}
    \ln{L\left( \vec{x},\theta \right)}
    = n \cdot \ln{\frac{1}{\sqrt{2 \cdot \pi}}}
      - \sum_{k=1}^n \frac{x_k^2 - \overline{x}^2}{2}
      - n \cdot \frac{\left( \theta - \overline{x} \right)^2}{2}
  \end{equation*}
  Видим, что последнее слагаемое не может быть положительным,
  так как это квадрат со знаком ``минус''.
  Когда оценка $\theta$ равна выборочному среднему (идеальный случай),
  то последнее слагаемое обращается в нуль, а сама функция правдоподобия
  в таком случае принимает максимальное значение.
  Делаем предположение о том, как находить наилучшую оценку
  \begin{equation*}
    \theta_* = \argmaxof{\ln{L\left( \vec{x}, \theta \right)}}{\theta}
  \end{equation*}
  Соответствующий рецепт поиска оценок во многих случаях оказывается
  эффективным.
\end{example}

\begin{definition}[Оценка максимального правдоподобия]
  \label{def:maximumLikelihoodEstimation}
  \index{оценка!максимального правдоподобия}
  Оценка максимального правдоподобия
  $\theta_*$ --- такое значение параметра $\theta$,
  при котором функция правдоподобия достигает своего максимального значения
  $$\theta_*=\argmaxof{\ln{L\left( \vec{x},\theta \right)}}{\theta}$$
\end{definition}

\begin{remark}
  Оценок максимального правдоподобия может быть несколько,
  а может не существовать ни одной.
\end{remark}

\begin{definition}[Уравнение правдоподобия]\index{уравнение!правдоподобия}
  Уравнением правдоподобия называется равенство вида
  \begin{equation*}
    U\left( \vec{x}, \theta \right) = 0
  \end{equation*}
  Или же
  \begin{equation*}
    \frac{\partial}{\partial\theta}\ln{L\left( \vec{x}, \theta \right)} = 0
  \end{equation*}
\end{definition}

\begin{remark}
  В гладком случае оценку $\theta_*$ можно искать с помощью уравнения
  правдоподобия.
  Тем не менее, нужно помнить, что равенство первой производной нулю является
  лишь необходимым условием максимума.
  Полученные критические точки нужно проверять на характер и наличие
  экстремума.
\end{remark}

\begin{example}
  Пусть \xsample --- выборка из показательного распределения с
  параметром $\lambda > 0$.
  Тогда
  \begin{align*}
    \frac{\partial}{\partial\theta} \ln{L\left( \vec{x}, \theta \right)} =
    \frac{\partial}{\partial \lambda} \ln{\left[ \prod_{k=1}^n \lambda
      \cdot e^{- \lambda \cdot x_k}
      \cdot \Indicator{x_k \in \left[ 0; +\infty \right)} \right]} = \\
    = \frac{\partial}{\partial \lambda} \sum_{k=1}^{n} \left( \ln{\lambda}
        - \lambda \cdot x_k \right)
      \cdot \Indicator{x_k \in \left[ 0; +\infty \right)} = \\
    = \sum_{k=1}^{n} \left( \frac{1}{\lambda} - x_k \right)
      \cdot \Indicator{x_k \in \left[ 0; +\infty \right)}
  \end{align*}
  Уравнение правдоподобия примет вид
  \begin{equation*}
    \sum_{k=1}^{n} \left( \frac{1}{\lambda} - x_k \right)
      \cdot \Indicator{x_k \in \left[ 0; +\infty \right)} = 0
  \end{equation*}
  Его решение будет следующим
  \begin{equation*}
    \lambda_* = \frac{n}{\sum_{k=1}^{n} x_k}
  \end{equation*}
  Проверим полученный результат с помощью второй производной следующим образом
  \begin{equation*}
    \frac{\partial^2}{\partial \lambda^2}
    \ln{L\left( \vec{x}, \lambda_* \right)} < 0
  \end{equation*}
  Действительно, получаем
  \begin{equation*}
    -\frac{1}{\lambda_*^2} < 0
  \end{equation*}
  То есть, обратное к среднему и есть оценка максимального правдоподобия для
  параметра $\lambda$
  \begin{equation*}
    \lambda_* = \frac{1}{\overline{x}}
  \end{equation*}
\end{example}

\begin{definition}[Вариационный ряд]\index{вариационный ряд}
  Вариационный ряд выборки \xsample --- значения выборки,
  упорядоченные в порядке неубывания
  \begin{equation*}
    x_{\left(1\right)} \le x_{\left(2\right)} \le \dots
      \le x_{\left(n\right)},\qquad
    x_{\left(1\right)}=\underset{k}\min{x_k},\;
    x_{\left(n\right)}=\underset{k}\max{x_k}
  \end{equation*}
\end{definition}

Не всегда удобно и возможно использовать производную для решения уравнения
правдоподобия.
Следующий пример продемонстрирует это.

\begin{example}
  Пускай \xsample --- выборка из равномерного распределения
  с параметром $\left[ 0; \theta \right],\; \theta > 0$.
  Плотность принимает вид
  \begin{equation*}
    \pdf{x, \theta}
    = \frac{1}{\theta} \cdot \Indicator{x \in \left[ 0; \theta \right]}
  \end{equation*}
  Нам нужно, чтобы все $x_k$ оставались в пределах отрезка
  $\left[ 0; \theta \right]$, а это значит, что минимальный элемент не меньше,
  чем $0$, а максимальный не больше $\theta$. Сейчас
  \begin{equation*}
    L\left( \vec{x}, \theta \right)
    = \frac{1}{\theta^n} \cdot \Indicator{0 \le x_{\left( 1 \right)}
      \le x_{\left( n \right)} \le \theta}
  \end{equation*}

  График функции правдоподобия (без индикаторов) изображён на рисунке
  \ref{fig:tikz:exampleMaximumLikelihoodEstimator}.
  Чем меньше $\theta$, тем больше значение функции правдоподобия, но есть одно
  важное ограничение --- индикатор, который не позволяет быть парамеру $\theta$
  меньше максимального элемента выборки $x_{\left( n \right)}$.
  Значит, у нас есть оценка максимального правдоподобия
  \begin{equation*}
    \theta_* = x_{\left( n \right)}
  \end{equation*}
  Возникает вопрос состоятельности этой оценки.
  При увеличении $n$ мы располагаем всё большим количеством значений выборки,
  а $\theta_*$ при этом не убывает. Значит,
  \begin{equation*}
    \exists \lim_{n \to \infty} \theta_* = \theta'
  \end{equation*}
  Также знаем, что $\theta' \le \theta$, так как всегда $\theta_* \le \theta$.
  Предположим, что
  \begin{equation*}
    \Probability{\theta - \theta' > 0} > 0
    \Rightarrow \exists \delta > 0:
      \Probability{\theta' < \theta - \delta} > 0
  \end{equation*}
  Если максимальное значение меньше какого-то числа, то все остальные элементы
  тоже меньше его
  \begin{equation*}
    \Probability{\theta_* < \theta - \delta}
    = \frac{\left( \theta - \delta \right)^n}{\theta^n} \covergence{} 0
  \end{equation*}
  Противоречие. Значит, оценка $\theta_* = x_{\left( n \right)}$ сильно
  состоятельная
  \begin{equation*}
    \theta_* \acovergence \theta
  \end{equation*}
\end{example}

\begin{theorem}
  \index{теорема!о состоятельности оценки максимального правдоподобия}
  \index{оценка!максимального правдоподобия!теорема о состоятельности}
  Если плотность $\pdf{x,\theta}$
  непрерывна и дифференцируема по параметру $\theta$,
  а производная не равна нулю
  $\frac{\partial}{\partial\theta}\pdf{x,\theta}\neq 0$,
  то оценка максимального правдоподобия состоятельна
\end{theorem}

\begin{figure}[h!]
  \center\includestandalone[]{tikz/exampleMaximumLikelihoodEstimator}
  \caption{Параметр $\theta$ не может быть меньше максимального значения
    выборки}
  \label{fig:tikz:exampleMaximumLikelihoodEstimator}
\end{figure}
