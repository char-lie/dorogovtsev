\chapter{Основы}
\section{Методы оценок характеристик распределения
    наблюдаемых случайных величин}
$x_1, \dots, x_n$ --- независимые одинаково распределённые случайные величины
с неизвестной функцией распределения $F$.
\index{функция распределения!неизвестная}
Логично, что вероятность выпадения каждого $x_k$
(вероятность того, что наугад взятый из выборки $x$ будет равен $x_k$)
одинакова
$$P(x=x_k)=\frac{1}{n}$$

Цель --- найти $F$ или сказать что-то о её свойствах.

\subsection{Эмпирическая функция распределения}
\index{функция распределения!эмпирическая}
\index{функция распределения!выборочная}
\begin{definition}[Эмпирическая функция распределения]
    Эмпирической (выборочной) функцией распределения,
    построенной по выборке $x_1, \dots, x_n$ называется функция
    $$\cdfn{x}=\frac{1}{n}\cdot \sum_{k=1}^n
    \indicator{x_k\le x}$$
\end{definition}

\begin{theorem}Неизвестная функция распределения $\cdf{x}$
    может быть сколь угодно точно
    восстановлена по выборке достаточно большого объёма
    \cite[стр.~25]{BorovkovMS}.
    $$\probability{\cdfn{x}\dCovergence \cdf{x}}=1$$
\end{theorem}
\begin{proof}[Идея доказательства]
Вспомним, чему равна эмпирическая функция распределения
$$\cdfn{x}=\frac{1}{n}\cdot \sum_{k=1}^n
\indicator{x_k\le x}$$

Заметим, что индикаторы $\indicator{x_k\le x}$
являются независимыми одинаково распределёнными случайными величинами,
а функцию распределения $\cdf{x}$ можно записать следующим образом
$$\cdf{x}=\Probability{x_1\le x}=\mean{\indicator{x_1\le x}}$$

Так как эмпирическая функция распределения является
средним арифметическим индикаторов, то по усиленному закону больших чисел
она сходится к неизвестной функции распределения почти наверное
при устремлении длины выборки к бесконечности
$$\cdfn{x}=\frac{1}{n}\cdot\sum_{k=1}^n\indicator{x_k\le x}
\acovergence\mean{\indicator{x_1}}=\cdf{x}$$

Теорема доказана
$$\cdfn{x}\aCovergence\cdf{x}$$
\end{proof}

\subsection{Гистограмма}
Как можно попытаться отследить плотность распределения?
Постараемся найти функцию распределения, а потом и плотность.

Допустим, $F$ имеет хорошую (непрерывную) плотность.
Как тогда из $F$ получить $p$?

Мы знаем, что $F'=p$, но это никому не нужно, так как $F_n'$ --- производная
ступенчатой функции, которая почти везде будет равна нулю.

Но также мы помним, что
$$\cdf{b}-\cdf{a}=\int\limits_a^b \pdf{x} dx$$

Положим $a=x$ и введём $\Delta_x=b-x$
$$\cdf{x+\Delta_x}-\cdf{x}=\int\limits_x^{x+\Delta_x} \pdf{y} dy$$

Делим обе части на $\Delta_x$.
$$\frac{1}{\Delta_x}\cdot\int\limits_x^{x+\Delta_x} \pdf{y} dy
=\frac{\cdf{x+\Delta_x}-\cdf{x}}{\Delta_x}$$

Несложно заметить,
что при достаточно малых значениях $\Delta_x$
получаем плотность распределения $\pdf{x}$
$$\frac{\Delta\cdf{x}}{\Delta_x}
\xrightarrow[]{\Delta_x\to 0}
\frac{d\cdf{x}}{dx}=\pdf{x}$$

Значит, можем заменить $\pdf{x}$ не производной, а такой разностью.
$$\pdf{x}\approx\frac{\cdf{x+\Delta}-\cdf{x}}{\Delta}$$

Возьмём $m$ полуинтервалов на числовой прямой
$I_j=\left(a_{j-1},a_j\right], i=\overline{1,m}$
таких, что все значения выборки попадают в один из них.
Для этого определим пару свойств точек, ограничивающих эти интервалы:
\begin{enumerate}
    \item Каждая следующая точка строго правее (больше) предыдущей.
        (так как зачем нам одинаковые точки?)
        $$a_0<a_1<\dots<a_m$$
    \item Каждое значение выборки должно попадать ровно в один полуинтервал.
        Очевидно, что данные полуинтервалы $I_j$ не пересекаются между собой.
        Значит, осталось потребовать, чтобы
        крайнее левое значение было меньше минимального значения из выборки,
        а крайнее правое --- не больше максимального
        $$a_0<min\left(X\right)\le max\left(X\right)\le a_m$$
\end{enumerate}

Введём функцию $q\left(y\right)$
$$q\left(y\right)
=\sum_{j=1}^m \frac{\cdf{a_j}-\cdf{a_{j-1}}}{a_j-a_{j-1}}
    \cdot\indicator{y\in I_j}$$

Определим последовательность функций $q_n\left(y\right)$,
заменив $\cdf{x}$ на $\cdfn{x}$ в предыдущем определении
\begin{equation}\label{eq:histogram_start}
q_n\left(y\right)
=\sum_{j=1}^m \frac{\cdfn{a_j}-\cdfn{a_{j-1}}}{a_j-a_{j-1}}
    \cdot\indicator{y\in I_j}
\end{equation}

Отметим, что
$q_n$ сходится к $q$ почти наверное (согласно закону больших чисел),
а $q$ в свою очередь сходится к $p$ (согласно центральной предельной теореме)
$$q_n\left(y\right)\acovergence q\left(y\right)\covergencen{m}{}\pdf{y}$$

Функция $q_n$ называется \textbf{гистограммой}.
\index{гистограмма}

Избавимся от $a_j$ в формуле, а для этого вспомним, чему равно $\cdfn{x}$
$$\cdfn{x}=\frac{1}{n}\cdot \sum_{k=1}^n
\indicator{x_k\le x}$$

Теперь посмотрим, чему равна разность $\cdfn{a_j}-\cdfn{a_{j-1}}$,
которая, как мы видим, является вероятностью того,
что $x$ попало в отрезок $I_j$
\begin{align*}
    \cdfn{a_j}-\cdfn{a_{j-1}}=\\
    =\frac{1}{n}\cdot \sum_{k=1}^n
        \indicator{x_k\le a_j}-\frac{1}{n}\cdot \sum_{k=1}^n
        \indicator{x_k\le a_{j-1}}
\end{align*}

Сгруппируем слагаемые и получим чуть более компактную запись разности
\begin{eqnarray}\label{eq:cdfn_difference}
    \cdfn{a_j}-\cdfn{a_{j-1}}=\nonumber\\
    =\frac{1}{n}\cdot \sum_{k=1}^n
        \left[\indicator{x_k\le a_j}-\indicator{x_k\le a_{j-1}}\right]
\end{eqnarray}

Рассмотрим возможные значения индикаторов

Если оба индикатора равны единице,
это значит, что $x_k$ не больше $a_j$ и не больше $a_{j-1}$.
Поскольку $a_{j-1}\le a_j$, то можно обойтись тем, что $x\le a_{j-1}$
\begin{align*}
    \begin{cases}
        \indicator{x_k\le a_j}=1\\
        \indicator{x_k\le a_{j-1}}=1\\
        a_{j-1}\le a_j
    \end{cases}
    \Rightarrow
    \begin{cases}
        x_k\le a_j\\
        x_k\le a_{j-1}\\
        a_{j-1}\le a_j
    \end{cases}
    \\\Rightarrow
        x_k\le a_{j-1}\le a_j
    \Rightarrow
        x_k\le a_{j-1}
\end{align*}

Такая ситуация,
что $x$ больше, чем $a_j$, но не больше, чем $a_{j-1}$, невозможна,
так как $a_{j-1}$ не больше, чем $a_j$,
а признать возможной такое положение дел ($a_j<x_k\le a_{j-1}$)
означало бы то, что $a_j<a_{j-1}$
\begin{align*}
    \begin{cases}
        \indicator{x_k\le a_j}=0\\
        \indicator{x_k\le a_{j-1}}=1\\
        a_{j-1}\le a_j
    \end{cases}
    &\Rightarrow
    \begin{cases}
        x_k>a_j\\
        x_k\le a_{j-1}\\
        a_{j-1}\le a_j
    \end{cases}
    \\&\Rightarrow
    \begin{cases}
        a_j<x_k\le a_{j-1}\\
        a_{j-1}\le a_j
    \end{cases}
\end{align*}


Если оба индикатора равны нулю,
то это значит, что $x$ строго больше как $a_j$, так и $a_{j-1}$.
Опять же, поскольку $a_{j-1}\le a_j$, то достаточно сказать, что $x>a_j$.
\begin{align*}
    \begin{cases}
        \indicator{x_k\le a_j}=0\\
        \indicator{x_k\le a_{j-1}}=0\\
        a_{j-1}\le a_j
    \end{cases}
    \Rightarrow
    \begin{cases}
        x_k>a_j\\
        x_k>a_{j-1}\\
        a_j\ge a_{j-1}
    \end{cases}
    \\\Rightarrow
        x_k>a_j\ge a_{j-1}
    \Rightarrow
        x_k>a_j
\end{align*}

Если же $x$ больше, чем $a_{j-1}$, но не больше, чем $a_j$,
то $x$ попадает в полуинтервал $\left(a_{j-1},a_j\right]$
\begin{align*}
    \begin{cases}
        \indicator{x_k\le a_j}=1\\
        \indicator{x_k\le a_{j-1}}=0\\
        a_{j-1}\le a_j
    \end{cases}
    \Rightarrow
    \begin{cases}
        x_k\le a_j\\
        x_k>a_{j-1}\\
        a_j\ge a_{j-1}
    \end{cases}
    \\\Rightarrow
        a_{j-1}<x_k\le a_j
\end{align*}

Вспомним формулу \eqref{eq:cdfn_difference}
\begin{align*}
    \cdfn{a_j}&-\cdfn{a_{j-1}}=\\
    &=\frac{1}{n}\cdot \sum_{k=1}^n
    \left[\indicator{x_k\le a_j}-\indicator{x_k\le a_{j-1}}\right]
\end{align*}

Очевидно, что нас интересуют те пары, разность которых не равна нулю.
Это значит, что те случаи, когда $x>a_j$ или $x\le a_{j-1}$, нас не интересуют.
Поскольку такой случай, что $a_j<x\le a_{j-1}$ невозможен, то его тоже отбросим.
Значит, остался только тот вариант,
когда $x$ попадает в полуинтервал $\left(a_{j-1},a_j\right]$
$$\frac{1}{n}\cdot \sum_{k=1}^n
        \left[\indicator{x_k\le a_j}-\indicator{x_k\le a_{j-1}}\right]
    =\frac{1}{n}\cdot \sum_{k=1}^n \indicator{x_k\in \left(a_{j-1},a_j\right]}
$$

Видим знакомые полуинтервалы $\left(a_{j-1},a_j\right]=I_j$. Воспользуемся этим
$$\frac{1}{n}\cdot \sum_{k=1}^n \indicator{x_k\in \left(a_{j-1},a_j\right]}
=\frac{1}{n}\cdot \sum_{k=1}^n \indicator{x_k\in I_j}$$

Получаем компактную запись для разности функций распределения
\begin{equation}\label{eq:cdfn_difference_final}
\cdfn{a_j}-\cdfn{a_{j-1}}
=\frac{1}{n}\cdot \sum_{k=1}^n \indicator{x_k\in I_j}
\end{equation}


Вернёмся к уравнению \eqref{eq:histogram_start}
$$
q_n\left(y\right)
=\sum_{j=1}^m \frac{\cdfn{a_j}-\cdfn{a_{j-1}}}{a_j-a_{j-1}}
    \cdot\indicator{y\in I_j}
    $$

Воспользовавшись тем,
что $\left(a_j-a_{j-1}\right)$ --- длина полуинтервала $I_j$,
а разность $\cdfn{a_j}-\cdfn{a_{j-1}}$ была только что переписана
через индикаторы, получаем такую формулу
$$q_n\left(y\right)=\sum_{j=1}^m\frac{1}{n}\sum_{k=1}^n
\indicator{x_k\in I_j}\cdot\frac{1}{\left|I_j\right|}
\cdot\indicator{y \in I_j}$$

Упростим, введя функцию $\nu_j\left(X\right)$ \cite[стр.~68]{BorovkovMS},
которая считает количество элементов выборки $X=x_1, \dots, x_n$,
попавших в интервал $I_j$.
Это будет сумма индикаторов того, что элемент $x_k$ попал в $I_j$

$$\nu_j\left(X\right)
=\sum_{x\in X} \indicator{x\in I_j}
=\sum_{k=1}^n \indicator{x_k\in I_j}$$

Поскольку $\indicator{y\in I_j}$ зависит от $j$ и не зависит от $k$,
то его можно перенести во внешнюю сумму. Получаем следующую формулу
$$q_n\left(y\right)
=\sum_{j=1}^m \frac{\indicator{y\in I_j}}{n\cdot\left|I_j\right|}
    \cdot\nu_j\left(X\right)$$

У этой суммы только один ненулевой элемент,
так как $y$ может попасть только в один полуинтервал.
Тогда обозначим номер отрезка, в который попал $y$, через $k$ ($y\in I_k$),
а функцию $q_n\left(y\right)$ запишем как $q_n^k$
\begin{equation}\label{eq:histogram_borovkov}
q_n^k=
    \frac{\nu_k\left(X\right)}{n\cdot\left|I_k\right|}
\end{equation}


Что мы тут видим? Теперь $k$ --- номер ``столбика'' гистограммы
(номер интересующего нас полуинтервала --- того, в который попал $y$).

``Высота'' столбика (значение функции на определённом полуинтервале)
пропорциональна количеству элементов, попавших в этот отрезок (что логично).
Кроме того, происходит деление на общее количество элементов. Деление нужно,
чтобы $q\left(y\right)$ сходилось к $\pdf{y}$.

Делителю же $\left|I_k\right|$ отведена особая роль --- он предотвращает
искажение гистограммы при различных длинах отрезков.
То есть, чем длиннее отрезок, тем ниже столбик,
так как элементы более ``размазаны'' по отрезку, что тоже логично.

Представим, что значение функции --- это высоту прямоугольника,
а длина отрезка --- его ширина (графически это изображается именно так).
Тогда отношение количества элементов, попавших в полуинтервал,
к количеству всех элементов выборки
(вероятность того,
что случайно взятый элемент из выборки
попадёт в $k$-ый отрезок \cite[стр.~24]{BorovkovMS}),
является площадью прямоугольника
$$S_k=\frac{\nu_k\left(X\right)}{n}=\probabilityn{x\in I_k}$$

Введём замену в формуле \eqref{eq:histogram_borovkov}
и умножим обе части на длину отрезка
$$\probabilityn{x\in I_k}=q_n^k\cdot\left|I_k\right|$$

Если устремить количество полуинтервалов к бесконечности ($m\to\infty$),
то каждый полуинтервал будет сжиматься в точку.
При этом вероятность попадения $x$ в отрезок будет стремиться
к вероятности попадения $x$ в точку $y$.
Введём обозначения $|I_j|=\delta$, $I_j=\Delta_y$
$$\probabilityn{x=y}
\approx\probabilityn{x\in\Delta_y}=q_n\left(y\right)\cdot\delta,
\qquad m\to\infty$$

Очень напоминает ситуацию с плотностью распределения
непрерывной случайной величины $\xi$
$$\probability{\xi=x}\approx\pdf{x}\cdot\delta,\qquad\delta\to 0$$

Нужно отметить,
что количество элементов выборки
должно стремиться к бесконечности ($n\to\infty$),
так как плотность может быть лишь у непрерывных случайных величин.
Чем больше будет элементов,
тем плотнее они будут стоять на числовой прямой.

\subsection{Оценка неизвестных параметров}
Снова у нас есть $x_1, \dots, x_n$ --- выборка из распределения $F_\theta$,
\index{неизвестный параметр}
где $\theta$ --- неизвестный параметр из множества $\Theta$

\begin{example}Имеем нормальное распределение с известным СКО $\sigma=1$
    и неизвестным математическим ожиданием $a$ --- $N\left(a,1\right)$.
    Тогда $\theta$ --- математическое ожидание $a$
\end{example}
\begin{example}
    Есть нормальное распределение, в котором неизвестны оба параметра.
    Тогда $\theta$ будет парой $(a,\sigma)$
\end{example}

Главный вопрос --- определение основных параметров распределения выборки.

\index{статистика}
\begin{definition}[Статистика]
Статистикой называют функцию $S$ от выборки $X=\left(x_1,x_2,\dots,x_n\right)$
    $$S\left(X\right)=S\left(x_1, x_2, \dots, x_n\right)$$
\end{definition}
\index{оценка}
\begin{definition}[Оценка]Статистику,
    значение которой заменяет неизвестный параметр,
    называют оценкой
\end{definition}
\begin{example}Предположим, что выборка сделана из распределения Бернулли,
    то есть $\left\{x_i\right\}$ --- набор одинаково распределённых
    случайных величин, причём
    \begin{align*}
    x_i=
    \begin{cases}
        1,&p\\
        0,&1-p
    \end{cases}
    \end{align*}

    Тогда неизвестный параметр --- величина $p$
    (вероятность удачного эксперимента)
    $$\theta=p\in\left[0;1\right]=\Theta$$

    Введём разные оценки $\hat{p}$
    \begin{align*}
        \hat{p}_1&=\frac{1}{n}\sum_{k=1}^n x_k\\
        \hat{p}_2&=x_1\\
        \hat{p}_3&=
            \frac{2}{n}\sum_{k=1}^{\left\lfloor \frac{n}{2} \right\rfloor} x_k
    \end{align*}
\end{example}
Замечание:
Поскольку $\hat{p}$ --- случайная величина, то может оказаться,
что она не равна настоящему параметру $p$
$$\Probability{\hat{p}=p}=0$$
\begin{enumerate}
    \item Возникает мысль о том, что разность $\hat{p}-p$
        должна быть ``маленькой''. Например, чтобы
        $\mean{\left(\hat{p}-p\right)}^2$ было самое маленькое из возможных.
    \item Также логично желать того,
        чтобы оценка $\hat{p}$ сходилась к истинному значению параметра $p$
        по вероятности ($\hat{p}\pcovergence p$)
        или почти всюду ($\hat{p}\acovergence p$)
    \item При многократном повторении эксперимента
        даже самая (на первый взгляд) плохая оценка может оказаться полезной
        \begin{align*}
            \mean{\hat{p}_1}=p\\
            \mean{\hat{p}_2}=p\\
            \mean{\hat{p}_3}=p
        \end{align*}
        Например, если целый год каждый день дают набор чисел,
        а статистик считает значение параметра $p$ с помощью оценки $\hat{p}$,
        то в среднем за год у него получится величина, близкая к истинному $p$.
\end{enumerate}

\index{оценка!состоятельная}
\begin{definition}[Состоятельная оценка]
    Оценка $\hat{\theta}$ называется состоятельной,
    если стремится к истинному значению $\theta$ по вероятности
    $$\hat{\theta}\pcovergence\theta$$
\end{definition}
\index{оценка!сильно состоятельная}
\begin{definition}[Сильно состоятельная оценка]
    Оценка $\hat{\theta}$ называется сильно состоятельной,
    если стремится к истинному значению $\theta$ почти наверное
    $$\hat{\theta}\acovergence\theta$$
\end{definition}
\begin{example}
    Оценка $\hat{p}_1$ из прошлого примера является сильно состоятельной.
\end{example}
\index{оценка!несмещённая}
\begin{definition}[Несмещённая оценка]
    Оценка $\hat{\theta}$ несмещённая, если
    $$\forall\theta\in\Theta: \meanof{\theta}{\hat{\theta}}=\theta$$
\end{definition}
\begin{remark}Несмещённая оценка существует не всегда
\end{remark}
\begin{definition}Несмещённая оценка $\hat{\theta}\in K$
называется оптимальной
в классе квадратично интегрируемых оценок $K$,
если для всякой другой несмещённой оценки $\tilde{\theta}\in K$
$$\dispersionof{\theta}{\hat{\theta}}\le\dispersionof{\theta}{\tilde{\theta}},
\qquad \forall\theta\in\Theta$$
или же
$$\meanof{\theta}{\left(\hat{\theta}-\theta\right)^2}
\le\meanof{\theta}{\left(\tilde{\theta}-\theta\right)^2},
\qquad \forall\theta\in\Theta$$
\end{definition}
\begin{remark}
    В учебнике Боровкова А. А. ``Математическая статистика'' 
    оценка, удовлетворяющая этим условиям,
    носит название \textbf{эффективная оценка} \cite[стр.~130]{BorovkovMS},
    но у нас этот термин будет использоваться далее в другом смысле
\end{remark}
\begin{example}Сравним $\hat{p}_1$ и $\hat{p}_3$
    \begin{align*}
    \dispersionof{p}{\hat{p}_1}
        &=\frac{1}{n^2}\cdot n\cdot p\cdot\left(1-p\right)
        =\frac{p\cdot\left(1-p\right)}{n}\\
    \dispersionof{p}{\hat{p}_3}
        &=\frac{2\cdot p\cdot\left(1-p\right)}{n}
    \end{align*}
\end{example}
\subsection{Выборочные оценки. Метод моментов}
Как восстановить неизвестный параметр $\theta\in\Theta$
из функции распределения $\cdfof{\theta}{x}$?

Вспомним распределения и их параметры
\begin{enumerate}
    \item Нормальное распределение $N\left(a,\sigma^2\right)$.
        В нём параметр $a$ является средним,
        а параметр $\sigma^2$ --- дисперсией
    \item Пуассоновское распределение $Poi\left(\lambda\right)$.
        Тут параметр $\lambda$ является и средним, и дисперсией
    \item Экспоненциальное распределение $Exp\left(\lambda\right)$.
        $\frac{1}{\lambda}$ --- среднее,
        $\frac{1}{\lambda^2}$ --- дисперсия
\end{enumerate}
И так далее\ldots

Как правило, неизвестный параметр $\theta$ можно искать следующим образом:
$$\exists\varphi\in C\left(\mathbb{R}\right):
    \int\limits_{\mathbb{R}}\varphi\left(x\right)d\cdfof{\theta}{x}
        =g\left(\theta\right)$$

Значит, у нас есть уравнение для поиска оценки $\hat{\theta}$
\begin{equation}\label{eq:unknown_parameter}
g\left(\hat{\theta}\right)
    =\int\limits_{\mathbb{R}}\varphi\left(x\right)d\cdfn{x}
\end{equation}

\begin{example} Если $\theta$ --- среднее, то $\varphi\left(x\right)=x$
$$\int\limits_{-\infty}^{+\infty}xd\cdfof{\theta}{x}
    =\theta=g\left(\theta\right)$$
\end{example}
\begin{theorem}Пусть функция $\varphi\left( x \right)$
    в \eqref{eq:unknown_parameter} ограничена и строго монотонная.
    Тогда оценка $\hat{\theta}$ существует и является сильно состоятельной.
\end{theorem}
\begin{proof}
    Имеем формулу \eqref{eq:unknown_parameter}
    $$g\left(\hat{\theta}\right)
            =\int\limits_{\mathbb{R}}\varphi\left(x\right)d\cdfn{x}$$

    Поскольку функция $g\left(\hat{\theta}\right)$ непрерывна и монотонна,
    то она имеет обратную функцию
    $g^{-1}:g^{-1}\left(g\left(\hat{\theta}\right)\right)=\hat{\theta}$.

    Применим обратную функцию к обеим частям уравнения
    $$\hat{\theta}
            =g^{-1}\left(
                \int\limits_{\mathbb{R}}\varphi\left(x\right)d\cdfn{x}\right)$$

    Поскольку выборочная функция распределения почти всюду равна
    неизвестной функции распределения при достаточно большом объёме выборки,
    то
    $$\int\limits_{\mathbb{R}}\varphi\left(x\right)d\cdfn{x}\acovergence
        \int\limits_{\mathbb{R}}\varphi\left(x\right)d\cdfn{x}$$

    Функция $g^{-1}\left(x\right)$ непрерывна
    $$\hat{\theta}
        =g^{-1}\left(
            \int\limits_{\mathbb{R}}\varphi\left(x\right)d\cdfn{x}\right)
        \acovergence g^{-1}\left(
            \int\limits_{\mathbb{R}}\varphi\left(x\right)d\cdfn{x}\right)
        =\theta$$
    Теорема доказана
    $$\hat{\theta}\acovergence\theta$$
\end{proof}
\index{выборочное среднее}
\begin{definition}[Выборочное среднее]
    Выборочное средние обозначается через $\overline{x}$
    и считается по следующей формуле
    $$\overline{x}=\int\limits_{\mathbb{R}}xd\cdfn{x}$$

    Поскольку все элементы выборки равновероятны,
    получаем математическое ожидание
    дискретной равномерно распределённой случайной величины,
    принимающей $n$ значений
    $$\overline{x}=\int\limits_{\mathbb{R}}xd\cdfn{x}
        =\frac{1}{n}\cdot\sum_{k=1}^n x_k$$
\end{definition}
\index{выборочная дисперсия}
\begin{definition}[Выборочная дисперсия]
    Выборочная дисперсия $\overline{\sigma^2}$
    считается формуле
    $$\overline{\sigma^2}
        =\int\limits_{\mathbb{R}}\left(x-\overline{x}\right)^2d\cdfn{x}
        =\frac{1}{n}\cdot\sum_{k=1}^n \left(x_k-\overline{x}\right)^2$$
\end{definition}
\section{Свойства оценок}
\subsection{Неравенство Рао-Крамера}
\begin{theorem}[Колмогорова]\index{теорема!Колмогорова}
    Оптимальная оценка единственная или её нет вообще
\end{theorem}
\begin{proof}
    Допустим,
    есть две разные оптимальные и несмещённые оценки $\theta_1$ и $\theta_2$.
    Тогда по определению для любой несмещённой оценки $\hat{\theta}$ будет
    \begin{align*}
        \begin{cases}
            \dispersionof{\theta}{\theta_1}
                \le\dispersionof{\theta}{\hat{\theta}}\\
            \dispersionof{\theta}{\theta_2}
                \le\dispersionof{\theta}{\hat{\theta}}
        \end{cases}
        ,\forall\theta\in\Theta
    \end{align*}

    Поскольку неравенство выполняется
    для каждой несмещённой оценки $\hat{\theta}$,
    а оценки $\theta_1$ и $\theta_2$ являются несмещёнными,
    то можем их и поставить в неравенство в роли $\hat{\theta}$

    \begin{align*}
        \begin{cases}
            \dispersionof{\theta}{\theta_1}
                \le\dispersionof{\theta}{\theta_2}\\
            \dispersionof{\theta}{\theta_2}
                \le\dispersionof{\theta}{\theta_1}
        \end{cases}
        ,\forall\theta\in\Theta
    \end{align*}

    А это возможно только если дисперсии этих оценок равны.
    Обозначим эту дисперсию через $\sigma^2\left(\theta\right)$

    $$\dispersionof{\theta}{\theta_1}
        =\dispersionof{\theta}{\theta_2}
        =\sigma^2\left(\theta\right)$$

    Возьмём несмещённую оценку $\tilde{\theta}$,
    равную среднеарифметическому оценок $\theta_1$ и $\theta_2$
    $$\tilde{\theta}=\frac{1}{2}\cdot\theta_1+\frac{1}{2}\cdot\theta_2$$

    Тогда по определению $\theta_1$ и $\theta_2$ получаем,
    что дисперсия новой оценки не меньше, чем у оптимальных
    \begin{equation}\label{eq:estimator_ge}
        \dispersionof{\theta}{\tilde{\theta}}\ge\sigma^2\left(\theta\right)
    \end{equation}

    Попробуем честно вычислить дисперсию оценки $\tilde{\theta}$
    \begin{align*}
    \dispersionof{\theta}{\tilde{\theta}}
        &=\meanof{\theta}{\left( \tilde{\theta}-\theta \right)}
        =\meanof{\theta}{\left[ \frac{1}{2}\cdot\left( \theta_1-\theta \right)
            +\frac{1}{2}\cdot\left( \theta_2-\theta \right) \right]^2}=\\
        &=\frac{1}{4}\cdot\dispersionof{\theta}{\theta_1}
            +\frac{1}{4}\cdot\dispersionof{\theta}{\theta_1}
            +\frac{1}{2}\cdot\meanof{\theta}
                {\left[ \left( \theta_1-\theta \right)
                    \cdot\left( \theta_2-\theta \right) \right]}
    \end{align*}

    Воспользуемся неравенством Коши (частный случай неравенства Гёльдера)
    \begin{eqnarray}\label{eq:koshi_eq}
        \meanof{\theta}{\left[ \left( \theta_1-\theta \right)
            \cdot\left( \theta_2-\theta \right) \right]}
        \le\sqrt{\meanof{\theta}{\left( \theta_1-\theta \right)^2}
            \cdot\meanof{\theta}{\left( \theta_2-\theta \right)^2}}=\\
        =\sqrt{\dispersionof{\theta}{\theta_1}
            \cdot\dispersionof{\theta}{\theta_2}}
        =\sqrt{\sigma_1^2\cdot\sigma_2^2}\nonumber
    \end{eqnarray}

    \begin{align*}
        \frac{1}{4}\cdot\dispersionof{\theta}{\theta_1}
            +\frac{1}{4}\cdot\dispersionof{\theta}{\theta_1}
            +\frac{1}{2}\cdot\meanof{\theta}
                {\left[ \left( \theta_1-\theta \right)
                    \cdot\left( \theta_2-\theta \right) \right]}\le\\
        \le\frac{1}{2}\cdot\sigma^2\left( \theta \right)
            +\frac{1}{2}\cdot\sqrt{\sigma^2\left( \theta \right)
                \cdot\sigma^2\left( \theta \right)}
        =\sigma^2\left( \theta \right)
    \end{align*}

    То есть, дисперсия оценки $\tilde{\theta}$ не больше дисперсии
    введённой оптимальной оценки
    \begin{equation}\label{eq:estimator_le}
        \dispersionof{\theta}{\tilde{\theta}}\le\sigma^2\left(\theta\right)
    \end{equation}

    Воспользовавшись неравенствами
    \eqref{eq:estimator_ge} и \eqref{eq:estimator_le}, получаем равенство
    $$\dispersionof{\theta}{\tilde{\theta}}=\sigma^2\left(\theta\right)$$

    Это значит, что в неравенстве \eqref{eq:koshi_eq}
    в данном случае тоже выходит равенство
    $$\meanof{\theta}{\left[ \left( \theta_1-\theta \right)
            \cdot\left( \theta_2-\theta \right) \right]}
        =\sqrt{\meanof{\theta}{\left( \theta_1-\theta \right)^2}}
            \cdot\sqrt{\meanof{\theta}{\left( \theta_2-\theta \right)^2}}$$

    Для дальнейших размышлений вспомним аналогию с векторами.
    $$\vec{a}\cdot\vec{b}
        =\left|\vec{a}\right|\cdot\left|\vec{b}\right|
            \cdot\cos{\left(\widehat{\vec{a},\vec{b}}\right)}
        =\sqrt{\vec{a}^2}\cdot\sqrt{\vec{b}^2}
            \cdot\cos{\left(\widehat{\vec{a},\vec{b}}\right)}$$

    Скалярное произведение двух векторов равно произведению их модулей
    только тогда, когда они сонаправлены
    $$\left(\widehat{\vec{a},\vec{b}}\right)=0
        \Rightarrow \vec{a}\cdot\vec{b}
        =\sqrt{\vec{a}^2}\cdot\sqrt{\vec{b}^2}$$

    Положим математическое ожидание нормой,
    а $\theta_1-\theta$ и $\theta_2-\theta$ векторами
    пространства случайных событий.
    Получаем, что нормы и направление этих векторов совпадает,

    \begin{align*}
        &\meanof{\theta}{\left[ \left( \theta_1-\theta \right)
            \cdot\left( \theta_2-\theta \right) \right]}
        =\sqrt{\meanof{\theta}{\left( \theta_1-\theta \right)^2}}
            \cdot\sqrt{\meanof{\theta}{\left( \theta_2-\theta \right)^2}}\\
        &\Rightarrow\left(\widehat{\theta_1-\theta,\theta_2-\theta}\right)\\
        \end{align*}
    Это значит, что они равны,
    что противоречит предположению о том, что они разные. Теорема доказана
    \begin{align*}
        \begin{cases}
            \left(\widehat{\theta_1-\theta,\theta_2-\theta}\right)=0\\
            \meanof{\theta}{\left( \theta_1-\theta \right)^2}
                =\meanof{\theta}{\left( \theta_2-\theta \right)^2}
        \end{cases}
        \Rightarrow \theta_1-\theta=\theta_2-\theta\\
        \Rightarrow\theta_1=\theta_2
    \end{align*}

\end{proof}

Для дальнейших действий будем считать,
что функция распределения $\cdfof{\theta}{x}$ имеет плотность $\pdf{x,\theta}$,
которая дважды дифференцируема по $\theta$.
То есть, дифференцируема так,
что её можно дифференцировать под знаком интеграла.

В таком случае выбора $\left( x_1, \dots, x_n \right)$
имеет плотность распределения,
так как является случайным вектором в $\mathbb{R}^n$.

Плотность распределения вектора независимых случайных величин
равна произведению плотностей распределения его компонент.

\begin{definition}[Функция правдоподобия]\index{функция!правдобия}
    $$L\left( \vec{x},\theta \right)=\prod_{k=1}^n\pdf{x_k,\theta}$$
\end{definition}

Прологорифмировав функцию правдоподобия, получим симпатичную сумму
$$\ln{L\left( \vec{x},\theta \right)}=\sum_{k=1}^n\ln{\pdf{x_k,\theta}}$$

А симпатична она тем,
что это сумма незасимых одинаково распределённых случайных величин.
Воспользовавшись законом больших чисел, можем сказать,
что она стремится к сумме $n$ одинаковых математических ожиданий
при достаточно большом размере выборки
\begin{align*}
    \ln{L\left( \vec{x},\theta \right)}
        &=n\cdot\frac{\ln{\pdf{x_1,\theta}}+\dots+\ln{\pdf{x_n,\theta}}}
            {n}\approx\\
        &\approx n\cdot\meanof{\theta}{\left[\ln{\pdf{x_1,\theta}}\right]}
\end{align*}

Проблема в том, что мы не знаем среднего.
Для разрешения этого вопроса введём ещё одно определение

\begin{definition}[Вклад выборки]\index{вклад выборки}
    Ваклад выборки --- частная производная по параметру $\theta$
    от логарифма функции правдоподобия
    \begin{align*}
        U\left( \vec{x},\theta \right)
            =\frac{\partial}{\partial\theta}\ln{L\left(\vec{x},\theta\right)}
            &=\sum_{k=1}^n
                \frac{\partial}{\partial\theta}\cdot\ln{\pdf{x_k,\theta}}\\
            &=\frac{\frac{\partial}{\partial\theta}L\left(\vec{x},\theta\right)}
                {L\left(\vec{x},\theta\right)}
    \end{align*}
\end{definition}

\begin{remark}
     Математическое ожидание вклада выборки равно нулю
    $$\meanof{\theta}{U\left( \vec{x},\theta \right)}=0$$
\end{remark}
\begin{proof}
Посчитаем математическое ожидание вклада выборки

\begin{align*}
    \meanof{\theta}{U\left( \vec{x},\theta \right)}
        &=\integral{\mathbb{R}^n}{}{\vec{u}}
            {U\left( \vec{u},\theta \right)
                \cdot L\left( \vec{u},\theta \right)}=\\
        &=\integral{\mathbb{R}^n}{}{\vec{u}}
            {\frac{\frac{\partial}{\partial\theta}L\left(\vec{x},\theta\right)}
                {L\left(\vec{x},\theta\right)}
                \cdot L\left( \vec{u},\theta \right)}=\\
        &=\integral{\mathbb{R}^n}{}{\vec{u}}
            {\frac{\partial}{\partial\theta}
                L\left( \vec{u},\theta \right)}
\end{align*}

Воспользовавшись предположением о том,
что функция распределения дважды дифференцируема,
вынесем взятие производной за знак интеграла
\begin{align*}
    \meanof{\theta}{U\left( \vec{x},\theta \right)}
        &=\frac{\partial}{\partial\theta}
            \integral{\mathbb{R}^n}{}{\vec{u}}{L\left( \vec{u},\theta \right)}
\end{align*}

Поскольку интегрируем плотность распределения случайного вектора
по всему пространству, то он равен единице.
Производная же от единице равна нулю.
Это значит, что математическое ожидание вклада выборки равно нулю
\begin{align*}
    \meanof{\theta}{U\left( \vec{x},\theta \right)}
        &=\frac{\partial}{\partial\theta}
            \integral{\mathbb{R}^n}{}{\vec{u}}{L\left( \vec{u},\theta \right)}
        =\frac{\partial}{\partial\theta}1
        =0
\end{align*}
\end{proof}
\begin{remark}
    Частная производная по оценке $\theta$ от функции правдоподобия
    $L\left( \vec{u},\theta \right)$ равна нулю.
\end{remark}
\begin{proof}
    Выше у нас было равенство
    $$\frac{\partial}{\partial\theta}
        \integral{\mathbb{R}^n}{}{\vec{u}}{L\left( \vec{u},\theta \right)}=0$$

    Так как производную можем заносить под знак интеграла
    (согласно нашему предположению), то получаем такое равенство
    $$\integral{\mathbb{R}^n}{}{\vec{u}}{
        \frac{\partial}{\partial\theta}L\left( \vec{u},\theta \right)}=0$$

    Поскольку интеграл не зависит от $\theta$,
    то такое возможно лишь в том случае, когда производная равна нулю
    $$\frac{\partial}{\partial\theta}L\left( \vec{u},\theta \right)=0$$
\end{proof}
\begin{definition}[Количество информации Фишера]
    \index{количество информации Фишера}
    Математическое ожидание квадрата вклада выборки называется
    количеством информации Фишера
    $$I_n\left(\theta\right)=
        \meanof{\theta}{U\left( \vec{x},\theta \right)^2}$$
\end{definition}
\begin{remark}
    $$\meanof{\theta}{U\left( \vec{x},\theta \right)^2}
        =-\meanof{\theta}{
            \frac{\partial^2}{\partial\theta^2}
            \ln{L\left( \vec{x},\theta \right)}}$$
\end{remark}
\begin{proof}
    Будем доказывать справа налево
    \begin{align*}
        -\meanof{\theta}{
            \frac{\partial^2}{\partial\theta^2}
            \ln{L\left( \vec{x},\theta \right)}}=
        -\meanof{\theta}{
            \frac{\partial}{\partial\theta}
            \frac{\frac{\partial}{\partial\theta}L\left(\vec{x},\theta\right)}
                {L\left(\vec{x},\theta\right)}}=\\
        =-\meanof{\theta}{
            \left(
            \frac{\frac{\partial^2}{\partial\theta^2}
                L\left(\vec{x},\theta\right)\cdot L\left(\vec{x},\theta\right)-
                    \left[\frac{\partial}{\partial\theta}
                        L\left(\vec{x},\theta\right)\right]^2
                }
                {L\left(\vec{x},\theta\right)^2}
                \right)}=\\
        =-\meanof{\theta}{
            \frac{\frac{\partial^2}{\partial\theta^2}
                L\left(\vec{x},\theta\right)}
                {L\left(\vec{x},\theta\right)}}
            +\meanof{\theta}{
                \left[\frac{\frac{\partial}{\partial\theta}
                    L\left(\vec{x},\theta\right)}
                    {L\left(\vec{x},\theta\right)}\right]^2}
    \end{align*}
    
    Помним, что производная от функции правдоподобия по $\theta$ равна нулю.
    Значит вторая производная тоже равна нулю
    и остаётся лишь математическое ожидание квадрата,
    который равен квадрату производной логарифма функции правдоподобия,
    что в свою очередь и есть вклад выборки
    \begin{align*}
        \frac{\partial}{\partial\theta}L\left( \vec{u},\theta \right)=0
        \Rightarrow
            -\meanof{\theta}{
            \frac{\frac{\partial^2}{\partial\theta^2}
                L\left(\vec{x},\theta\right)}
                {L\left(\vec{x},\theta\right)}}=0\\
        \Rightarrow
            -\meanof{\theta}{
            \frac{\partial^2}{\partial\theta^2}
            \ln{L\left( \vec{x},\theta \right)}}
            =\meanof{\theta}{
                \left[\frac{\frac{\partial}{\partial\theta}
                    L\left(\vec{x},\theta\right)}
                    {L\left(\vec{x},\theta\right)}\right]^2}=\\
            =\meanof{\theta}{\left[
            \frac{\partial}{\partial\theta}
            \ln{L\left( \vec{x},\theta \right)}\right]^2}
            =\meanof{\theta}{U\left( \vec{x},\theta \right)^2}
    \end{align*}

    Утверждение доказано
    $$\meanof{\theta}{U\left( \vec{x},\theta \right)^2}
        =-\meanof{\theta}{
            \frac{\partial^2}{\partial\theta^2}
            \ln{L\left( \vec{x},\theta \right)}}$$
\end{proof}
