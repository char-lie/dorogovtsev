\chapter{Основы}
\section{Методы оценок характеристик распределения
    наблюдаемых случайных величин}
$x_1, \dots, x_n$ --- независимые одинаково распределённые случайные величины
с неизвестной функцией распределения $F$.
\index{функция распределения!неизвестная}
Логично, что вероятность выпадения каждого $x_k$
(вероятность того, что наугад взятый из выборки $x$ будет равен $x_k$)
одинакова
$$P(x=x_k)=\frac{1}{n}$$

Цель --- найти $F$ или сказать что-то о её свойствах.

\subsection{Эмпирическая функция распределения}
\index{функция распределения!эмпирическая}
\index{функция распределения!выборочная}
\begin{definition}[Эмпирическая функция распределения]
    Эмпирической (выборочной) функцией распределения,
    построенной по выборке $x_1, \dots, x_n$ называется функция
    $$\cdfn{x}=\frac{1}{n}\cdot \sum_{k=1}^n
    \indicator{x_k\le x}$$
\end{definition}

\begin{theorem}Неизвестная функция распределения $\cdf{x}$ может быть сколь
    угодно точно восстановлена по выборке достаточно большого объёма
    \cite[стр.~25]{BorovkovMS}.
    $$\probability{\cdfn{x}\dCovergence \cdf{x}}=1$$
\end{theorem}
\begin{proof}
Вспомним, чему равна эмпирическая функция распределения
$$\cdfn{x}=\frac{1}{n}\cdot \sum_{k=1}^n
\indicator{x_k\le x}$$

Заметим, что индикаторы $\indicator{x_k\le x}$
являются независимыми одинаково распределёнными случайными величинами,
а функцию распределения $\cdf{x}$ можно записать следующим образом
$$\cdf{x}=\Probability{x_1\le x}=\mean{\indicator{x_1\le x}}$$

Так как эмпирическая функция распределения является
средним арифметическим индикаторов, то по усиленному закону больших чисел
она сходится к неизвестной функции распределения почти наверное
при устремлении длины выборки к бесконечности
$$\cdfn{x}=\frac{1}{n}\cdot\sum_{k=1}^n\indicator{x_k\le x}
\acovergence\mean{\indicator{x_1}}=\cdf{x}$$

Теорема доказана
$$\cdfn{x}\aCovergence\cdf{x}$$
\end{proof}

\subsection{Гистограмма}
Как можно попытаться отследить плотность распределения?
Постараемся найти функцию распределения, а потом и плотность.

Допустим, $F$ имеет хорошую (непрерывную) плотность.
Как тогда из $F$ получить $p$?

Мы знаем, что $F'=p$, но это никому не нужно, так как $F_n'$ --- производная
ступенчатой функции, которая почти везде будет равна нулю.

Но также мы помним, что
$$\cdf{b}-\cdf{a}=\int\limits_a^b \pdf{x} dx$$

Положим $a=x$ и введём $\Delta_x=b-x$
$$\cdf{x+\Delta_x}-\cdf{x}=\int\limits_x^{x+\Delta} \pdf{y} dy$$

Делим обе части на $\Delta_x$.
$$\frac{1}{\Delta_x}\cdot\int\limits_x^{x+\Delta_x} \pdf{y} dy
=\frac{\cdf{x+\Delta_x}-\cdf{x}}{\Delta_x}$$

Несложно заметить,
что при достаточно малых значениях $\Delta_x$
получаем плотность распределения $\pdf{x}$
$$\frac{\Delta\cdf{x}}{\Delta_x}
\xrightarrow[]{\Delta_x\to 0}
\frac{d\cdf{x}}{dx}=\pdf{x}$$

Значит, можем заменить $\pdf{x}$ не производной, а такой разностью.
$$\pdf{x}\approx\frac{\cdf{x+\Delta}-\cdf{x}}{\Delta}$$

Возьмём выборку из $m$ случайных величин в порядке возрастания
$a_1, \dots, a_m$, обозначим отрезки $I_j=[a_{j-1},a_j]$
и введём функцию $q\left(y\right)$
$$q\left(y\right)
=\sum_{j=1}^m \frac{\cdf{a_j}-\cdf{a_{j-1}}}{a_j-a_{j-1}}
    \cdot\indicator{y\in I_j}$$

Теперь введём последовательность функций $q_n\left(y\right)$ и видим,
что она сходится к $q_n\left(y\right)$ почти наверное
согласно закону больших чисел,
а та в свою очередь имеет сходимость порядка $\frac{1}{n}$
к плотности распределения $\pdf{y}$
\begin{equation}\label{eq:histogram_start}
q_n\left(y\right)
=\sum_{j=1}^m \frac{\cdfn{a_j}-\cdfn{a_{j-1}}}{a_j-a_{j-1}}
    \cdot\indicator{y\in I_j}
\end{equation}

Отметим, что $q_n$ сходится к $q$ почти наверное, а $q$ в свою очередь
сходится к $p$
$$q_n\left(y\right)\acovergence q\left(y\right)\covergencen{m}{}\pdf{y}$$

Функция $q_n$ называется \textbf{гистограммой}.
\index{гистограмма}

Избавимся от $a_j$ в формуле, а для этого вспомним, чему равно $\cdfn{x}$
$$\cdfn{x}=\frac{1}{n}\cdot \sum_{k=1}^n
\indicator{x_k\le x}$$

Теперь посмотрим, чему равна разность $\cdfn{a_j}-\cdfn{a_{j-1}}$,
которая, как мы видим, является вероятностью того,
что $x$ попало в отрезок $I_j$
$$\cdfn{a_j}-\cdfn{a_{j-1}}
    =\frac{1}{n}\cdot \sum_{k=1}^n
    \indicator{x_k\le a_j}-\frac{1}{n}\cdot \sum_{k=1}^n
    \indicator{x_k\le a_{j-1}}$$

Сгруппируем слагаемые и получим чуть более компактную запись разности
\begin{equation}\label{eq:cdfn_difference}
    \cdfn{a_j}-\cdfn{a_{j-1}}=\frac{1}{n}\cdot \sum_{k=1}^n
    \left[\indicator{x_k\le a_j}-\indicator{x_k\le a_{j-1}}\right]
\end{equation}

Рассмотрим возможные значения индикаторов

Если оба индикатора равны единице,
это значит, что $x_k$ не больше $a_j$ и не больше $a_{j-1}$.
Поскольку $a_{j-1}\le a_j$, то можно обойтись тем, что $x\le a_{j-1}$
\begin{align*}
    \begin{cases}
        \indicator{x_k\le a_j}=1\\
        \indicator{x_k\le a_{j-1}}=1\\
        a_{j-1}\le a_j
    \end{cases}
    \Rightarrow
    \begin{cases}
        x_k\le a_j\\
        x_k\le a_{j-1}\\
        a_{j-1}\le a_j
    \end{cases}
    \Rightarrow
        x_k\le a_{j-1}\le a_j
    \Rightarrow
        x_k\le a_{j-1}
\end{align*}

Такая ситуация,
что $x$ больше, чем $a_j$, но не больше, чем $a_{j-1}$, невозможна,
так как $a_{j-1}$ не больше, чем $a_j$,
а признать возможной такое положение дел ($a_j<x_k\le a_{j-1}$)
означало бы то, что $a_j<a_{j-1}$
\begin{align*}
    \begin{cases}
        \indicator{x_k\le a_j}=0\\
        \indicator{x_k\le a_{j-1}}=1\\
        a_{j-1}\le a_j
    \end{cases}
    \Rightarrow
    \begin{cases}
        x_k>a_j\\
        x_k\le a_{j-1}\\
        a_{j-1}\le a_j
    \end{cases}
    \Rightarrow
    \begin{cases}
        a_j<x_k\le a_{j-1}\\
        a_{j-1}\le a_j
    \end{cases}
\end{align*}


Если оба индикатора равны нулю,
то это значит, что $x$ строго больше как $a_j$, так и $a_{j-1}$.
Опять же, поскольку $a_{j-1}\le a_j$, то достаточно сказать, что $x>a_j$.
\begin{align*}
    \begin{cases}
        \indicator{x_k\le a_j}=0\\
        \indicator{x_k\le a_{j-1}}=0\\
        a_{j-1}\le a_j
    \end{cases}
    \Rightarrow
    \begin{cases}
        x_k>a_j\\
        x_k>a_{j-1}\\
        a_j\ge a_{j-1}
    \end{cases}
    \Rightarrow
        x_k>a_j\ge a_{j-1}
    \Rightarrow
        x_k>a_j
\end{align*}

Если же $x$ больше, чем $a_{j-1}$, но не больше, чем $a_j$,
то $x$ попадает в полуинтервал $\left(a_{j-1},a_j\right]$
\begin{align*}
    \begin{cases}
        \indicator{x_k\le a_j}=1\\
        \indicator{x_k\le a_{j-1}}=0\\
        a_{j-1}\le a_j
    \end{cases}
    \Rightarrow
    \begin{cases}
        x_k\le a_j\\
        x_k>a_{j-1}\\
        a_j\ge a_{j-1}
    \end{cases}
    \Rightarrow
        a_{j-1}<x_k\le a_j
\end{align*}

Вспомним формулу \eqref{eq:cdfn_difference}
$$\cdfn{a_j}-\cdfn{a_{j-1}}
=\frac{1}{n}\cdot \sum_{k=1}^n
    \left[\indicator{x_k\le a_j}-\indicator{x_k\le a_{j-1}}\right]$$

Очевидно, что нас интересуют те пары, разность которых не равна нулю.
Это значит, что те случаи, когда $x>a_j$ или $x\le a_{j-1}$, нас не интересуют.
Поскольку такой случай, что $a_j<x\le a_{j-1}$ невозможен, то его тоже отбросим.
Значит, остался только тот вариант,
когда $x$ попадает в полуинтервал $\left(a_{j-1},a_j\right]$
$$\frac{1}{n}\cdot \sum_{k=1}^n
        \left[\indicator{x_k\le a_j}-\indicator{x_k\le a_{j-1}}\right]
    =\frac{1}{n}\cdot \sum_{k=1}^n \indicator{x_k\in \left(a_{j-1},a_j\right]}
$$

Пренебрегаем тем, что у нас полуинтервал, и будем считать,
что вероятность попадения $x$ чётко на границу интервала пренебрежимо мала
и заменим индикатор на более удобный.
$$\frac{1}{n}\cdot \sum_{k=1}^n \indicator{x_k\in \left(a_{j-1},a_j\right]}
=\frac{1}{n}\cdot \sum_{k=1}^n \indicator{x_k\in I_j}$$

Получаем компактную запись для разности функций распределения
\begin{equation}\label{eq:cdfn_difference_final}
\cdfn{a_j}-\cdfn{a_{j-1}}
=\frac{1}{n}\cdot \sum_{k=1}^n \indicator{x_k\in I_j}
\end{equation}


Вернёмся к уравнению \eqref{eq:histogram_start}
$$
q_n\left(y\right)
=\sum_{j=1}^m \frac{\cdfn{a_j}-\cdfn{a_{j-1}}}{a_j-a_{j-1}}
    \cdot\indicator{y\in I_j}
    $$

Воспользовавшись тем, что $\left(a_j-a_{j-1}\right)$ --- длина отрезка $I_j$,
а разность $\cdfn{a_j}-\cdfn{a_{j-1}}$ была только что компактизирована,
получаем такую формулу
$$q_n\left(y\right)=\sum_{j=1}^m\frac{1}{n}\sum_{k=1}^n
\indicator{x_k\in I_j}\cdot\frac{1}{\left|I_j\right|}
\cdot\indicator{y \in I_j}$$

Упростим формулу.
Введём функцию $\nu_j\left(X\right)$ \cite[стр.~68]{BorovkovMS},
которая считает количество элементов выборки $X=x_1, \dots, x_n$,
попавших в интервал $I_j$.
Это будет сумма индикаторов того, что элемент $x_k$ попал в интервал $I_j$

$$\nu_j\left(X\right)
=\sum_{x\in X} \indicator{x\in I_j}
=\sum_{k=1}^n \indicator{x_k\in I_j}$$

Поскольку $\indicator{y\in I_j}$ зависит от $j$ и не зависит от $k$,
то его можно перенести во внешнюю сумму. Получаем следующую формулу
$$q_n\left(y\right)
=\sum_{j=1}^m \frac{\indicator{y\in I_j}}{n\cdot\left|I_j\right|}
    \cdot\nu_j\left(X\right)$$

У этой суммы только один ненулевой элемент,
так как $y$ может попасть только в один отрезок
(пренебрегаем возможностью его попадания на границу между двумя отрезками).
Тогда обозначим номер отрезка, в который попал $y$, как $k$,
а функцию $q_n\left(y\right)$ как $q_n^k$
\begin{equation}\label{eq:histogram_borovkov}
q_n^k=
    \frac{\nu_k\left(X\right)}{n\cdot\left|I_k\right|}
\end{equation}


Что мы тут видим? Теперь $k$ --- номер ``столбика'' гистограммы
(номер интересующего нас отрезка --- номер отрезка, в который попал $y$).

``Высота'' столбика (значение функции на определённом отрезке)
пропорциональна количеству элементов, попавших в этот отрезок (что логично).
Кроме того, происходит деление на общее количество элементов,
которое возникло, чтобы $q\left(y\right)$ сходилось к $\pdf{y}$.

Делителю же $\left|I_k\right|$ отведена особая роль --- он предотвращает
искажение гистограммы при различных длинах отрезков.
Получается, что, чем длиннее отрезок, тем ниже столбик,
так как элементы более ``размазаны'' по отрезку --- тоже логично.

Если рассматривать значение функции как высоту прямоугольника,
а длину отрезка как его ширину (графически это изображается именно так),
то оказывается, что отношение количества элементов, попавших в отрезок,
к количеству всех элементов выборки
(вероятность того,
что случайно взятый элемент из выборки
попадёт в $k$-ый отрезок \cite[стр.~24]{BorovkovMS})
яется площадью прямоугольника
$$S_k=\frac{\nu_k\left(X\right)}{n}=\probabilityn{x\in I_k}$$

Введём замену в формуле \eqref{eq:histogram_borovkov}
и умножим обе части на длину отрезка
$$\probabilityn{x\in I_k}=q_n^k\cdot\left|I_k\right|$$

Если устремить количество отрезков к бесконечности ($m\to\infty$),
то каждый отрезок будет сжиматься в точку.
При этом вероятность попадения $x$ в отрезок будет стремиться
к вероятности попадения $x$ в точку $y$.
Введём обозначения $|I_j|=\delta$, $I_j=\Delta_y$
$$\probabilityn{x=y}
\approx\probabilityn{x\in\Delta_y}=q_n\left(y\right)\cdot\delta,
\qquad m\to\infty$$

Очень напоминает ситуацию с плотностью распределения
непрерывной случайной величины $\xi$
$$\probability{\xi=x}\approx\pdf{x}\cdot\delta,\qquad\delta\to 0$$

Нужно отметить,
что количество элементов выборки
должно стремиться к бесконечности ($n\to\infty$),
так как плотность может быть лишь у непрерывных случайных величин.
Чем больше будет элементов,
тем плотнее они будут стоять на числовой прямой.

\subsection{Оценка неизвестных параметров}
Снова у нас есть $x_1, \dots, x_n$ --- выборка из распределения $F_\theta$,
\index{неизвестный параметр}
где $\theta$ --- неизвестный параметр из множества $\Theta$

\begin{example}Имеем нормальное распределение с известным СКО $\sigma=1$
    и неизвестным математическим ожиданием $a$ --- $N\left(a,1\right)$.
    Тогда $\theta$ --- математическое ожидание $a$
\end{example}
\begin{example}
    Есть нормальное распределение, в котором неизвестны оба параметра.
    Тогда $\theta$ будет парой $(a,\sigma)$
\end{example}

Главный вопрос --- определение основных параметров распределения выборки.

\index{оценка}
\begin{definition}[Оценка]Функцию от выборки,
    значение которой заменяет неизвестный параметр,
    называют оценкой
\end{definition}
\begin{example}Предположим, что выборка сделана из распределения Бернулли,
    то есть $\left\{x_i\right\}$ --- набор одинаково распределённых
    случайных величин, причём
    \begin{align*}
    x_i=
    \begin{cases}
        1,&p\\
        0,&1-p
    \end{cases}
    \end{align*}

    Тогда неизвестный параметр --- величина $p$
    (вероятность удачного эксперимента)
    $$\theta=p\in\left[0;1\right]=\Theta$$

    Введём разные оценки $\hat{p}$
    \begin{align*}
        \hat{p}_1&=\frac{1}{n}\sum_{k=1}^n x_k\\
        \hat{p}_2&=x_1\\
        \hat{p}_3&=
            \frac{2}{n}\sum_{k=1}^{\left\lfloor \frac{n}{2} \right\rfloor} x_k
    \end{align*}
\end{example}
Замечание:
Поскольку $\hat{p}$ --- случайная величина, то может оказаться,
что она не равна настоящему параметру $p$
$$\Probability{\hat{p}=p}=0$$
\begin{enumerate}
    \item Возникает мысль о том, что разность $\hat{p}-p$
        должна быть ``маленькой''. Например, чтобы
        $\mean{\left(\hat{p}-p\right)}^2$ было самое маленькое из возможных.
    \item Также логично желать того,
        чтобы оценка $\hat{p}$ сходилась к истинному значению параметра $p$
        по вероятности ($\hat{p}\pcovergence p$)
        или почти всюду ($\hat{p}\acovergence p$)
    \item При многократном повторении эксперимента
        даже самая (на первый взгляд) плохая оценка может оказаться полезной
        \begin{align*}
            \mean{\hat{p_1}}=p\\
            \mean{\hat{p_2}}=p\\
            \mean{\hat{p_3}}=p
        \end{align*}
        Например, если целый год каждый день дают набор чисел,
        а статистик считает значение параметра $p$ с помощью оценки $\hat{p}$,
        то в среднем за год у него получится величина, близкая к истинному $p$.
\end{enumerate}

\index{оценка!состоятельная}
\begin{definition}[Состоятельная оценка]
    Оценка $\hat{\theta}$ называется состоятельной,
    если стремится к истинному значению $\theta$ по вероятности
    $$\hat{\theta}\pcovergence\theta$$
\end{definition}
\index{оценка!сильно состоятельная}
\begin{definition}[Сильно состоятельная оценка]
    Оценка $\hat{\theta}$ называется сильно состоятельной,
    если стремится к истинному значению $\theta$ почти наверное
    $$\hat{\theta}\acovergence\theta$$
\end{definition}
\begin{example}
    Оценка $\hat{p_1}$ из прошлого примера является сильно состоятельной.
\end{example}
\index{оценка!несмещённая}
\begin{definition}[Несмещённая оценка]
    Оценка $\hat{\theta}$ несмещённая, если
    $$\forall\theta\in\Theta: \meanof{\theta}{\hat{\theta}}=\theta$$
\end{definition}
\begin{remark}Несмещённая оценка существует не всегда
\end{remark}
\begin{definition}Несмещённая оценка $\hat{\theta}\in K$
называется оптимальной (эффективной \cite[стр.~130]{BorovkovMS})
в классе квадратично интегрируемых оценок $K$,
если для всякой другой несмещённой оценки $\tilde{\theta}\in K$
$$\dispersionof{\theta}{\hat{\theta}}\le\dispersionof{\theta}{\tilde{\theta}},
\qquad \forall\theta\in\Theta$$
или же
$$\meanof{\theta}{\left(\hat{\theta}-\theta\right)^2}
\le\meanof{\theta}{\left(\tilde{\theta}-\theta\right)^2},
\qquad \forall\theta\in\Theta$$
\end{definition}
\begin{example}Сравним $\hat{p_1}$ и $\hat{p_3}$
    \begin{align*}
    \dispersionof{p}{\hat{p_1}}
        &=\frac{1}{n^2}\cdot n\cdot p\cdot\left(1-p\right)
        =\frac{p\cdot\left(1-p\right)}{n}\\
    \dispersionof{p}{\hat{p_3}}
        &=\frac{2\cdot p\cdot\left(1-p\right)}{n}
    \end{align*}
\end{example}
\subsection{Выборочные оценки. Метод моментов}
Как восстановить неизвестный параметр $\theta\in\Theta$,
имея и так далее функцию распределения $\cdfof{\theta}{x}$?

Вспомним распределения и их параметры
\begin{enumerate}
    \item Нормальное распределение $N\left(a,\sigma^2\right)$.
        В нём параметр $a$ является средним,
        а параметр $\sigma^2$ --- дисперсией
    \item Пуассоновское распределение $Poi\left(\lambda\right)$.
        Тут параметр $\lambda$ является и средним, и дисперсией
    \item Экспоненциальное распределение $Exp\left(\lambda\right)$.
        $\frac{1}{\lambda}$ --- среднее,
        $\frac{1}{\lambda^2}$ --- дисперсия
\end{enumerate}
И так далее\ldots

Как правило, неизвестный параметр $\theta$ можно искать следующим образом:
$$\exists\varphi\in C\left(\mathbb{R}\right):
    \int\limits_{\mathbb{R}}\varphi\left(x\right)d\cdfof{\theta}{x}
        =g\left(\theta\right)$$

Значит, у нас есть уравнение для поиска оценки $\hat{\theta}$
\begin{equation}\label{eq:unknown_parameter}
g\left(\hat{\theta}\right)
    =\int\limits_{\mathbb{R}}\varphi\left(x\right)d\cdfn{x}
\end{equation}

\begin{example} Если $\theta$ --- среднее, то $\varphi\left(x\right)=x$
$$\int\limits_{-\infty}^{+\infty}xd\cdfof{\theta}{x}
    =\theta=g\left(\theta\right)$$
\end{example}
\begin{theorem}Пусть функция $\varphi\left( x \right)$
    в \eqref{eq:unknown_parameter} ограничена и строго монотонная.
    Тогда оценка $\hat{\theta}$ существует и является сильно состоятельной.
\end{theorem}
\begin{proof}
    Имеем формулу \eqref{eq:unknown_parameter}
    $$g\left(\hat{\theta}\right)
            =\int\limits_{\mathbb{R}}\varphi\left(x\right)d\cdfn{x}$$

    Поскольку функция $g\left(\hat{\theta}\right)$ непрерывна и монотонна,
    то она имеет обратную функцию
    $g^{-1}:g^{-1}\left(g\left(\hat{\theta}\right)\right)=\hat{\theta}$.

    Применим обратную функцию к обеим частям уравнения
    $$\hat{\theta}
            =g^{-1}\left(
                \int\limits_{\mathbb{R}}\varphi\left(x\right)d\cdfn{x}\right)$$

    Поскольку выборочная функция распределения почти всюду равна
    неизвестной функции распределения при достаточно большом объёме выборки,
    то
    $$\int\limits_{\mathbb{R}}\varphi\left(x\right)d\cdfn{x}\acovergence
        \int\limits_{\mathbb{R}}\varphi\left(x\right)d\cdfn{x}$$

    Функция $g^{-1}\left(x\right)$ непрерывна
    $$\hat{\theta}
        =\int\limits_{\mathbb{R}}\varphi\left(x\right)d\cdfn{x}
        \acovergence\int\limits_{\mathbb{R}}\varphi\left(x\right)d\cdfn{x}
        =\theta$$
    Теорема доказана
    $$\hat{\theta}\acovergence\theta$$
\end{proof}
\index{выборочное среднее}
\begin{definition}[Выборочное среднее]
    Выборочное средние обозначается через $\overline{x}$
    и считается по следующей формуле
    $$\overline{x}=\int\limits_{\mathbb{R}}xd\cdfn{x}$$

    Поскольку все элементы выборки равновероятны,
    получаем математическое ожидание
    дискретной равномерно распределённой случайной величины,
    принимающей $n$ значений
    $$\overline{x}=\int\limits_{\mathbb{R}}xd\cdfn{x}
        =\frac{1}{n}\cdot\sum_{k=1}^n x_k$$
\end{definition}
\index{выборочная дисперсия}
\begin{definition}[Выборочная дисперсия]
    Выборочная дисперсия $\overline{\sigma^2}$
    считается формуле
    $$\overline{x}
        =\int\limits_{\mathbb{R}}\left(x-\overline{x}\right)^2d\cdfn{x}
        =\frac{1}{n}\cdot\sum_{k=1}^n \left(x_k-\overline{x}\right)^2$$
\end{definition}
