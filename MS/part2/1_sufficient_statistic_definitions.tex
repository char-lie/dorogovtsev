\section{Оптимальная оценка}
\begin{definition}[Симметризация]\index{симметризация}
  Симметризация $\Lambda$ оценки $\hat{\theta}$ --- среднее
  оценок $\hat{\theta}$ для
  всевозможных перестановок $\sigma\in S_n$
  элементов выборки \xsample
  $$\Lambda\hat{\theta}
      = \frac{1}{n!}\cdot\sum_{\sigma\in S_n} \hat{\theta}\left(
      x_{\sigma\left(1\right)}, x_{\sigma\left(2\right)},
          \dots, x_{\sigma\left(n\right)}\right)$$
\end{definition}
\begin{lemma}
  \index{лемма!о симметризации несмещённой оценки}
  Для произвольной несмещённой оценки $\hat{\theta}$
  её симметризация $\Lambda{\hat{\theta}}$
  не хуже её самой в среднем квадратическом
  \begin{align*}
  \meanof{\theta}{\hat{\theta}}
      = \theta
  \Rightarrow
      \begin{cases}
      \meanof{\theta}{\Lambda{\hat{\theta}}}
          = \meanof{\theta}{\hat{\theta}}
          = \theta\\
      \dispersionof{\theta}{\Lambda{\hat{\theta}}}
          \le\dispersionof{\theta}{\hat{\theta}}
      \end{cases}
  \end{align*}
\end{lemma}
\begin{proof}
  Берём \xsample --- независимые одинаково распределённые
  случайные величины.
  Введём обозначения для более короткой записи
  используемых в доказательстве случайных векторов.
  Вектор, состоящий из элементов выборки в их изначальном порядке,
  обозначим привычным $\vec{x}$
  \begin{equation*}
    \left(x_1, x_2, \dots, x_n\right) = \vec{x}
  \end{equation*}
  Вектор, состоящий из элементов, изменивших своё местоположение под влиянием
  перестановки $\sigma$ (значение которой будет ясно из контекста),
  будем обозначать через $\vec{x}_\sigma$
  \begin{equation*}
    \left(x_{\sigma\left(1\right)}, x_{\sigma\left(2\right)},
      \dots, x_{\sigma\left(n\right)}\right)= \vec{x}_\sigma
  \end{equation*}
  Тогда и оценки примут более красивый вид
  \begin{align*}
      \hat{\theta}\left(x_1, x_2, \dots, x_n\right)
      &= \hat{\theta}\left(\vec{x}\right)\\
      \hat{\theta}\left(x_{\sigma\left(1\right)},
          x_{\sigma\left(2\right)},
          \dots, x_{\sigma\left(n\right)}\right)
      &= \hat{\theta}\left(\vec{x}_\sigma\right)
  \end{align*}

  Теперь приступим непосредственно к доказательству.
  \begin{enumerate}
      \item
      Начнём с первого пункта --- докажем несмещённость
      симметризации оценки $\hat{\theta}$.

      Нетрудно показать, что  вектора $\vec{x}$ и $\vec{x}_\sigma$
      имеют одинаковое распределение для любой перестановки $\sigma$,
      а это значит, что и оценки $\hat{\theta}\left(\vec{x}\right)$
      и $\hat{\theta}\left(\vec{x}_\sigma\right)$
      распределены одинаково как функции случайных
      одинаково распределённых векторов.
      Следовательно, их математические ожидания равны между собой
      при любой перестановке $\sigma$
      $$\meanof{\theta}{\hat{\theta}\left(\vec{x}\right)}
          = \meanof{\theta}{\hat{\theta}\left(\vec{x}_\sigma\right)}
          = \theta$$

      Посчитаем математическое ожидание симметризации оценки
      $\hat{\theta}$
      \begin{align*}
          \meanof{\theta}{\Lambda\hat{\theta}}
        &= \meanof{\theta}{
            \left\{\frac{1}{n!}\cdot\sum_{\sigma\in S_n}
            \hat{\theta}\left(\vec{x}_\sigma\right)\right\}}
      \end{align*}

      Помним, что математическое ожидание линейно и
      константы можно выносить за знак математического ожидания,
      а математическое ожидание суммы равно сумме математических ожиданий
      \begin{align*}
          \meanof{\theta}{\left\{\frac{1}{n!}\cdot\sum_{\sigma\in S_n}
        \hat{\theta}\left(\vec{x}_\sigma\right)\right\}}
        = \frac{1}{n!}\cdot\sum_{\sigma\in S_n}
            \meanof{\theta}{\hat{\theta}\left(\vec{x}_\sigma\right)}
      \end{align*}

      Не забываем, что математическое ожидание
      $\hat{\theta}\left( \vec{x}_{\sigma} \right)$ равно параметру
      $\theta$

      \begin{align*}
          \frac{1}{n!}\cdot\sum_{\sigma\in S_n}
        \meanof{\theta}{\hat{\theta}\left(\vec{x}_\sigma\right)}
        = \frac{1}{n!}\cdot\sum_{\sigma\in S_n}\theta
      \end{align*}

      Сумма имеет $n!$ слагаемых (количество перестановок $\sigma\in S_n$)
      \begin{align*}
          \frac{1}{n!}\cdot\sum_{\sigma\in S_n}\theta
        = \frac{1}{n!}\cdot n!\cdot\theta
        = \theta
      \end{align*}

      А это значит, что первый пункт доказан и симметризация
      несмещённой оценки $\hat{\theta}$ действительно несмещённая
      $$\meanof{\theta}{\Lambda\hat{\theta}}= \theta$$
      \item
      Теперь посмотрим, чему равна дисперсия симметризации
      оценки $\hat{\theta}$

      Воспользуемся определением
      \begin{align*}
          \dispersionof{\theta}{\Lambda\hat{\theta}}
        = \meanof{\theta}{
            \left(\Lambda\hat{\theta}-\theta\right)^2}
        = \meanof{\theta}{
            \left\{\frac{1}{n!}\cdot\sum_{\sigma\in S_n}
        \hat{\theta}\left(\vec{x}_\sigma\right)
        -\theta\right\}^2}
      \end{align*}

      Внесём параметр $\theta$ в сумму.
      Для этого нужно умножить и поделить его на $n!$
      (так как сумма имеет $n!$ слагаемых)
      \begin{align*}
        \meanof{\theta}{\left\{\frac{1}{n!}\cdot\sum_{\sigma\in S_n}
          \hat{\theta}\left(\vec{x}_\sigma\right)-\theta\right\}^2}
        = \meanof{\theta}{
          \left\{\frac{1}{n!}\cdot\sum_{\sigma\in S_n}
      \left(\hat{\theta}\left(\vec{x}_\sigma\right)
      -\theta\right)\right\}^2} = \\
        = \meanof{\theta}{
          \left\{\sum_{\sigma\in S_n}\frac{1}{n!}\cdot
      \left(\hat{\theta}\left(\vec{x}_\sigma\right)
      -\theta\right)\right\}^2}
      \end{align*}

      Вспомним неравенство Йенсена для выпуклой функции $f$
      \cite[с.~167]{DorogovtsevMA}
      $$f\left(\sum_{i=1}^n q_i\cdot x_i\right)
          \le \sum_{i=1}^n q_i\cdot f\left(x_i\right),\;
        \sum_{i=1}^n q_i=1$$

      В нашем случае
      $x_i= \left(\hat{\theta}
          \left(\vec{x}_{\sigma_i}\right)-\theta\right)$,
      функция $f\left(x\right)=x^2$,
      сумма проходит по всевозможным перестановкам $\sigma$,
      а роль $q_i$ выполняет $\frac{1}{n!}$,
      так как
          $$\sum_{\sigma\in S_n} q_i
        = \sum_{\sigma\in S_n}\frac{1}{n!}=n!\cdot\frac{1}{n!}=1$$

      Перепишем неравенство Йенсена для нашего случая
      \begin{equation}\label{eq:jensen_symmetrization}
          \meanof{\theta}{\left\{\sum_{\sigma\in S_n}\frac{1}{n!}\cdot
        \left(\hat{\theta}\left(\vec{x}_\sigma\right)
        -\theta\right)\right\}^2}
        \le\meanof{\theta}{\sum_{\sigma\in S_n}\frac{1}{n!}\cdot
            \left(\hat{\theta}\left(\vec{x}_\sigma\right)
            -\theta\right)^2}
      \end{equation}

      Воспользуемся линейностью математического ожидания,
      внеся его под знак суммы
      \begin{align*}
          \meanof{\theta}{\sum_{\sigma\in S_n}\frac{1}{n!}\cdot
        \left(\hat{\theta}\left(\vec{x}_\sigma\right)
        -\theta\right)^2}
          = \frac{1}{n!}\cdot\sum_{\sigma\in S_n}
        \meanof{\theta}{
            \left(\hat{\theta}\left(\vec{x}_\sigma\right)
            -\theta\right)^2}
      \end{align*}

      Видим сумму дисперсий.
      Дисперсии одинаковы, так как оценки имеют одинаковые распределения
      \begin{align*}
          \frac{1}{n!}\cdot\sum_{\sigma\in S_n}
        \meanof{\theta}{
            \left(\hat{\theta}\left(\vec{x}_\sigma\right)
            -\theta\right)^2}
          = \frac{1}{n!}\cdot\sum_{\sigma\in S_n}
        \dispersionof{\theta}{
            \hat{\theta}\left(\vec{x}_\sigma\right)}= \\
          = \frac{1}{n!}\cdot\sum_{\sigma\in S_n}
        \dispersionof{\theta}{\hat{\theta}\left(\vec{x}\right)}
          = \frac{1}{n!}\cdot n!
        \cdot\dispersionof{\theta}{\hat{\theta}\left(\vec{x}\right)}
          = \dispersionof{\theta}{\hat{\theta}\left(\vec{x}\right)}
      \end{align*}

      Из неравенства Йенсена \eqref{eq:jensen_symmetrization} видим,
      что дисперсия симметризации не хуже дисперсии самой оценки
      $$\dispersionof{\theta}{\Lambda\hat{\theta}}
          \le\dispersionof{\theta}{\hat{\theta}\left({\vec{x}}\right)}$$

  \end{enumerate}

  То есть, симметризация не ухудшает оценку,
  а в общем случае (когда неравенство строгое) даже делает её лучше.
\end{proof}

\begin{remark}
  Равенство в неравенстве Йенсена (в формуле \eqref{eq:jensen_symmetrization}
  из доказательства выше)
  возможно только в случае симметричной функции.
  Значит,
  в качестве оценки достаточно брать только симметричные функции выборки
\end{remark}

\begin{comment}
\begin{definition}[Функция вариационного ряда]\index{функция!вариационного ряда}
  Если оценка $\hat{\theta}$ симметрична относительно перестановок аргументов,
  то она является функцией вариационного ряда
\end{definition}
\end{comment}

\begin{remark}
  Все оценки, которые претендуют быть оптимальными,
  должны быть функциями вариационного ряда
\end{remark}

\section{$\sigma$-алгебра, порождённая случайной величиной}
Имеем вероятностное пространство
$\left( \Omega, \mathfrak{F}, \mathbb{P} \right)$,
также есть функция $\xi: \Omega\rightarrow\mathbb{R}$
такая, что связанные с ней множества измеримы по Лебегу
$$\left\{\omega
  \mcond \xi\left(\omega\right) < c\right\} \in \mathfrak{F}, c\in \mathbb{R}$$

Но это будет неудобно при использовании,
поэтому возьмём борелевские подмножества $\mathfrak{B}$ множества $\mathbb{R}$
$$\mathbb{R}\supset\mathfrak{B}\ni\Delta:
  \xi^{-1}\left( \Delta \right) \in \mathfrak{F}$$

Рассмотрим более подробно,
что же означает запись $\xi^{-1}\left( \Delta \right)$
$$\xi^{-1}\left( \Delta \right)
  = \left\{ \omega \mcond \xi\left( \omega \right) \in \Delta \right\},\;
      \Delta\in\mathfrak{B}, \omega\in\Omega$$

\begin{definition}[Сигма-алгебра, порождённая случайной величиной]
  \index{сигма-алгебра!порождённая!случайной величиной}
  $\mathfrak{F}_\xi = \sigma\left( \xi \right)$
  --- $\sigma$-алгебра, порождённая случайной величиной $\xi$
  $$\mathfrak{F}_\xi
      = \left\{ \xi^{-1}\left( \Delta \right)
      \mcond \Delta\in\mathfrak{B} \right\}$$
\end{definition}

Из курса теории вероятностей помним лемму, которая утверждает,
что $\xi$ --- случайная величина тогда и только тогда, когда
$$\forall\Delta\in\mathfrak{B}:
  \left\{ \omega \mcond \xi\left( \omega \right) \in \Delta \right\}
  = \left\{ \xi\in\Delta \right\}
  = \xi^{-1}\left( \Delta \right) \in \mathfrak{F}$$

А это значит, что все элементы $\sigma$-алгебры $\mathfrak{F}_\xi$
входят в $\sigma$-алгебру $\mathfrak{F}$, а сама $\mathfrak{F}_\xi$
является подмножеством $\mathfrak{F}$
\begin{align*}
  \begin{cases}
      \mathfrak{F}_\xi
      = \left\{ \xi^{-1}\left( \Delta \right)
          \mcond \Delta\in\mathfrak{B} \right\}\\
      \forall\Delta\in\mathfrak{B}:
      \xi^{-1}\left( \Delta \right) \in \mathfrak{F}
  \end{cases}
  \Rightarrow
  \mathfrak{F}_\xi \subset \mathfrak{F}
\end{align*}

Проверим, что $\mathfrak{F}_\xi$ действительно является $\sigma$-алгеброй
\begin{enumerate}
  \item Множество элементарных исходов $\Omega$ входит в $\mathfrak{F}_\xi$.
      Поскольку случайная величина $\xi$ принимает действительные значения,
      то прообраз множества действительных чисел $\mathbb{R}$
      и будет множеством элементарных исходов $\Omega$.
      А поскольку $\mathbb{R}$ принадлежит борелевской $\sigma$-алгебре,
      то его прообраз по определению принадлежит
      $\sigma$-алгебре $\mathfrak{F}_\xi$
      \begin{align*}
      \begin{cases}
          \xi^{-1}\left( \Delta \in \mathfrak{B} \right) \in\mathfrak{F}\\
          \mathbb{R}\in\mathfrak{B}\\
          \xi^{-1}\left( \mathbb{R} \right)= \Omega
      \end{cases}
      \Rightarrow
      \Omega \in \mathfrak{F}_\xi
      \end{align*}
  \item Если событие $A$ принадлежит $\mathfrak{F}_\xi$,
      то его дополнение $\stcomp{A}$ тоже принадлежит $\mathfrak{F}_\xi$
      \begin{align*}
      A= \xi^{-1}\left( \Delta \right)
          &= \left\{ \omega \mcond \xi\left( \omega \right)
        \in \Delta \right\}\\
      \Rightarrow
      \stcomp{A}
          = \left\{ \omega \mcond \xi\left( \omega \right)
        \notin \Delta \right\}
          &= \left\{ \omega \mcond \xi\left( \omega \right)
        \in \stcomp{\Delta}\right\}\\
      \stcomp{A}&= \xi^{-1}\left( \stcomp{\Delta} \right)
      \end{align*}

      Поскольку $\mathfrak{B}$ является $\sigma$-алгеброй,
      а $\Delta$ --- её элемент,
      то дополнение $\stcomp{\Delta}$ тоже принадлежит
      $\sigma$-алгебре $\mathfrak{B}$.
      Из этого следует, что свойство выполняется
      \begin{align*}
      \begin{cases}
          \xi^{-1}\left( \Delta \right) \in \mathfrak{F}\\
          \Delta \in \mathfrak{B}
        \Rightarrow \stcomp{\Delta} \in \mathfrak{B}
      \end{cases}
      \Rightarrow
      \stcomp{\xi^{-1}\left( \Delta \right)}
          = \xi^{-1}\left( \stcomp{\Delta} \right) \in \mathfrak{F}
      \end{align*}
  \item Замкнутость относительно счётных пересечений.

      Начнём с замкнутости относительно пересечения двух множеств
      $$A= \xi^{-1}\left( \Delta_1 \right), B= \xi^{-1}\left( \Delta_2 \right)$$

      Начинаем считать
      \begin{align*}
      A \cap B
          &= \xi^{-1}\left( \Delta_1 \right)
        \cap \xi^{-1}\left( \Delta_2 \right) = \\
          &= \left\{ \omega \mcond \xi\left( \omega \right)
        \in \Delta_1 \right\}
        \cap \left\{ \omega \mcond \xi\left( \omega \right)
            \in \Delta_2 \right\} = \\
          &= \left\{ \omega \mcond \xi\left( \omega \right) \in \Delta_1
        \wedge \xi\left( \omega \right) \in \Delta_2 \right\} = \\
          &= \left\{ \omega \mcond \xi\left( \omega \right)
        \in \Delta_1 \cap \Delta_2 \right\}
          = \xi^{-1}\left( \Delta_1 \cap \Delta_2 \right)
      \end{align*}

      Значит, имеем равенство
      $$\xi^{-1}\left( \Delta_1 \right) \cap \xi^{-1}\left( \Delta_2 \right)
      = \xi^{-1}\left( \Delta_1 \cap \Delta_2 \right)$$

      Пользуясь методом математической индукции нетрудно показать,
      что для любого $n$ выполняется
      $$\xi^{-1}\left( \bigcap_{i=1}^n \Delta_i  \right)
      = \bigcap_{i=1}^n \xi^{-1}\left( \Delta_i \right),
          \Delta_i \in \mathfrak{B}$$
\end{enumerate}

Как устроена эта $\sigma$-алгебра?
Каждому элементарному исходу отвечает одно и только одно значение
случайной величины, а каждому значению случайной величины
отвечает один и больше элементарных исходов.
Допустим, есть некое $a\in\mathbb{R}$, которое является образом по крайней мере
двух элементарных исходов $\omega_1$ и $\omega_2$

$$\xi\left( \omega_1 \right) = \xi\left( \omega_2 \right) = a$$

Теперь рассмотрим элемент $\Delta$ борелевской $\sigma$-алгебры $\mathfrak{B}$.
Из вышесказанного следует, что,
если число $a$ принадлежит множеству $\Delta$, то прообраз этого множества
содержит элементы $\omega_1$ и $\omega_2$,
в противном случае оба элементарных исхода не входят в прообраз
\begin{align*}
  a \in \Delta
      \Rightarrow \xi^{-1}\left( \Delta \right) \ni \omega_1, \omega_2 \\
  a \notin \Delta
      \Rightarrow \xi^{-1}\left( \Delta \right) \not\ni \omega_1, \omega_2 \\
\end{align*}

То есть, множество $\mathfrak{F}_\xi$ не будет различать
элементы $\omega_1$ и $\omega_2$.
Это в свою очередь означает, что можно разбить $\mathfrak{F}_\xi$
на уровни --- непересекающиеся подмножества

\begin{definition}[Множество уровня]\index{множество уровня}
  Множество уровня $H_t$ --- полный прообраз
  значения $t\in\mathbb{R}$ случайной величины $\xi$
  $$H_t
      = \left\{ \omega \mcond \xi\left( \omega \right) = t \right\}
      = \xi^{-1}\left( t \right)$$
\end{definition}

\begin{remark}
  Уровни $H_i$ составляют разбиение множества элементарных исходов $\Omega$.
  \begin{enumerate}
      \item Множества $H_i$ не пересекаются
      $$H_{t_1} \neq H_{t_2} \Leftrightarrow t_1 \neq t_2$$
      \item Объединение всех $H_i$ даёт множество элементарных исходов
      $$\bigcup_{t \in \mathbb{R}} H_t
          = \bigcup_{t \in \mathbb{R}} \xi^{-1}\left( t \right)
          = \xi^{-1}\left( \mathbb{R} \right)
          = \Omega$$
  \end{enumerate}
\end{remark}

Очень похоже на гипотезы из курса теории вероятностей с той лишь разницей,
что уровней может быть бесконечное и даже континуальное количество,
из чего также следует, что вероятность некоторых из них может быть нулевой.

\section{Случайная величина, измеримая относительно $\sigma$-алгебры}
В общем случае вероятностное пространство может быть разбито
на континуальное количество множеств уровней
(для $\sigma$-алгебры, порождённой непрерывной случайной величиной).

Начнём же с рассмотрения того случая,
когда случайная величина $\xi$ принимает $n$ значений
$a_1, a_2, \dots, a_n$
$$\xi: \Omega \rightarrow \left\{ a_1, a_2, \dots, a_n \right\}$$

Это в свою очередь означает, что у нас есть $n$ уровней
$$H_k = \left\{ \omega \mcond \xi\left( \omega \right) = a_k \right\},
  k= \overline{1,n}$$

Нетрудно понять,
что $\sigma$-алгебра $\sigma\left( \xi \right)$ содержит $2^n$ элементов
$$\sigma\left( \xi \right) = \left\{ \bigcup_{k=1}^n H_k^{\eta_k}
  \mcond \eta_k = \overline{0,1}, H_k^0 = \emptyset, H_k^1 = H_k \right\}$$

Прежде, чем продолжить, зафиксируем явление и дадим ему название.

\begin{definition}[Сигма-алгебра, порождённая полным набором гипотез]
  \index{сигма-алгебра!порождённая!полным набором гипотез}
  Возьмём набор множеств $H_1, \dots, H_n$ который является полным набором
  гипотез для пространства элементарных исходов $\Omega$
  $$\bigcap_{k=1}^n H_k = \emptyset,\; \bigcup_{k=1}^n H_k = \Omega,\;
      \Probability{H_k} \neq 0$$

  В таком случае $\sigma$-алгебра, содержащая всевозможные объединения этих
  множеств, будет называться $\sigma$-алгеброй, порождённой полным набором
  гипотез и будет выглядеть следующим образом
  $$\mathfrak{F}_1 = \left\{ \bigcup_{k=1}^n H_k^{\eta_k}
      \mcond \eta_k = \overline{0,1},
      H_k^0 = \emptyset, H_k^1 = H_k \right\}$$
\end{definition}

Нам нет смысла пользоваться лишь одной случайной величиной $\xi$.
Нас интересует, как устроены случайные величины,
которые измеримы относительно $\sigma$-алгебры $\sigma\left( \xi \right)$.

\begin{definition}[Случайная величина, измеримая относительно сигма-алгебры]
  \index{случайная величина!измеримая относительно сигма-алгебры}
  Тот факт, что случайная величина $\varkappa$ измерима относительно
  $\mathfrak{F}_1$, значит, что все прообразы случайной величины
  $\varkappa$ лежат в $\sigma$-алгебре $\mathfrak{F}_1$
  \begin{align*}
      \forall c \in \mathbb{R}:\;
      \left\{ \omega \mcond \varkappa\left( \omega \right) \le c \right\}
      \in \mathfrak{F}_1
  \end{align*}
\end{definition}

Возьмём случайную величину $\kappa$, измеримую относительно $\sigma$-алгебры
$\sigma\left( \xi \right)$
\begin{align*}
  \left\{ \omega \mcond \varkappa\left( \omega \right) \le c \right\}
      \in \sigma\left( \xi \right)
\end{align*}

То есть, прообразы $\varkappa$ выражаются через объединения уровней $H_k$
$$\left\{ \omega \mcond \varkappa\left( \omega \right) \le c \right\}
  = \bigcup_{k=1}^n H_k^{\eta_k}$$

Введём обозначение
$$A\left( c \right)
  = \left\{ \omega \mcond \varkappa\left( \omega \right) \le c \right\}$$

Очевидно, что при $c\to-\infty$ прообразом является пустое множество,
а когда $c\to+ \infty$, то прообразом является всё множество элементарных исходов
\begin{align*}
  \left\{ \omega \mcond \varkappa\left( \omega \right) \le -\infty \right\}
      &= \left\{ \omega \mcond \varkappa\left(\omega\right)\in\emptyset \right\}
      = \varkappa^{-1}\left( \emptyset \right)
      = \emptyset \\
  \left\{ \omega \mcond \varkappa\left( \omega \right) \le + \infty \right\}
      &= \left\{ \omega \mcond\varkappa\left(\omega\right)\in\mathbb{R} \right\}
      = \varkappa^{-1}\left( \mathbb{R} \right)
      = \Omega
\end{align*}

Также ясно,
что, если имеются два элемента борелевского множества и один включён в другой,
то полный прообраз первого элемента тоже будет включён в прообраз второго
\begin{align*}
  \Delta_1, \Delta_2 \in \mathfrak{B},
  \Delta_1 \subseteq \Delta_2 \\
  \Rightarrow \varkappa^{-1}\left( \Delta_1 \right)
      \subseteq \varkappa^{-1}\left( \Delta_1 \right)
      \cup \varkappa^{-1}\left( \Delta_2 \right) = \\
      = \varkappa^{-1}\left( \Delta_1 \cup \Delta_2 \right)
      = \varkappa^{-1}\left( \Delta_2 \right)
\end{align*}

Ни у кого не возникает сомнений, что справедливо и такое утверждение
$$c_1, c_2 \in \mathbb{R}, c_1 \le c_2
  \Rightarrow A\left( c_1 \right) \subseteq A\left( c_2 \right)$$

Объединим и проанализируем вышеописанное:
\begin{enumerate}
  \item Количество элементов в множестве $A\left( c \right)$
      не уменьшается с ростом $c$
      $$c_1 \le c_2
      \Rightarrow A\left( c_1 \right) \subseteq A\left( c_2 \right)$$

  \item Множество $A\left( c \right)$ ``разрастается''
      от пустого множества $\emptyset$
      до множества элементарных событий $\Omega$
      с ростом $c$ от $-\infty$ до $+ \infty$
      $$A\left( -\infty \right)= \emptyset, A\left( + \infty \right)= \Omega$$

  \item Множество $A\left( c \right)$ растёт дискретными шагами.
      Это связано с тем, что уровни $H_k$ в нашей $\sigma$-алгебре неделимые,
      а каждый её элемент должен состоять из
      объединений этих уровней и ничего другого.
\end{enumerate}

Из этого всего делаем более конкретные выводы о том,
как изменяется значение функции $A\left( c \right)$ с ростом параметра $c$.
Должны быть опорные точки, на которых происходит ``скачок'' ---
точки, на которых к объединению добавляется ещё один или более уровней.

Поскольку имеется $n$ уровней, то может быть не более $n$ скачков:
ведь самый ``медленный'' рост будет происходить,
если добавлять по одному уровню на определённых константах,
а нужно пройти всё от пустого множества $\emptyset$
до множества элементарных исходов $\Omega$.

Выделим $m$ точек ($m \le n$) $c_1<c_2<\dots<c_m$
на числовой прямой $\mathbb{R}$ как значения случайной величины $\varkappa$
$$\varkappa: \Omega \rightarrow \left\{ c_1, c_2, \dots, c_m \right\}$$

Посмотрим, как соотносятся между собой
$A\left( c_i \right)$ и $A\left( c_{i-1} \right)$,
чтобы лучше понять природу скачков.

Сначала покажем, что $A\left( c_1 \right)$ является прообразом $c_1$
$$\varkappa^{-1}\left( c_1 \right)
  = \left\{ \omega \mcond \varkappa\left( \omega \right) = c_1 \right\}$$

Поскольку случайная величина не принимает значений до $c_1$,
то множество $A\left( c_1-0 \right)
= \left\{ \omega \mcond \varkappa\left( \omega \right) < c_1 \right\}$ пустое.
Получаем то, что хотели
\begin{align*}
  \varkappa^{-1}\left( c_1 \right)
      &= \left\{ \omega \mcond \varkappa\left( \omega \right) = c_1 \right\}
      \cup \emptyset = \\
      &= \left\{ \omega \mcond \varkappa\left( \omega \right) = c_1 \right\}
      \cup \left\{ \omega
          \mcond \varkappa\left( \omega \right) < c_1 \right\} = \\
      &= \left\{ \omega \mcond \varkappa\left( \omega \right) \le c_1 \right\}
      = A\left( c_1 \right)
\end{align*}

Идём дальше. Обозначим $c_0 = -\infty$.
Тогда в каждой точке $A\left( c_i \right), i = \overline{1,m}$
происходит скачок на множество $\varkappa^{-1}\left( c_i \right)$, то есть 
$$A\left( c_i \right)
  = A\left( c_{i-1} \right) \cup \varkappa^{-1}\left( c_i \right)$$

Так происходит, потому что имеет место равенство,
которое выполняется из-за того,
что функция имеет скачки лишь на параметрах $c_i$,
а между ними не меняет значения
$$A\left( c_i \right) = A\left( c_{i+1} - 0 \right)$$

В таком случае тождество очевидно
\begin{align*}
A\left( c_i \right)
  = \left\{ \omega \mcond \varkappa\left( \omega \right) \le c_i \right\} = \\
  = \left\{ \omega \mcond \varkappa\left( \omega \right) < c_i \right\} \cup
      \left\{ \omega \mcond \varkappa\left( \omega \right) = c_i \right\} = \\
  = A\left( c_{i-1}-0 \right) \cup \varkappa^{-1}\left( c_i \right)
  = A\left( c_{i-1} \right) \cup \varkappa^{-1}\left( c_i \right)
\end{align*}

Поскольку $\varkappa$ --- случайная величина, принимающая $m$ значений,
то её прообразы составляют разбиение пространства элементарных исходов $\Omega$.
А поскольку $A\left( c_{i-1} \right)$ состоит из объединений этих прообразов,
то оно не пересекается с $\varkappa^{-1}\left( c_i \right)$.
То есть, мы знаем, как вычислять прообраз $\varkappa$
\begin{align*}
  \begin{cases}
      A\left( c_{i-1} \right) \cap \varkappa^{-1}\left( c_i \right)
      = \emptyset \\
      A\left( c_i \right)
      = A\left( c_{i-1} \right) \cup \varkappa^{-1}\left( c_i \right)
  \end{cases}
  \Rightarrow \varkappa^{-1}\left( c_i \right) =
      A\left( c_{i} \right) \setminus A\left( c_{i-1} \right)
\end{align*}

Значит, случайная величина $\varkappa$ принимает значение $c_i$
при выпадении любого элементарного исхода $\omega$
из множества $A\left( c_{i} \right) \setminus A\left( c_{i-1} \right)$
\begin{equation}\label{randomVariableFirst}
  \varkappa\left( \omega \right) = c_i,
      \omega \in A\left( c_{i} \right) \setminus A\left( c_{i-1} \right)
\end{equation}

Запишем это в более удобном виде
$$\varkappa\left( \omega \right)
  = \sum_{i=1}^m c_i \cdot \Indicator{\omega
      \in A\left( c_{i} \right) \setminus A\left( c_{i-1} \right)}$$

Но эта сумма кажется уродливой из-за длинного индикатора и непонятного $m$.
Попытаемся разобраться,
в чём же дело и как прийти к изначальной $n$ и милым $H_k$.

Помним, что $A\left( c_{i} \right) \setminus A\left( c_{i-1} \right)$ ---
объединение нескольких множеств уровня $H_k$.

Для любого $t$ разность множеств
$A\left( c_{t} \right) \setminus A\left( c_{t-1} \right) \neq \emptyset$
(когда это множество пустое, то индикатор просто не сработает и нечего считать)
можно представить как объединение двух непересекающихся множеств,
которые обозначим $H_1^t \in \mathfrak{F}$ и $H_2^t \in \mathfrak{F}$,
причём $H_1^t$ --- множество уровня, а $H_2^t$ --- произвольное множество
из $\mathfrak{F}$ (в том числе и пустое, если разность и есть множество уровня).
Тогда $t$-ое слагаемое примет следующий вид
$$c_t \cdot \Indicator{\omega \in
  A\left( c_{t} \right) \setminus A\left( c_{t-1} \right)}
  = c_t \cdot \Indicator{\omega \in H_1^t \cup H_2^t}$$

Поскольку множества $H_1^t$ и $H_2^t$ по условию не пересекаются,
то можно разбить индикатор на сумму
\begin{align*}
c_t \cdot \Indicator{\omega \in H_1^t \cup H_2^t}
  &= c_t \cdot \left( \Indicator{\omega \in H_1^t}
      + \Indicator{\omega \in H_2^t} \right) \\
  &= c_t \cdot \Indicator{\omega \in H_1^t}
      + c_t \cdot \Indicator{\omega \in H_2^t}
\end{align*}

Если ввести две константы $c_1^t$ и $c_2^t$, которые будут равны старой $c_t$,
то равенство примет более симпатичный вид
$$c_t \cdot \Indicator{\omega \in H_1^t}
  + c_t \cdot \Indicator{\omega \in H_2^t}
  = c_1^t \cdot \Indicator{\omega \in H_1^t}
  + c_2^t \cdot \Indicator{\omega \in H_2^t}$$

Если же $H_2^t$ не является пустым множеством $\emptyset$
или множеством уровня $H_k$, то нужно повторить процедуру,
разбив $H_2^t$ на объединение двух непересекающихся множеств --- на множество
уровня и множество из $\mathfrak{F}$.
В итоге (вследствие конечности множества $\mathfrak{F}$)
индикатор разности $A\left( c_{t} \right) \setminus A\left( c_{t-1} \right)$
будет разбита на сумму индикаторов множеств уровней.

Таким же образом можно поступить со всеми остальными индикаторами.
В итоге получим $n$ констант $d_1, d_2, \dots, d_n$
вместо $m$ чисел $c_1, c_2, \dots, c_m$.

Теперь сумма примет более приятный для глаз
и понятный из контекста начала раздела вид
$$\varkappa\left( \omega \right)
  = \sum_{i=1}^m c_i \cdot \Indicator{\omega
      \in A\left( c_{i} \right) \setminus A\left( c_{i-1} \right)}
  = \sum_{i=1}^n d_i \cdot \Indicator{\omega \in H_i}$$

Видим, что теперь можно определить отображение из множества значений,
принимаемых случайной величиной $\xi$, в множество значений,
принимаемых случайной величиной $\varkappa$

$$f: \left\{ a_1, a_2, \dots, a_n \right\}
  \rightarrow \left\{ d_1, d_2, \dots, d_n \right\}$$

Попробуем показать, что $\varkappa$ является функцией от $\xi$.
Очевидно, что случайная величина $\xi$ имеет такой же вид,
что и $\varkappa$ --- сумма констант, умноженных на индикаторы,
так как мы только что показали, что все функции,
измеримые относительно $\sigma$-алгебры, порождённой случайной величиной $\xi$,
выглядят именно так
$$f\left( \xi\left( \omega \right) \right)
  = f\left( \sum_{i=1}^n a_i \cdot \Indicator{\omega \in H_i} \right)$$

Поскольку уровни $H_i$ не пересекаются,
то лишь одно слагаемое не будет равно нулю:
$\omega$ может принадлежать лишь одному уровню.
В таком случае запись принимает свой изначальный вид без суммы
\eqref{randomVariableFirst}
$$f\left( \xi\left( \omega \right) \right)
  = f\left( a_i \right),\; \omega \in H_i$$

Замечаем, что $f\left( a_i \right) = d_i$, а это и есть то значение,
которое принимает случайная величина $\varkappa$ на уровне $H_i$
$$f\left( \xi\left( \omega \right) \right)
  = f\left( a_i \right) = d_i
  = \varkappa\left( \omega \right),\; \omega \in H_i$$

Поскольку мы не привязывались к конкретным $i$ и конкретным $\omega$,
то получаем желаемое равенство
$$\varkappa = f\left( \xi \right)$$

Отсюда делаем следующий вывод
\begin{affirmation}\label{measurableRandomVariable}
  Случайной величине $\varkappa$
  необходимо и достаточно быть функцией случайной величины $\xi$,
  чтобы быть измеримой относительно $\sigma$-алгебры,
  порождённой случайной величиной $\xi$.
\end{affirmation}