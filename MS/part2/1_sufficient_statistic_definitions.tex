\section{Оптимальная оценка}
\begin{example}\label{example:optimalEstimate}
  Пусть \xsample[2 \cdot n] --- выборка из распределения Бернулли
  \begin{equation*}
    \theta \in \left[ 0; 1 \right]:\qquad
    x_i = \begin{cases}
      1,& \theta \\
      0,& 1 - \theta
    \end{cases}
  \end{equation*}
  Введём оценку
  \begin{equation*}
    \hat{\theta}
    = \frac{2 \cdot x_1 + x_2 + 2 \cdot x_3 + x_4 + \dots
      + 2 \cdot x_{2 \cdot n - 1} + x_{2 \cdot n}}{3 \cdot n}
  \end{equation*}
  Оценка $\hat{\theta}$ состоятельная
  \begin{equation*}
    \hat{\theta}
    = \frac{2 \cdot \overline{x}}{3}
      + \frac{x_1 + x_3 + \dots + x_{2 \cdot n - 1}}{3 \cdot n}
  \end{equation*}
  По закону больших чисел видим, что
  \begin{equation*}
    \begin{cases}
      \frac{2 \cdot \overline{x}}{3} 
        \covergence{} \frac{2 \cdot \theta}{3} \\ \\ % TODO: workaround
      \frac{x_1 + x_3 + \dots + x_{2 \cdot n - 1}}{3 \cdot n}
        \covergence{} \frac{\theta}{3}
    \end{cases}
  \end{equation*}
  Значит,
  \begin{equation*}
    \hat{\theta}
    \covergence{} \frac{2}{3} \cdot \theta + \frac{1}{3} \cdot \theta
    = \theta
  \end{equation*}
  Также оценка $\hat{\theta}$ является несмещённой
  \begin{equation*}
    \mean{\hat{\theta}}
    = \frac{2 \cdot n \cdot \theta + n \cdot \theta}{3 \cdot n}
    = \theta
  \end{equation*}
  Хоть оценка $\hat{\theta}$ и обладает такими хорошими свойствами как
  состоятельность и несмещённость, она не оптимальная --- не лучшая.
\end{example}

\begin{exercise}
  Проверить, что дисперсия $\hat{\theta}$ больше, чем дисперсия
  $\theta_* = \overline{x}$
\end{exercise}

\begin{definition}[Симметризация]\index{симметризация}
  Симметризация $\Lambda$ оценки $\hat{\theta}$ --- среднее
  оценок $\hat{\theta}$ для
  всевозможных перестановок $\sigma\in S_n$
  элементов выборки \xsample
  $$\Lambda\hat{\theta}
      = \frac{1}{n!}\cdot \sum_{\sigma\in S_n} \hat{\theta}\left(
      x_{\sigma\left(1\right)}, x_{\sigma\left(2\right)},
          \dots, x_{\sigma\left(n\right)}\right)$$
\end{definition}
\begin{lemma}
  \index{лемма!о симметризации несмещённой оценки}
  Для произвольной несмещённой оценки $\hat{\theta}$
  её симметризация $\Lambda{\hat{\theta}}$
  не хуже её самой в среднем квадратическом
  \begin{align*}
  \meanof{\theta}{\hat{\theta}}
      = \theta
  \Rightarrow
      \begin{cases}
      \meanof{\theta}{\Lambda{\hat{\theta}}}
          = \meanof{\theta}{\hat{\theta}}
          = \theta\\
      \dispersionof{\theta}{\Lambda{\hat{\theta}}}
          \le\dispersionof{\theta}{\hat{\theta}}
      \end{cases}
  \end{align*}
\end{lemma}
\begin{proof}
  Как и раньше, обозначим $\vec{x} = \left[ x_1, x_2, \dots, x_n \right]$.
  Для перестановки $\sigma \in S_n$ используем
  $\vec{x}_\sigma = \left[ x_{\sigma\left(1\right)}, x_{\sigma\left(2\right)},
  \dots, x_{\sigma\left(n\right)} \right]$
  Тогда
  \begin{equation*}
    \Lambda\hat{\theta}
    = \frac{1}{n!} \cdot \sum_{\sigma \in S_n}
      \hat{\theta}\left( \vec{x}_{\sigma} \right)
  \end{equation*}

  \begin{enumerate}
    \item
      Сначала докажем несмещённость $\Lambda\hat{\theta}$.

      Нетрудно показать, что  вектора $\vec{x}$ и $\vec{x}_\sigma$
      имеют одинаковое распределение для любой перестановки $\sigma$,
      а это значит, что и оценки $\hat{\theta}\left(\vec{x}\right)$
      и $\hat{\theta}\left(\vec{x}_\sigma\right)$
      распределены одинаково как результаты применения оодной и той же
      функции к одинаково распределённым случайным векторам.
      Следовательно, их математические ожидания равны между собой
      при любой перестановке $\sigma$
      \begin{equation*}
        \meanof{\theta}{\hat{\theta}\left(\vec{x}\right)}
        = \meanof{\theta}{\hat{\theta}\left(\vec{x}_\sigma\right)}
        = \theta
      \end{equation*}

      Посчитаем математическое ожидание симметризации оценки $\hat{\theta}$
      \begin{align*}
        \meanof{\theta}{\Lambda\hat{\theta}}
        = \meanof{\theta}{\left\{\frac{1}{n!}\cdot \sum_{\sigma\in S_n}
          \hat{\theta}\left( \vec{x}_{\sigma} \right)\right\}}
        = \frac{1}{n!} \cdot \sum_{\sigma \in S_n}
          \meanof{\theta}{\hat{\theta}
            \left( \vec{x}_{\sigma} \right)}
        = \frac{1}{n!} \cdot \sum_{\sigma \in S_n} \theta
        = \theta
      \end{align*}
      \begin{comment}
      Помним, что математическое ожидание линейно и
      константы можно выносить за знак математического ожидания,
      а математическое ожидание суммы равно сумме математических ожиданий
      \begin{align*}
          \meanof{\theta}{\left\{\frac{1}{n!}\cdot \sum_{\sigma\in S_n}
        \hat{\theta}\left(\vec{x}_\sigma\right)\right\}}
        = \frac{1}{n!}\cdot \sum_{\sigma\in S_n}
            \meanof{\theta}{\hat{\theta}\left(\vec{x}_\sigma\right)}
      \end{align*}

      Не забываем, что математическое ожидание
      $\hat{\theta}\left( \vec{x}_{\sigma} \right)$ равно параметру
      $\theta$

      \begin{align*}
          \frac{1}{n!}\cdot \sum_{\sigma\in S_n}
        \meanof{\theta}{\hat{\theta}\left(\vec{x}_\sigma\right)}
        = \frac{1}{n!}\cdot \sum_{\sigma\in S_n}\theta
      \end{align*}

      Сумма имеет $n!$ слагаемых (количество перестановок $\sigma\in S_n$)
      \begin{align*}
          \frac{1}{n!}\cdot \sum_{\sigma\in S_n}\theta
        = \frac{1}{n!}\cdot n!\cdot \theta
        = \theta
      \end{align*}

      А это значит, что первый пункт доказан и симметризация
      несмещённой оценки $\hat{\theta}$ действительно несмещённая
      $$\meanof{\theta}{\Lambda\hat{\theta}}= \theta$$
      \end{comment}
    \item
      Теперь посмотрим, чему равна дисперсия симметризации
      оценки $\hat{\theta}$

      Воспользуемся определением
      \begin{align*}
          \dispersionof{\theta}{\Lambda\hat{\theta}}
        = \meanof{\theta}{
            \left(\Lambda\hat{\theta}-\theta\right)^2}
        = \meanof{\theta}{
            \left\{\frac{1}{n!}\cdot \sum_{\sigma\in S_n}
        \hat{\theta}\left(\vec{x}_\sigma\right)
        -\theta\right\}^2}
      \end{align*}

      Внесём параметр $\theta$ в сумму
      \begin{align*}
        &\meanof{\theta}{\left\{ \frac{1}{n!} \cdot \sum_{\sigma\in S_n}
          \hat{\theta}\left( \vec{x}_\sigma \right) - \theta \right\}^2}
        = \meanof{\theta}{
          \left\{ \frac{1}{n!}\cdot \sum_{\sigma\in S_n}
          \left( \hat{\theta}\left( \vec{x}_\sigma \right)
            - \theta \right) \right\}^2} = \\
        &= \meanof{\theta}{
          \left\{ \sum_{\sigma\in S_n}\frac{1}{n!}
            \cdot \left( \hat{\theta}\left(\vec{x}_\sigma \right)
              -\theta \right) \right\}^2}
      \end{align*}

      Воспользуемся неравенством Коши-Буняковского.
      Помним, что в $S_n$ находится $n!$ перестановок
      \begin{equation*}
        \begin{split}
          \left\{ \sum_{\sigma\in S_n} \frac{1}{n!}
            \cdot \left( \hat{\theta}\left( \vec{x}_{\sigma} \right)
              -\theta \right) \right\}^2
          & \le \sum_{\sigma \in S_n} \left( \frac{1}{n!} \right)^2
            \cdot \sum_{\sigma \in S_n} \left\{
              \hat{\theta}\left( \vec{x}_{\sigma} \right) - \theta \right\}^2 \\
          & = \frac{1}{n!} \cdot \sum_{\sigma\in S_n}
              \left( \hat{\theta}\left( \vec{x}_\sigma \right) -\theta \right)^2
        \end{split}
      \end{equation*}

      Тогда
      \begin{equation}\label{eq:meanSymmetrization}
          \meanof{\theta}{\left\{\sum_{\sigma\in S_n}\frac{1}{n!}\cdot
        \left(\hat{\theta}\left(\vec{x}_\sigma\right)
        -\theta\right)\right\}^2}
        \le \frac{1}{n!} \cdot \sum_{\sigma\in S_n} \meanof{\theta}{
            \left( \hat{\theta}\left( \vec{x}_\sigma \right)
            -\theta \right)^2}
      \end{equation}

      Видим сумму дисперсий.
      Дисперсии одинаковы, так как оценки имеют одинаковые распределения
      \begin{align*}
        &\frac{1}{n!}\cdot \sum_{\sigma\in S_n}
          \meanof{\theta}{
            \left(\hat{\theta}\left(\vec{x}_\sigma\right)
            -\theta\right)^2}
        = \frac{1}{n!}\cdot \sum_{\sigma\in S_n}
          \dispersionof{\theta}{
            \hat{\theta}\left(\vec{x}_\sigma\right)}= \\
        &= \frac{1}{n!}\cdot \sum_{\sigma\in S_n}
          \dispersionof{\theta}{\hat{\theta}\left(\vec{x}\right)}
        = \frac{1}{n!}\cdot n!
          \cdot \dispersionof{\theta}{\hat{\theta}\left(\vec{x}\right)}
        = \dispersionof{\theta}{\hat{\theta}\left(\vec{x}\right)}
      \end{align*}

      Из неравенства \eqref{eq:meanSymmetrization} видим,
      что дисперсия симметризации не хуже дисперсии самой оценки
      \begin{equation*}
        \dispersionof{\theta}{\Lambda\hat{\theta}}
          \le \dispersionof{\theta}{\hat{\theta}\left({\vec{x}}\right)}
      \end{equation*}

  \end{enumerate}

  То есть симметризация не ухудшает оценку,
  а в общем случае (когда неравенство строгое) даже делает её лучше.
\end{proof}


\begin{comment}
\begin{definition}[Функция вариационного ряда]\index{функция!вариационного ряда}
  Если оценка $\hat{\theta}$ симметрична относительно перестановок аргументов,
  то она является функцией вариационного ряда
\end{definition}
\end{comment}

\begin{remark}
  В предыдущем примере \ref{example:optimalEstimate} выполняется равенство
  \begin{equation*}
    \Lambda \hat{\theta} = \overline{x}
  \end{equation*}
\end{remark}

\begin{remark}
  Любая оптимальная оценка является функцией вариационного ряда
\end{remark}

\section{$\sigma$-алгебра, порождённая случайной величиной}
Есть вероятностное пространство
$\left( \Omega, \mathfrak{F}, \mathbb{P} \right)$
и случайная величина $\xi$.

\begin{definition}[Сигма-алгебра, порождённая случайной величиной]
  \index{сигма-алгебра!порождённая!случайной величиной}
  $\mathfrak{F}_\xi = \sigma\left( \xi \right)$
  --- $\sigma$-алгебра, порождённая случайной величиной $\xi$
  $$\mathfrak{F}_\xi
      = \left\{ \xi^{-1}\left( \Delta \right)
      \mcond \Delta\in\mathfrak{B} \right\}$$
  $\mathfrak{B}$ --- борелевская $\sigma$-алгебра в $\mathbb{R}$.
\end{definition}

Из курса теории вероятностей помним лемму, которая утверждает,
что $\xi$ --- случайная величина тогда и только тогда, когда
\begin{equation*}
  \forall\Delta\in\mathfrak{B}:\qquad
  \left\{ \omega \mcond \xi\left( \omega \right) \in \Delta \right\}
  = \left\{ \xi\in\Delta \right\}
  = \xi^{-1}\left( \Delta \right) \in \mathfrak{F}
\end{equation*}

А это значит, что все элементы $\mathfrak{F}_\xi$ входят в $\sigma$-алгебру
$\mathfrak{F}$, а сама $\mathfrak{F}_\xi$ является подмножеством
$\mathfrak{F}$
\begin{align*}
  \begin{cases}
      \mathfrak{F}_\xi
      = \left\{ \xi^{-1}\left( \Delta \right)
          \mcond \Delta\in\mathfrak{B} \right\}\\
      \forall\Delta\in\mathfrak{B}:
      \xi^{-1}\left( \Delta \right) \in \mathfrak{F}
  \end{cases}
  \Rightarrow
  \mathfrak{F}_\xi \subset \mathfrak{F}
\end{align*}

Проверим, что $\mathfrak{F}_\xi$ действительно является $\sigma$-алгеброй.
\begin{enumerate}
  \item Множество элементарных исходов $\Omega$ входит в $\mathfrak{F}_\xi$.
      Поскольку случайная величина $\xi$ принимает действительные значения,
      то прообраз множества действительных чисел $\mathbb{R}$
      и будет множеством элементарных исходов $\Omega$.
      \begin{align*}
        \begin{cases}
          \xi^{-1}\left( \Delta \in \mathfrak{B} \right) \in \mathfrak{F} \\
          \mathbb{R} \in \mathfrak{B} \\
          \xi^{-1}\left( \mathbb{R} \right)= \Omega
        \end{cases}
        \Rightarrow
        \Omega \in \mathfrak{F}_\xi
      \end{align*}
  \item Если событие $A$ принадлежит $\mathfrak{F}_\xi$,
      то его дополнение $\stcomp{A}$ тоже принадлежит $\mathfrak{F}_\xi$
      \begin{align*}
        A
        = \xi^{-1}\left( \Delta \right)
        = \left\{ \omega \mcond \xi\left( \omega \right) \in \Delta \right\}
      \end{align*}
      Значит,
      \begin{align*}
        \stcomp{A}
        = \left\{ \omega \mcond \xi\left( \omega \right) \notin \Delta \right\}
        = \left\{ \omega \mcond \xi\left( \omega \right)
          \in \stcomp{\Delta}\right\}
        = \xi^{-1}\left( \stcomp{\Delta} \right)
      \end{align*}

      Поскольку $\mathfrak{B}$ является $\sigma$-алгеброй,
      а $\Delta$ --- её элемент,
      то дополнение $\stcomp{\Delta}$ тоже принадлежит
      $\sigma$-алгебре $\mathfrak{B}$.
      Из этого следует, что свойство выполняется
      \begin{align*}
      \begin{cases}
          \xi^{-1}\left( \Delta \right) \in \mathfrak{F}\\
          \Delta \in \mathfrak{B}
        \Rightarrow \stcomp{\Delta} \in \mathfrak{B}
      \end{cases}
      \Rightarrow
      \stcomp{\xi^{-1}\left( \Delta \right)}
          = \xi^{-1}\left( \stcomp{\Delta} \right) \in \mathfrak{F}
      \end{align*}
  \item Замкнутость относительно счётных пересечений.
    Пусть $A_n = \xi^{-1}\left( \Delta_n \right)$, $n \ge 1$,
    $\Delta_n \in \mathfrak{B}$.
    Тогда
    \begin{equation*}
      \bigcap_{n=1}^{\infty} A_n
      = \xi^{-1}\left( \bigcap_{n=1}^{\infty} \Delta_n \right).
    \end{equation*}
    Так как $\mathfrak{B}$ --- $\sigma$-алгебра, то
    \begin{equation*}
      \bigcap_{n=1}^{\infty} \Delta_n \in \mathfrak{B}.
    \end{equation*}
    Следовательно,
    \begin{equation*}
      \xi^{-1}\left( \bigcap_{n=1}^{\infty} \Delta_n \right)
      \in \mathfrak{F}_{\xi}
    \end{equation*}
\end{enumerate}

Как устроена эта $\sigma$-алгебра?
Каждому элементарному исходу отвечает одно и только одно значение
случайной величины, а каждому значению случайной величины
отвечает один и больше элементарных исходов.
Допустим, есть некое $a\in\mathbb{R}$, которое является образом по крайней мере
двух элементарных исходов $\omega_1$ и $\omega_2$
(рисунок \ref{fig:tikz:indistinguishableValuesImage})

$$\xi\left( \omega_1 \right) = \xi\left( \omega_2 \right) = a$$

\begin{figure}[h!]
  \center\includestandalone{tikz/indistinguishableValuesImage}
  %\center\includegraphics[width=\textwidth]{tikz/indistinguishableValuesImage.pdf}
  \caption{Множества уровней}
  \label{fig:tikz:indistinguishableValuesImage}
\end{figure}


Теперь рассмотрим элемент $\Delta$ борелевской $\sigma$-алгебры $\mathfrak{B}$.
Из вышесказанного следует, что,
если число $a$ принадлежит множеству $\Delta$, то прообраз этого множества
содержит элементы $\omega_1$ и $\omega_2$,
в противном случае оба элементарных исхода не входят в прообраз
\begin{align*}
  a \in \Delta
      \Rightarrow \xi^{-1}\left( \Delta \right) \ni \omega_1, \omega_2 \\
  a \notin \Delta
      \Rightarrow \xi^{-1}\left( \Delta \right) \not\ni \omega_1, \omega_2 \\
\end{align*}

То есть множество $\mathfrak{F}_\xi$ не будет различать
элементы $\omega_1$ и $\omega_2$.
Это в свою очередь означает, что можно разбить $\Omega$
на уровни --- непересекающиеся подмножества, не различимые с помощью
$\mathfrak{F}_{\xi}$.

\begin{definition}[Множество уровня]\index{множество уровня}
  Множество уровня $H_t$ --- полный прообраз
  значения $t\in\mathbb{R}$ случайной величины $\xi$
  $$H_t
      = \left\{ \omega \mcond \xi\left( \omega \right) = t \right\}
      = \xi^{-1}\left( t \right)$$
\end{definition}

\begin{remark}
  Уровни $H_i$ составляют разбиение множества элементарных исходов $\Omega$.
  \begin{enumerate}
      \item Множества $H_i$ не пересекаются
        \begin{equation*}
          H_{t_1} \cap H_{t_2} = \emptyset \Leftrightarrow t_1 \neq t_2 
        \end{equation*}
      \item Объединение всех $H_i$ даёт множество элементарных исходов
      $$\bigcup_{t \in \mathbb{R}} H_t
          = \bigcup_{t \in \mathbb{R}} \xi^{-1}\left( t \right)
          = \xi^{-1}\left( \mathbb{R} \right)
          = \Omega$$
  \end{enumerate}
\end{remark}

Очень похоже на гипотезы из курса теории вероятностей с той лишь разницей,
что уровней может быть бесконечное и даже континуальное количество,
из чего также следует, что вероятность некоторых из них может быть нулевой.

\section{Случайная величина, измеримая относительно $\sigma$-алгебры}
В общем случае вероятностное пространство может быть разбито
на континуальное количество множеств уровней
(для $\sigma$-алгебры, порождённой непрерывной случайной величиной).
Начнём же с рассмотрения того случая,
когда случайная величина $\xi$ принимает $n$ значений
$a_1, a_2, \dots, a_n$
$$\xi: \Omega \rightarrow \left\{ a_1, a_2, \dots, a_n \right\}$$
Это означает, что у нас есть $n$ уровней
$$H_k = \left\{ \omega \mcond \xi\left( \omega \right) = a_k \right\},
  k= \overline{1,n}$$
Нетрудно понять,
что $\sigma$-алгебра $\sigma\left( \xi \right)$ содержит $2^n$ элементов
$$\sigma\left( \xi \right) = \left\{ \bigcup_{k=1}^n H_k^{\eta_k}
  \mcond \eta_k = \overline{0,1}, H_k^0 = \emptyset, H_k^1 = H_k \right\}$$

\begin{definition}[Сигма-алгебра, порождённая полным набором гипотез]
  \index{сигма-алгебра!порождённая!полным набором гипотез}
  Возьмём набор множеств $H_1, \dots, H_n$ который является полным набором
  гипотез для пространства элементарных исходов $\Omega$
  $$\bigcap_{k=1}^n H_k = \emptyset,\; \bigcup_{k=1}^n H_k = \Omega,\;
      \Probability{H_k} \neq 0$$

  В таком случае $\sigma$-алгебра, содержащая всевозможные объединения этих
  множеств, будет называться $\sigma$-алгеброй, порождённой полным набором
  гипотез и будет выглядеть следующим образом
  $$\mathfrak{F}_1 = \left\{ \bigcup_{k=1}^n H_k^{\eta_k}
      \mcond \eta_k = \overline{0,1},
      H_k^0 = \emptyset, H_k^1 = H_k \right\}$$
\end{definition}

\begin{definition}[Случайная величина, измеримая относительно сигма-алгебры]
  \index{случайная величина!измеримая относительно сигма-алгебры}
  Случайная величина $\varkappa$ называется измеримой относительно
  $\sigma$-алгебры $\mathfrak{F}_1$, если
  \begin{equation*}
    \forall \Delta \in \mathfrak{B}:\qquad
      \left\{ \omega \mcond \varkappa\left( \omega \right) \in \Delta \right\}
      \in \mathfrak{F}_1
  \end{equation*}
\end{definition}

Нас интересует, как устроены случайные величины,
которые измеримы относительно $\sigma$-алгебры $\sigma\left( \xi \right)$.

\begin{affirmation}\label{measurableRandomVariable}
  Пусть случайная величина принимает $n$ значений $a_1$, $\dots$, $a_n$
  \begin{equation*}
    \xi: \Omega \rightarrow \left\{ a_1, \dots, a_n \right\}
  \end{equation*}
  Случайная величина $\varkappa$ измерима относительно
  $\sigma\left( \xi \right)$ тогда и только тогда, когда
  $\varkappa = f\left( \xi \right)$ для некоторой функции
  \begin{equation*}
    f: \left\{ a_1, \dots, a_n \right\} \rightarrow \mathbb{R}
  \end{equation*}
\end{affirmation}
\begin{proof}
  Докажем сначала необходимость.
  Из вида $\sigma$-алгебры $\sigma\left( \xi \right)$ следует, что множества
  из $\sigma\left( \xi \right)$ либо целиком содержат определённые множества
  уровней $H_k$, либо не пересекаются с ними
  \begin{equation*}
    \forall A \in \sigma\left( \xi \right),
    \forall k \in \left\{ 1, \dots, n \right\}: \qquad
    A \cap H_k \neq \emptyset \Rightarrow H_k \subset A
  \end{equation*}
  Для произвольной измеримой относительно $\sigma\left( \xi \right)$ случайной
  величины $\varkappa$ положим
  \begin{equation*}
    \forall k \in \left\{ 1, \dots, n \right\},
    \forall \omega_k \in H_k:\qquad
    c_k = \varkappa\left( \omega_k \right)
  \end{equation*}
  Введём обозначение
  \begin{equation*}
    \forall k \in \left\{ 1, \dots, n \right\}:\qquad
    A_k = \left\{ \omega \mcond \varkappa\left( \omega \right) = c_k \right\}
  \end{equation*}
  Получаем
  \begin{equation*}
    \forall k \in \left\{ 1, \dots, n \right\}:\qquad
    \omega_k \in A_k \cap H_k
    \Rightarrow A_k \cap H_k \neq \emptyset
    \Rightarrow H_k \subset A_k
  \end{equation*}
  Значит,
  \begin{equation*}
    \forall \omega \in H_k: \varkappa\left( \omega \right) = c_k
  \end{equation*}
  Введём функцию
  \begin{equation*}
    \forall k \in \left\{ 1, \dots, n \right\}:\forall
    f\left( a_k \right) = c_k
  \end{equation*}
  Имеем
  \begin{equation*}
    \varkappa\left( \omega \right)
    = \sum_{k=1}^{n} c_k \cdot \Indicator{\xi\left( \omega \right) = a_k}
    = f\left( \xi\left( \omega \right) \right)
  \end{equation*}

  Докажем достаточность.
  Пусть $\varkappa = f\left( \xi\left( \omega \right) \right)$.
  Обозначим
  \begin{equation*}
    \forall k \in \left\{ 1, \dots n \right\}:\qquad
    c_i = f\left( a_k \right)
  \end{equation*}
  Тогда для произвольного $\Delta \in \mathfrak{B}\left( \mathbb{R} \right)$
  \begin{equation*}
    \begin{split}
      \left\{ \omega \mcond \varkappa\left( \omega \right) \in \Delta \right\}
      &= \bigcup_{k=1}^n H_k \cap 
        \left\{ \omega \mcond \varkappa\left( \omega \right)
          \in \Delta \right\} = \\
      &= \bigcup_{k=1}^n \left\{ \omega \mcond
        \xi\left( \omega \right) = a_k,
        f\left( \xi\left( \omega \right) \in \Delta \right) \right\} = \\
      &= \bigcup_{k=1}^n \left\{ \omega \mcond
        \xi\left( \omega \right) = a_k \right\},
        f\left( a_k \right) \in \Delta = \\
      &= \bigcup_{k=1}^n \left\{ \omega \mcond
        \xi\left( \omega \right) = a_k, c_i \in \Delta \right\}
      = \bigcup_{k=1}^n H_i^{\eta_i},
    \end{split}
  \end{equation*}
  где
  \begin{equation*}
    \eta_k = \begin{cases}
      0,& c_k \notin \Delta \\
      1,& c_k \in \Delta
    \end{cases}
  \end{equation*}
  Видим, что
  \begin{equation*}
    \left\{ \omega \mcond \varkappa\left( \omega \right) \in \Delta \right\}
      \in \sigma\left( \xi \right)
  \end{equation*}
  Теорема доказана.
\end{proof}

Легко увидеть, что все наши рассуждения остаются верными, если рассматривать не
конечные наборы гипотез, а счётные (соответственно, случайные величины,
принимающие счётное количество значений).
В таком случае $\sigma$-алгебра $\mathfrak{F}_1$ содержит континуальное число
элементов, а утверждение \ref{measurableRandomVariable} остаётся в силе
\begin{equation*}
  \mathfrak{F}_1
  = \left\{ \bigcup_{k=1}^{\infty} H_k^{\eta_k} \mcond
    \eta_k = \overline{0, 1}, H_k^0 = \emptyset, H_k^1 = H_k \right\}
\end{equation*}

Справедливо гораздо более общее утверждение, касающееся случайных величин с произвольным распределением.

\begin{theorem}
  Случайная величина $\eta$ измерима относительно $\sigma$-алгебры,
  порождённой случайной величиной $\xi$, тогда и только тогда,
  когда существует борелевская функция
  \begin{equation*}
    f: \mathbb{R} \rightarrow \mathbb{R}
  \end{equation*}
  такая, что
  \begin{equation*}
    f\left( \xi \right) = \eta
  \end{equation*}
  \cite[с.~219]{Shiryayev1}.
\end{theorem}
