\section{Условные распределения}
\index{условное!распределение}

\begin{definition}[Условное распределение]
    Условное распределение случайной величины $\xi$
    при известной $\sigma$-алгебре $\mathfrak{F}_1$ --- это функция $\pi$
    $$\pi: \Omega \times \mathfrak{B} \rightarrow \left[ 0, 1 \right]$$
    
    Функция $\pi$ должна обладать следующими свойствами
    \begin{enumerate}
        \item На любом элементе $\Delta$ борелевского множества $\mathfrak{F}_1$
            функция $\pi\left( \cdot, \Delta \right)$ является измеримой
            относительно $\mathfrak{F}_1$
        \item На любом элементарном исходе из множества $\Omega$
            функция $\pi\left( \omega, \cdot \right)$
            является вероятностной мерой
        \item Выполняется равенство
            $$\forall \Delta \in \mathfrak{B}: \pi\left( \cdot, \Delta \right)
                = \Mean{\Indicator{\xi \in \Delta} \mcond \mathfrak{F}_1}$$

            Это равенство нам уже знакомо, поэтому ничего принципиально нового
            не добавилось
            $$\probability{\xi \in \Delta} = \mean{\Indicator{\xi \in \Delta}}$$
    \end{enumerate}

    Обозначение
    $$\pi\left( \cdot, \Delta \right)
        = \probability{\xi \in \Delta \mcond \mathfrak{F}_1}$$

    Если же $\sigma$-алгебра $\mathfrak{F}_1$ порождена
    случайной величиной $\eta$: $\mathfrak{F}_1 = \sigma\left( \eta \right)$,
    работает следующее обозначение
    $$\probability{\xi \in \Delta \mcond \sigma\left( \eta \right)}
        = \pdf{\eta, \Delta}$$

    Когда нас интересует событие $\eta = t$, работает следующее обозначение
    $$\probability{t, \Delta} = \pdf{\xi \in \Delta \mcond \eta = t}$$

    Связь с условным математическим ожиданием
    $$\Mean{f\left( \xi \right) \mcond \eta = t}
        = \integrall{\mathbb{R}}{\pdf{t, du}}{f\left( u \right)}$$
\end{definition}

\begin{remark}
    В обозначениях выше точка вместо аргумента означает,
    что на выходе мы получаем не определённое значение,
    а функцию от того аргумента, который заменён точкой.

    Например, запись $\pi\left( \cdot, \Delta \right)$
    означает некую функцию $\rho$
        $$\rho: \Omega \rightarrow \left[ 0, 1 \right]$$

    Значение этой функции будет считаться по формуле
        $$\rho\left( \omega \right) = \pi\left( \omega, \Delta \right)$$
\end{remark}

Рассмотрим примеры вычисления условных распределений

\begin{example}[См. пример \ref{discreteConditionalExpectationExample}]
    Случайные величины $\xi$ и $\eta$ имеют совместное дискретное распределение
    $$\Probability{\xi = a_i, \eta = b_j} = p_{ij}$$

    В таком случае условное распределение считается по формуле
    $$\Probability{\xi = a_i, \eta = b_j} = \frac{p_{ij}}{\sum_j p_{ij}}$$
\end{example}

\begin{example}[См. формулу \ref{phiIntegral}]
    Случайные величины $\xi$ и $\eta$ имеют
    совместную плотность распределения $\pdf{x,y}$
        $$\frac{\integral{\Delta}{}{y}{y \cdot \pdf{x,y}}}
            {\integral{\mathbb{R}}{}{y}{\pdf{x,y}}}$$
\end{example}

\begin{example}[См. теорему \ref{conditionalExpectationDefinition}]
    У случайного вектора $\vec{x}$ есть плотность распределения $\pdf{\vec{u}}$.
    Тогда условное распределение $f\left( \vec{x} \right)$ относительно
    гладкой функции $g\left( \vec{x} \right)$ считается по формуле
    $$\probability{f\left( \vec{x} \right) \in \Delta
        \mcond g\left( \vec{x} \right) = t}
        = \frac{\integrall{S_t \cap \Delta}{\sigma_{t}\left(d\vec{u} \right)}{
            \pdf{\vec{u}} \cdot \frac{1}{
                \left\| \vec{\nabla} \cdot g\left( \vec{u} \right) \right\|}}}
            {\integrall{S_t}{\sigma_{t}\left(d\vec{u} \right)}{
                \pdf{\vec{u}} \cdot \frac{1}{
                    \left\| \vec{\nabla}
                        \cdot g\left( \vec{u} \right) \right\|}}}$$
\end{example}

\section{Достаточные статистики}
Как говорилось в подразделе \ref{conditionalExpectationSubsection},
условное математическое ожидание нам понадобилось из-за наличия
статистик $T$, обладающих особыми свойствами.
Пришло время о них поговорить

\begin{definition}[Достаточная статистика]\index{статистика!достаточная}
    Статистика $T\left( x_1, x_2, \dots, x_n \right)$ --- достаточная статистика
    для параметра $\theta$, если условное распределение выборки
    при известном $T$ не зависит от $\theta$
\end{definition}

Осмыслим написанное
\begin{enumerate}
    \item Речь идёт об условном распределении всей выборки.
        Никаких новых инструментов, к счастью, не появилось:
        $$\pi\left( T, \Delta \right)
            = \probability{\vec{x} \in \Delta \mcond T}$$
    \item Почему возникает определение достаточных статистик?
        Пускай $T$ --- достаточная статистика.
        Как с её помощью получить распределение всей выборки?
        $$\Probability{\vec{x} \in \Delta}
            = \mean{\Indicator{\vec{x} \in \Delta}}$$

        Далее воспользуемся
        \ref{conditionalExpectationProperty:totalProbability}
        свойством условного математического ожидания
        (формула полной вероятности)
        $$\mean{\Indicator{\vec{x} \in \Delta}}
            = \mean{\Mean{\Indicator{\vec{x} \in \Delta} \mcond T}}$$

        Помним, что условное математическое ожидание
        относительно $\sigma$-алгебры, порождённой случайной величиной $T$
        (функция случайного вектора является случайной величиной),
        является случайной величиной, измеримой
        относительно $\sigma\left( T \right)$.
        Мы также помним, что ``быть измеримой относительно $\sigma$-алгебры,
        порождённой случайной величиной $T$'', это то же самое, что
        ``быть функцией случайной величины $T$''
        (утверждение \ref{measurableRandomVariable}), а это значит,
        что существует функция $f$ такая, что
        $$\Mean{\Indicator{\vec{x} \in \Delta \mcond T}} = f\left( T \right)$$

        Тогда получаем такое красивое равенство
        $$\Probability{\vec{x} \in \Delta} = \mean{f\left( T \right)}$$
\end{enumerate}

\begin{theorem}[Об улучшении оценки с помощью достаточной статистики]
    \index{оценка!улучшенная}
    Пусть $x_1, \dots, x_n$ --- выборка из распределения $\cdfof{\theta}{x}$,
    $\theta \in \Theta$.
    Есть $T$ --- достаточная статистика для параметра $\theta$,
    а также несмещённая оценка $\hat{\theta}$ параметра $\theta$.
    Введём оценку $\theta_*$
    $$\theta_* = \Mean{\hat{\theta} \mcond T}$$

    Оценка $\theta_*$ не хуже, чем оценка $\hat{\theta}$
    $$\begin{cases}
        \meanof{\theta}{\theta_*} = \theta \\
        \dispersionof{\theta}{\theta_*} \le \dispersionof{\theta}{\hat{\theta}}
    \end{cases}$$
\end{theorem}

\begin{remark}
    Оценка $\theta_* = \Mean{\hat{\theta} \mcond T}$ не зависит от $\theta$,
    так как $T$ --- достаточная статистика
\end{remark}

\begin{remark}
    ``Как правило'', одномерная достаточная статистика
    для одномерного параметра даёт не улучшаемую статистику
\end{remark}

\begin{proof}
    \begin{enumerate}
        \item С первым пунктом всё просто:
            пользуемся формулой полной вероятности
            (\ref{conditionalExpectationProperty:totalProbability} свойство)
            $$\meanof{\theta}{\theta_*}
                = \meanof{\theta}{\Mean{\hat{\theta} \mcond T}}
                = \meanof{\theta}{\hat{\theta}}
                = \theta$$
        \item Тут же доказательство пройдёт в несколько этапов.

            Сначала распишем дисперсию и и оценку $\theta_*$ по определению
            $$\dispersionof{\theta}{\theta_*}
                = \meanof{\theta}{\left( \theta_* - \theta \right)^2}
                = \meanof{\theta}{\left( \Mean{\hat{\theta} \mcond T}
                    - \theta \right)^2}$$

            Поскольку $T$ --- достаточная статистика и не зависит от $\theta$,
            то $\theta$ измерима относительно $\sigma\left( T \right)$
            и является константой. Значит, можно переписать
            статистику $\theta$ как условное математическое ожидание
            (\ref{conditionalExpectationProperty:measurableRandomVariable}
            свойство), а затем воспользоваться линейностью
            условного математического ожидания
            (\ref{conditionalExpectationProperty:linearity} свойство)
            \begin{align*}
                \meanof{\theta}{\left( \Mean{\hat{\theta} \mcond T}
                        - \theta \right)^2}
                    = \meanof{\theta}{\left( \Mean{\hat{\theta} \mcond T}}
                        - \Mean{\theta \mcond T} \right)^2 = \\
                    = \meanof{\theta}{\left(
                        \Mean{\left( \hat{\theta} - \theta \right) \mcond T}
                        \right)^2}
            \end{align*}

            Дальше воспользуемся неравенством Йенсена
            (\ref{conditionalExpectationProperty:Jensen} свойство)
            и формулой полной вероятности
            (\ref{conditionalExpectationProperty:totalProbability} свойство)
            \begin{align*}
                \meanof{\theta}{\left( \Mean{\left( \hat{\theta}
                        - \theta \right) \mcond T}\right)^2}
                    \le \meanof{\theta}{\Mean{\left( \hat{\theta}
                        - \theta \right)^2 \mcond T}} = \\
                    = \meanof{\theta}{\left( \hat{\theta} -\theta \right)^2}
                    = \dispersionof{\theta}{\hat{\theta}}
            \end{align*}
    \end{enumerate}
\end{proof}

\begin{remark}
    Равенство в неравенстве Йенсена выше возможно,
    когда условное распределение вырождается в одну точку.
    Когда условное распределение не вырождено,
    то неравенство оказывается строгим.
\end{remark}

\begin{remark}
    Оценка $\theta_* = \Mean{\hat{\theta} \mcond T}$ измерима относительно $T$
    по определению условного математического ожидания, а это значит,
    что она является функцией от $T$.

    Пусть $\tilde{\theta}$ --- оптимальная несмещённая оценка.
    Тогда $\theta_* = \Mean{\hat{\theta} \mcond T}$ --- оптимальная, а значит,
    эти оценки равны $\theta_* = \tilde{\theta}$ по теореме единственности
    (теорема Колмогорова \ref{theorem:Kolmogorov}),
    поскольку оптимальная оценка либо одна, либо не существует вовсе.
    Значит, оптимальная оценка --- функция достаточной статистики.
\end{remark}

\begin{theorem}[О факторизации достаточной статистики]
    Пусть $x_1, \dots, x_n$ --- выборка из распределения
    с плотностью $\pdf{x,\theta}$, $\theta \in \Theta$.

    Статистика $T$ является достаточной тогда и только тогда, когда
    функция правдоподобия $L\left( \vec{x}, \theta \right)$
    допускает факторизацию, то есть может быть представлена
    произведением двух функций следующего вида
    $$L\left( \vec{x}, \theta \right)
        = h\left( T, \theta \right) \cdot g\left( \vec{x} \right)$$
\end{theorem}

\begin{proof}[Наброски доказательства для гладкой функции правдоподобия]
    Условное распределение выборки при известной статистике
    $T=f\left( \vec{x} \right)$ определяется формулой
    $$\probability{\vec{x} \in \Delta \mcond T = t}
        = \frac{\integrall{S_t \cap \Delta}{\sigma_{t}\left(d\vec{u} \right)}{
            L\left( \vec{u}, \theta \right) \cdot \frac{1}{
                \left\| \vec{\nabla} \cdot f\left( \vec{u} \right) \right\|}}}
            {\integrall{S_t}{\sigma_{t}\left(d\vec{u} \right)}{
                L\left( \vec{u}, \theta \right) \cdot \frac{1}{
                    \left\| \vec{\nabla}
                        \cdot f\left( \vec{u} \right) \right\|}}}$$
    \begin{enumerate}
        \item[Достаточность]
        \item[Необходимость]
    \end{enumerate}
\end{proof}
