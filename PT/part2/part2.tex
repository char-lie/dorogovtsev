\chapter{Вероятность}

\section{Условная вероятность}
$A$, $B$ --- случайные события, $\probability{B}>0)$
\begin{definition}\index{вероятность!условная}
    Условная вероятность события $A$ при условии $B$
    (при условии, что $B$ произошло)
    $$\probability{A\mid B}
    =\frac{\mathbb{P}\left(A\cap B\right)}{\probability{B}}$$
\end{definition}
Очевидные свойства:
\begin{enumerate}
    \item $\probability{B\mid B}=1$
    \item $\probability{\Omega\mid B}=1$
    \item $\probability{\emptyset\mid B}=0$
\end{enumerate}

\begin{example}Игральный кубик подбрасывается два раза.
    Событие $A$ состоит в том, что сумма очков равна $9$.
    Событие $B$ состоит в том, что во второй раз выпадет чётная цифра.
    \begin{alignat*}{3}
        \Omega&=\left\{\left(i,j\right)\mid i,j=\overline{1,6}\right\}
        &\Rightarrow&\left|\Omega\right|=6\cdot 6=36\\
        A&=\left\{\left(3,6\right),\left(4,5\right),\left(5,4\right),
            \left(6,3\right)\right\}
        &\Rightarrow&\left|A\right|=4\\
        B&=\left\{\left(i,k\right)\mid i=\overline{1,6}, k=2,4,6\right\}
        &\Rightarrow&\left|B\right|=6\cdot 3=18\\
        A\cap B&=\left\{\left(3,6\right), \left(5,4\right)\right\}
        &\Rightarrow&\left|A\cap B\right|=2\\
        \probability{B}&=\frac{\left|B\right|}{\left|\Omega\right|}
            =\frac{18}{36}=\frac{1}{2}\\
        \probability{A\cap B}&=\frac{\left|A\cap B\right|}{\left|\Omega\right|}
            =\frac{1}{18}\\
        \probability{A\mid B}&=\frac{\frac{1}{18}}{\frac{1}{2}}=\frac{1}{9}\\
    \end{alignat*}

\end{example}
\section{Формула полной вероятности}
\begin{definition}[Полный набор гипотез]\index{полный набор гипотез}
    Набор событий $H_1, H_2, \dots, H_n$ называется полным набором гипотез,
    если выполняются следующие условия:
    \begin{enumerate}
        \item Вероятность ни одного из них не равна нулю
            $$\probability{H_k}>0, k=\overline{1,n}$$
        \item Они попарно не пересекаются
            $$H_i\cap H_j=\emptyset, i\neq j$$
        \item Их объединение составляет вероятностное пространство
            $$\bigcup_{k=1}^n H_k=\Omega$$
    \end{enumerate}
    Свойства очень похожи на определение разбиения множества,
    но с одной поправкой: условие $1$ более сильное, так как ранее
    было показано, что бывают непустые множества, вероятность которых
    равна нулю.
\end{definition}
\begin{lemma}
    Если набор $H_1, \dots, H_n$ является разбиением множества $\Omega$,
    то для его произвольного непустого подмножества $A\subset\Omega$
    семейство $G=\left\{H_k\mid A\cap H_k\neq \emptyset\right\}$
    будет разбиением.
\end{lemma}
\begin{proof}
    Обозначим через $m$ количество элементов в множестве $G$
    $$m=\left|G\right|$$

    Первое свойство очевидно выполняется по построению:
    в семейство входят только ненулевые множества.

    Выполнение второго свойства показать просто
    $$G_i\cap G_j = \left(A\cap H_i\right)\cap \left(A\cap H_j\right)
    =\left(H_i\cap H_j\right)\cap A=\emptyset, i\neq j$$

    Чтобы показать то, что выполняется и третье свойство,
    нужно немного подумать
    $$\bigcup_{k=1}^m G_k
    =\bigcup_{A\cap H_k\neq\emptyset} \left(A\cap H_k\right)$$

    Поскольку объединение любого множества $A$ с пустым даст исходное
    множество ($A\cup \emptyset=A$), то к объединению можно добавить
    и пустые пересечения --- те $A\cap H_k$, которые не содержат элементов,
    от чего и не попали в $G$
    $$\bigcup_{k=1}^m G_k=\bigcup_{k=1}^n \left(A\cap H_k\right)$$

    А дальше всё тривиально
    $$\bigcup_{k=1}^m G_k=\bigcup_{k=1}^n \left(A\cap H_k\right)
    =A\cap\left(\bigcup_{k=1}^n H_k\right)=A\cap\Omega=A$$
\end{proof}
\begin{lemma}[Формула полной вероятности]
    \index{вероятность!полная}\index{формула!полной вероятности}
    $\Omega$ --- вероятностное пространство,
    $\Omega\supset A$ --- случайное событие,
    $\Omega\supset H_1, \dots, H_n$ --- полный набор гипотез.
    Тогда
    $$\probability{A}
    =\sum_{k=1}^n \probability{A\mid H_k}\cdot \probability{H_k}$$
\end{lemma}
\begin{proof}
    Когда $\probability{A}=0$, то доказательство очевидно,
    так как $\probability{A\mid H_k}=0, \forall H_k$.

    Займёмся случаем, когда $\probability{A}\neq 0$. Поскольку
    $\left\{H_k \mid k=\overline{1,n}\right\}$ --- разбиение $\Omega$,
    то семейство
    $G=\left\{A\cap H_k\mid A\cap H_k\neq\emptyset\right\}$ --- разбиение $A$
    ($\left|G\right|=m$),
    а это значит, что сумма мощностей всех $G_k$
    равняется мощности их объединения,
    а их объединение --- это и есть множество $A$
    $$\sum_{k=1}^m \left|G_k\right| = \left|\bigcup_{k=1}^m G_k\right|
    =\left|A\right|$$

    Перепишем по-другому это равенство, пользуясь тем, что
    добавление нуля к сумме ничего не меняет:
    ведь могут быть такие пересечения $A\cap H_k$,
    которые являются пустыми множествами,
    а это значит, что их мощность равна $0$
    ($A\cap H_k=\emptyset\Rightarrow\left|A\cap H_k\right|=0$)
    $$\left|A\right|=\sum_{k=1}^m \left|G_k\right|
    =\sum_{A\cap H_k\neq\emptyset} \left|A\cap H_k\right|
    =\sum_{k=1}^n \left|A\cap H_k\right|$$

    Поделим обе части на мощность вероятностного пространства $|\Omega|$
    $$\frac{\left|A\right|}{\left|\Omega\right|}
    =\sum_{k=1}^n \frac{\left|A\cap H_k\right|}{\left|\Omega\right|}$$

    Теперь видим вероятность события $A$ слева
    и сумму вероятностей того,
    что это событие произошло вместе с каждой гипотезой $H_k$, справа
    $$\probability{A}=\sum_{k=1}^n \probability{A\cap H_k}$$

    Умножаем правую часть на единицу и получаем желаемый результат
    $$\probability{A}
    =\sum_{k=1}^n \left(\probability{A\cap H_k}\cdot
        \frac{\probability{H_k}}{\probability{H_k}}\right)
    =\sum_{k=1}^n \left(\frac{\probability{A\cap H_k}}{\probability{H_k}}
        \cdot\probability{H_k}\right)$$

    Последняя дробь по определению является вероятностью $A$ при условии
    того, что произошло событие $H_k$. Таким образом, лемма доказана
    $$\probability{A}
    =\sum_{k=1}^n \probability{A\mid H_k}\cdot\probability{H_k}$$

\end{proof}
\section{Формула Байеса}
Постановка задачи: Имеется вероятностное пространство $\Omega$,
случайное событие $A\subset\Omega$,
$H_1,\dots,H_n$ --- полный набор гипотез,
вероятности $\probability{H_k}$ и $\probability{A\mid H_k}$ известны
для каждой гипотезы. Нужно найти $\probability{H_k\mid A}$.
\begin{lemma}[Формула Байеса]\index{формула!Байеса}
    $$\probability{H_k\mid A}
    =\frac{\probability{A\mid H_k}\cdot\probability{H_k}}
    {\displaystyle\sum_{i=1}^n \probability{A\mid H_i}\cdot\probability{H_i}}
    $$
\end{lemma}
\begin{proof}
    Начнём с определения условной вероятности
    $$\probability{H_k\mid A}
    =\frac{\probability{H_k\cap A}}{\probability{A}}
    $$
    
    Распишем знаменатель по формуле полной вероятности,
    а числитель умножим на $1$
    $$
    \frac{\probability{H_k\cap A}}{\probability{A}}
    =\frac{\probability{A\cap H_k}\cdot
    \frac{\probability{H_k}}{\probability{H_k}}}
    {\displaystyle\sum_{i=1}^n \probability{A\mid H_i}\cdot\probability{H_i}}
    $$

    В числителе получилась условная вероятность,
    умноженная на вероятность гипотезы --- формула Байеса доказана
    $$\probability{H_k\mid A}
    =\frac{\probability{A\mid H_k}\cdot\probability{H_k}}
    {\displaystyle\sum_{i=1}^n \probability{A\mid H_i}\cdot\probability{H_i}}
    $$
\end{proof}

\section{Независимые события}
\subsection{Основные определения и утверждения}
\begin{definition}[Независимые случайные события]
    \index{независимость!случайных событий!попарная}
    \index{случайные события!независимые!попарно}
    $A$ и $B$ независимы, если вероятность того,
    что они произошли одновременно, равна произведению их вероятностей
    $$P\left(A\cap B\right)
    =P\left(A\right)\cdot P\left(B\right)\Leftrightarrow P\left(A\mid B\right)
    =P\left(A\right)$$
\end{definition}
\begin{definition}
    \index{независимость!случайных событий}
    \index{случайные события!независимые!в совокупности}
    $A_1, \dots, A_n$ независимы в совокупности,
    если для всякого набора $\varepsilon_1, \dots, \varepsilon_n=\pm 1$
    выполняется равенство
    $$\probability{\bigcap_{k=1}^n A_{k}^{\varepsilon_k}}
    =\prod_{k=1}^n \probability{A_{k}^{\varepsilon_k}}$$

    Обозначение: $A^1=A, A^{-1}=\stcomp{A}$
\end{definition}
\begin{affirmation}
    Из того, что случайные величины $A_1, \dots, A_n$ независимы в совокупности,
    следует, что любая непустая подсовокупность этой совокупности
    тоже независима.
\end{affirmation}
\begin{proof}
    Если $n=2$, то доказательство тривиально, так как имеется набор $A_1, A_2$
    и подсовокупность будет содержать лишь один элемент,
    вероятность которого будет равна произведению вероятностей всех элементов,
    то есть его вероятности
    $$\probability{A_1^{\varepsilon_1}}
    =\probability{\bigcap_{k=1}^{1} A_{k}^{\varepsilon_k}}
    =\prod_{k=1}^{1} \probability{A_{k}^{\varepsilon_k}}
    =\probability{A^{\varepsilon_1}}$$

    Займёмся же серьёзными вещами и дальше будем считать, что $n>2$.
    Имеется набор независимых в совокупности случайных событий
    $A_1, \dots, A_n$. Это значит,
    что для всякого набора $\varepsilon_1, \dots, \varepsilon_n=\pm 1$
    выполняется равенство
    $$\probability{\bigcap_{k=1}^n A_{k}^{\varepsilon_k}}
    =\prod_{k=1}^n \probability{A_{k}^{\varepsilon_k}}$$

    Перепишем его в другом виде (отделим $A_n^{\varepsilon_n}$ от кучи)
    $$\probability{\bigcap_{k=1}^{n-1} A_{k}^{\varepsilon_k}
        \cap A_n^{\varepsilon_n}}
    =\prod_{k=1}^{n-1} \probability{A_{k}^{\varepsilon_k}}
        \cdot \probability{A_n^{\varepsilon_n}}$$

    Введём событие $\mathcal{A}^{\varepsilon}$,
    для набора
    $\varepsilon=\left\{\varepsilon_1, \dots, \varepsilon_{n-1}\right\}$,
    состоящее в том,
    что произошли все события
    $A_1^{\varepsilon_1}, \dots, A_{n-1}^{\varepsilon_{n-1}}$

    $$\mathcal{A^{\varepsilon}}=\bigcap_{k=1}^{n-1} A_{k}^{\varepsilon_k}$$

    Тогда вышеупомянутое тождество будет переписано в виде

    $$\probability{\mathcal{A}^{\varepsilon} \cap A_n^{\varepsilon_n}}
    =\prod_{k=1}^{n-1} \probability{A_{k}^{\varepsilon_k}}
        \cdot \probability{A_n^{\varepsilon_n}}$$

    Поделим обе части на вероятность того, что произошло событие $A_n$
    $$\frac{\probability{\mathcal{A}^{\varepsilon}\cap A_n^{\varepsilon_n}}}
        {\probability{A_n^{\varepsilon_n}}}
    =\prod_{k=1}^{n-1} \probability{A_{k}^{\varepsilon_k}}$$

    Слева имеем условную вероятность
    $$\probability{\mathcal{A}^{\varepsilon}\mid A_n^{\varepsilon_n}}
    =\prod_{k=1}^{n-1} \probability{A_{k}^{\varepsilon_k}}$$

    Отметим, что $\varepsilon_n$ не фигурирует справа и может принимать как
    значение $1$, так и $-1$, а это значит, что в левой части может стоять как
    $A_n$, так и его дополнение $\stcomp{A_n}$, а это значит, что условные
    вероятности равны
    \begin{equation}\label{eq:equal_conditional_probabilities}
        \probability{\mathcal{A}^{\varepsilon}\mid A_n^{-\varepsilon_n}}
        =\probability{\mathcal{A}^{\varepsilon}\mid A_n^{\varepsilon_n}}
        =\prod_{k=1}^{n-1} \probability{A_{k}^{\varepsilon_k}}
    \end{equation}

    Чтобы доказать утверждение о том,
    что набор событий $A_1, \dots, A_{n-1}$ является независимым в совокупности,
    нужно показать, что вероятность события $\mathcal{A}^{\varepsilon}$ равна
    произведению вероятностей событий
    $A_1^{\varepsilon_1}, \dots, A_{n-1}^{\varepsilon_{n-1}}$,
    то есть, показать, что событие $\mathcal{A}^{\varepsilon}$
    не зависит от события $A_n^{\varepsilon_n}$
    \begin{equation}\label{eq:main_condition}
        \probability{\mathcal{A}^{\varepsilon}}\stackrel{\rm ?}{=}
        \probability{\mathcal{A}^{\varepsilon}\mid A_n^{\varepsilon_n}}
        =\prod_{k=1}^{n-1} \probability{A_{k}^{\varepsilon_k}}
    \end{equation}

    Воспользуемся формулой полной вероятности для $\mathcal{A}^{\varepsilon}$
    с набором гипотез $A_n^{\varepsilon_n}$ и
    $\stcomp{A_n^{\varepsilon_n}}=A_n^{-\varepsilon_n}$
    $$\probability{\mathcal{A}^{\varepsilon}}
    =\probability{\mathcal{A}^{\varepsilon}\mid A_n^{\varepsilon_n}}
        \cdot\probability{A_n^{\varepsilon_n}}
    +\probability{\mathcal{A}^{\varepsilon}\mid A_n^{-\varepsilon_n}}
        \cdot\probability{A_n^{-\varepsilon_n}}$$

    Используем то, что $\probability{\stcomp{A}}=1-\probability{A}$
    $$\probability{\mathcal{A}^{\varepsilon}}
    =\probability{\mathcal{A}^{\varepsilon}\mid A_n^{\varepsilon_n}}
        \cdot\probability{A_n^{\varepsilon_n}}
    +\probability{\mathcal{A}^{\varepsilon}\mid A_n^{-\varepsilon_n}}
        \cdot\left(1-\probability{A_n^{\varepsilon_n}}\right)$$

    Раскрываем скобки и группируем множители при
    $\probability{A_n^{\varepsilon_n}}$
    \begin{equation}\label{eq:total_probability_result}
    \probability{\mathcal{A}^{\varepsilon}}
    =\probability{A_n^{\varepsilon_n}}\cdot
        \left[
            \probability{\mathcal{A}^{\varepsilon}\mid A_n^{\varepsilon_n}}
            -\probability{\mathcal{A}^{\varepsilon}\mid A_n^{-\varepsilon_n}}
        \right]
    +\probability{\mathcal{A}^{\varepsilon}\mid A_n^{-\varepsilon_n}}
    \end{equation}

    Взглянув на равенство \eqref{eq:equal_conditional_probabilities}, видим,
    что условные вероятности в скобках равенства
    \eqref{eq:total_probability_result} равны,
    а это значит, что их разность равна нулю
    $$\probability{\mathcal{A}^{\varepsilon}\mid A_n^{-\varepsilon_n}}
    =\probability{\mathcal{A}^{\varepsilon}\mid A_n^{\varepsilon_n}}
    \Rightarrow
    \probability{\mathcal{A}^{\varepsilon}\mid A_n^{\varepsilon_n}}
    -\probability{\mathcal{A}^{\varepsilon}\mid A_n^{-\varepsilon_n}}=0
    $$

    Учитывая то, что разность этих вероятностей равна нулю,
    вернёмся к равенству \eqref{eq:total_probability_result}
    \begin{align*}
            \probability{\mathcal{A}^{\varepsilon}}
            &=\probability{A_n^{\varepsilon_n}}\cdot 0
            +\probability{\mathcal{A}^{\varepsilon}\mid A_n^{-\varepsilon_n}}\\
            \probability{\mathcal{A}^{\varepsilon}}
            &=\probability{\mathcal{A}^{\varepsilon}\mid A_n^{-\varepsilon_n}}
    \end{align*}

    Снова воспользуемся равенством \eqref{eq:equal_conditional_probabilities}
    и получаем, что вероятность пересечения
    событий $A_1^{\varepsilon_1}, \dots, A_{n-1}^{\varepsilon_{n-1}}$
    равна произведению вероятностей этих событий, а это значит,
    что выполняется равенство \eqref{eq:main_condition}
    $$\probability{\mathcal{A}^{\varepsilon}}
      =\probability{\mathcal{A}^{\varepsilon}\mid A_n^{-\varepsilon_n}}
      =\probability{\mathcal{A}^{\varepsilon}\mid A_n^{\varepsilon_n}}
      =\prod_{k=1}^{n-1} \probability{A_{k}^{\varepsilon_k}}$$

    Убираем промежуточные значения (условные вероятности),
    переходим к начальным обозначениям и получаем то, что при выбрасывании
    последнего элемента из последовательности $A_1, \dots, A_n$
    остальные события $A_1, \dots, A_{n-1}$
    остаются независимыми в совокупности
    $$\probability{\bigcap_{k=1}^{n-1} A_{k}^{\varepsilon_k}}
    =\prod_{k=1}^{n-1} \probability{A_{k}^{\varepsilon_k}}$$

    Так как пересечение множеств и умножение чисел коммутативно,
    то можем переместить любой элемент $A_k$ в конец последовательности,
    а его вероятность в конец произведения. Тогда задача доказательства того,
    что при выбрасывании произвольного элемента
    из совокупности независимых событий
    всё равно будет независимый в совокупности набор случайных событий,
    сводится к предыдущей задаче, где удаляли последний элемент $A_n$.

    Не ограничиваемся данными рассуждениями.
    Если выкинуть один элемент из набора,
    то получаем независимые в совокупности события,
    а это значит, что, если получившийся набор не пуст,
    то из него опять же можно убрать один элемент
    и опять же получим независимые в совокупности события.
    Таким образом можно получить любую подсовокупность
    исходной независимой совокупности $A_1, \dots, A_n$,
    которая тоже в свою очередь будет независимой.

\end{proof}
\begin{affirmation}
    Если $A_1, \dots, A_n, A_{n+1}, \dots, A_{n+m}$ независимы в совокупности,
    то события
    $B_1=\bigcup_{k=1}^n A_k$ и $B_2=\bigcup_{k=n+1}^{n+m} A_k$ независимы.
\end{affirmation}
\begin{proof}
    Возьмём независимые в совокупности события.
    $$A_1, \dots, A_n, A_{n+1}, \dots, A_{n+m}$$
    
    Введём два события
    \begin{align*}
    B_1&=\bigcup_{k=1}^n A_k\\
    B_2&=\bigcup_{k=n+1}^{n+m} A_k
    \end{align*}

    Нужно доказать, что вероятность пересечения этих событий
    равна произведению их вероятностей
    \begin{equation}\label{eq:main_unions}
    \probability{B_1\cap B_2}
        \stackrel{\rm ?}{=}\probability{B_1}\cdot\probability{B_2}
    \end{equation}

    Применим закон де Моргана
    \begin{equation}\label{eq:de_morgan_result}
    \probability{B_1\cap B_2}
    =\probability{\stcomp{\stcomp{B_1}\cup \stcomp{B_2}}}
    =1-\probability{{\stcomp{B_1}\cup \stcomp{B_2}}}
    \end{equation}

    Имеем вероятность того, что произошло хотя бы одно из событий,
    значит, можно применить формулу включения-исключения
    \begin{equation}\label{eq:incl_excl_result}
    \probability{\stcomp{B_1}\cup \stcomp{B_2}}
    =\probability{\stcomp{B_1}}+\probability{\stcomp{B_2}}
        -\probability{\stcomp{B_1}\cap \stcomp{B_2}}
    \end{equation}

    Воспользовавшись законом де Моргана,
    перепишем события $B_1$ и $B_2$ без объединений
    \begin{align*}
    B_1&=\stcomp{\bigcap_{k=1}^n \stcomp{A_k}}\\
    B_2&=\stcomp{\bigcap_{k=n+1}^{n+m} \stcomp{A_k}}
    \end{align*}

    Поскольку пересечение $\stcomp{B_1}\cap \stcomp{B_2}$
    содержит лишь независимые в совокупности события,
    то его вероятность равна произведению вероятностей этих событий
    (вспомним, что дополнения независимых в совокупностей событий
    тоже независимы в совокупности, что описывается тем случаем, когда
    $\varepsilon_1=\varepsilon_2=\dots=\varepsilon_{n+m}=-1$)
    \begin{align*}
        \probability{\stcomp{B_1}\cap \stcomp{B_2}}
            &=\Probability{
                \left(\bigcap_{k=1}^n \stcomp{A_k}\right)
                \cap
                \left(\bigcap_{k=n+1}^{n+m} \stcomp{A_k}\right)}=\\
            &=\probability{
                \stcomp{A_1}\cap\stcomp{A_2}\cap
                \dots\cap\stcomp{A_n}\cap\stcomp{A_{n+1}}\cap
                \dots\cap\stcomp{A_{n+m}}}=\\
            &=\prod_{k=1}^{n+m}\probability{\stcomp{A_k}}
            =\prod_{k=1}^n \probability{\stcomp{A_k}}
                \cdot\prod_{k=n}^{n+m} \probability{\stcomp{A_k}}\\
    \end{align*}

    Поскольку $\stcomp{A_1}, \dots, \stcomp{A_{n+m}}$
    --- набор независимых случайных событий,
    то любая подсовокупность тоже является независимой.
    Таким образом, выделив два набора $\stcomp{A_1}, \dots, \stcomp{A_{n}}$
    и $\stcomp{A_{n+1}}, \dots, \stcomp{A_{n+m}}$, видим,
    что последние произведения вероятностей этих событий есть ни что иное,
    как вероятности пересечений
    $$\probability{\stcomp{B_1}\cap \stcomp{B_2}}
        =\prod_{k=1}^n \probability{\stcomp{A_k}}
            \cdot\prod_{k=n}^{n+m} \probability{\stcomp{A_k}}
        =\probability{\bigcap_{k=1}^{n} \stcomp{A_k}}
            \cdot\probability{\bigcap_{k=1}^{n} \stcomp{A_k}}$$

    Перейдя от пересечений событий $A_k$ обратно к событиям $B_1$ и $B_2$,
    видим, что дополнения этих событий независимы
    $$\probability{\stcomp{B_1}\cap \stcomp{B_2}}
        =\probability{\stcomp{B_1}}\cdot\probability{\stcomp{B_2}}$$

    Вернёмся к равенству \eqref{eq:incl_excl_result} и перепишем его,
    используя только что полученные знания
    \begin{align*}
    \probability{\stcomp{B_1}\cup \stcomp{B_2}}
    &=\probability{\stcomp{B_1}}+\probability{\stcomp{B_2}}
        -\probability{\stcomp{B_1}\cap \stcomp{B_2}}=\\
    &=\probability{\stcomp{B_1}}+\probability{\stcomp{B_2}}
        -\probability{\stcomp{B_1}}\cdot \probability{\stcomp{B_2}}
    \end{align*}

    А теперь посмотрим, что случится с равенством \eqref{eq:de_morgan_result}
    \begin{align*}
        \probability{B_1\cap B_2}
        &=\probability{\stcomp{\stcomp{B_1}\cup \stcomp{B_2}}}
        =1-\probability{{\stcomp{B_1}\cup \stcomp{B_2}}}=\\
        &=1-\probability{\stcomp{B_1}}-\probability{\stcomp{B_2}}
        +\probability{\stcomp{B_1}}\cdot \probability{\stcomp{B_2}}=\\
        &=\left[1-\probability{\stcomp{B_1}}\right]
            \cdot\left[1-\probability{\stcomp{B_2}}\right]
        =\probability{B_1}\cdot\probability{B_2}
    \end{align*}

    Видим, что равенство \eqref{eq:main_unions} выполняется,
    а это значит, что утверждение доказано
    $$\probability{B_1\cap B_2}=\probability{B_1}\cdot\probability{B_2}$$

\end{proof}
\subsection{Лемма Бореля-Кантелли}
    Подбрасываем монетку бесконечное число раз.
    Какова вероятность того, что решка выпадет бесконечное число раз?

    Если ввести событие $A_n$, которое состоит в том,
    что при $n$-ом подбрасывании монетки выпала решка,
    то дополнение к нему $\stcomp{A_n}$ будет состоять в том,
    что при $n$-ом подбрасывании монетки выпал орёл.

    Очевидно, что последовательность событий $A_1, A_2, \dots, A_n, \dots$
    независима в совокупности, так как монетке всё равно,
    какой стороной она упала на пол в прошлый раз.

    Теперь видим, что событие $A$, которое заключается в том,
    что решка выпадет бесконечное число раз, есть ни что иное как
    верхний предел последовательности событий $A_n$
    $$A=\varlimsup\limits_{n\to\infty}A_n$$

    Попробуем посчитать вероятность того, что этого не произойдёт.
    То есть, вероятность события $\stcomp{A}$.
    Для начала нужно разобраться, что оно из себя представляет
    $$\stcomp{A}=\stcomp{\varlimsup\limits_{n\to\infty}A_n}
        =\varliminf\limits_{n\to\infty}\stcomp{A_n}
        =\bigcup_{n\ge 1}\bigcap_{m\ge n}\stcomp{A_m}$$

    Поскольку мощность объединения множеств не больше, чем сумма их мощностей,
    а вероятность пересечения независимых событий
    равна произведению их вероятностей,
    то имеем мощные предпосылки для подсчёта вероятности.
    Пускай монетка несимметричная и вероятность выпадения решки равна $p:0<p<1$,
    а вероятность выпадения орла равна $q=1-p$
    $$\probability{\stcomp{A}}=\bigcup_{n\ge 1}\bigcap_{m\ge n}\stcomp{A_m}
        \le \sum_{n\ge 1} \prod_{m\ge n}\probability{\stcomp{A_m}}
        =\sum_{n\ge 1}\lim\limits_{m\to\infty}q^{-m}
        =\sum_{n\ge 1} 0=0$$
    
    То есть, не может быть такого, что с какого-то момента
    всегда начнёт выпадать орёл (или же решка).
    Это значит, что при бесконечном подбрасывании монетки
    и орёл, и решка встретятся бесконечно часто,
    что вполне соответствует нашим представлениям о мире и симметричной монетке.
    $$\probability{A}=1-\probability{\stcomp{A}}=1-0=1$$
\begin{lemma}[Бореля-Кантелли]Лемма состоит из двух частей
\begin{enumerate}[label=\alph*]
    \item Имеется набор \textbf{независимых} случайных событий
        $\left\{ A_n\mid n\ge1 \right\}$ (независимые в том смысле, что любая
        конечная подпоследовательность является независимой в совокупности).
        Если ряд, элементами которого являются вероятности этих событий,
        \textbf{расходится}, то произойдёт \textbf{бесконечно много}
        событий из исходной последовательности
        \begin{align*}
        &\begin{cases}
            \prod_{n\in N}\probability{A_n}
            =\probability{\bigcap_{n\in N}A_n},
            (\forall N\subset\mathbb{N}: \left|N\right|<+\infty)\\
            \sum_{n\ge 1}\probability{A_n} = +\infty
        \end{cases}\\
        &\Rightarrow \probability{\varlimsup\limits_{n\to\infty} A_n}=1
        \end{align*}
    \item Имеется \textbf{произвольный} набор случайных событий
        $\left\{ A_n\mid n\ge1 \right\}$.
        Если ряд, элементами которого являются вероятности этих событий,
        \textbf{сходится}, то произойдёт лишь \textbf{конечное число}
        событий из исходной последовательности
        $$\sum_{n\ge 1}\probability{A_n} < +\infty
            \Rightarrow \probability{\varlimsup\limits_{n\to\infty} A_n}=0$$
\end{enumerate}
\end{lemma}
\begin{proof} Доказательство тоже состоит из двух частей
    \begin{enumerate}[label=\alph*]
    \item 
        Имеются $A_1, A_2, \dots, A_n, \dots$ --- независимые случайные события.
        Это значит, что их дополнения $\stcomp{A_1}, \dots, \stcomp{A_n}, \dots$
        тоже независимы между собой
        \begin{align*}
            \forall N\ge n
            \begin{cases}
                \probability{\bigcap_{k=n}^NA_k}
                    =\prod_{k=n}^N\probability{A_k}\\
                \probability{\bigcap_{k=n}^N\stcomp{A_k}}
                    =\prod_{k=n}^N\probability{\stcomp{A_k}}
            \end{cases}
            \Rightarrow
            \begin{cases}
                \probability{\bigcap_{k\ge n}A_k}
                    =\prod_{k\ge n}\probability{A_k}\\
                \probability{\bigcap_{k\ge n}\stcomp{A_k}}
                    =\prod_{k\ge n}\probability{\stcomp{A_k}}
            \end{cases}
        \end{align*}

        Также известно, что ряд, состоящий из вероятностей исходных событий,
        расходится
        $$\sum_{n\ge 1}\probability{A_n}=+\infty$$

        Посмотрим, чему равна вероятность дополнения к верхнему пределу
        $$\probability{\stcomp{\varlimsup_{n\to\infty}A_n}}
            =\probability{\varliminf_{n\to\infty}\stcomp{A_n}}
            =\probability{\bigcup_{n\ge 1}\bigcap_{k\ge n}\stcomp{A_k}}$$

        Мощность объединения не больше, чем сумма мощностей множеств
        \begin{align*}
        \probability{\bigcup_{n\ge 1}\bigcap_{k\ge n}\stcomp{A_k}}
            \le \sum_{n\ge 1}\probability{\bigcap_{k\ge n}\stcomp{A_k}}
            &= \sum_{n\ge 1}\prod_{k\ge n}\probability{\stcomp{A_k}}\\
        \end{align*}

        Зафиксируем полученный результат
        \begin{equation}\label{eq:bc_start_a}
            \probability{\stcomp{\varlimsup_{n\to\infty}A_n}}
            \le \sum_{n\ge 1}\prod_{k\ge n}\probability{\stcomp{A_k}}
        \end{equation}
        
        Прологарифмируем произведение вероятностей дополнений случайных событий
        и воспользуемся неравенством $ln\left(1-x\right)\le -x,0\le x\le 1$
        \cite[стр.~327]{Shiryayev1}
        $$ln\left(\prod_{k\ge n}\probability{\stcomp{A_k}}\right)
            =\sum_{k\ge n}ln\left[\probability{1-A_k}\right]
            \le\sum_{k\ge n}\left[-\probability{A_k}\right]
            =-\sum_{k\ge n}\probability{A_k}$$

        Поскольку ряд вероятностей по условию расходится,
        то любой его остаток $r_n$ тоже расходится
        $$r_n=\sum_{k\ge n}\probability{A_k}=+\infty$$

        Это значит, что логарифм произведений стремится к $-\infty$,
        а само произведение стремится к нулю
        \begin{align*}
            ln\left(\prod_{k\ge n}\probability{\stcomp{A_k}}\right)
                =-\sum_{k\ge n}\probability{A_k}=-\infty
                \Rightarrow\prod_{k\ge n}\probability{\stcomp{A_k}}=0
        \end{align*}

        Следовательно, вероятность, которую искали в  \eqref{eq:bc_start_a},
        равна нулю
        $$\probability{\stcomp{\varlimsup_{n\to\infty}A_n}}
            \le \sum_{n\ge 1}\prod_{k\ge n}\probability{\stcomp{A_k}}
            =\sum_{n\ge 1} 0
            =0$$

        Это в свою очередь означает, что произойдёт бесконечно много событий
        из последовательности
        $$\probability{\varlimsup_{n\to\infty}A_n}
            =1-\probability{\stcomp{\varlimsup_{n\to\infty}A_n}}
            =1-0=1$$

    \item Есть набор случайных событий $\left\{ A_n\mid n\ge1 \right\}$.
        Также известно, что ряд, состоящих из их вероятностей, сходится.
        $$\sum_{n\ge 1}\probability{A_n} < +\infty$$

        Поскольку ряд сходится, то это значит, что его остаток $r_n$
        при достаточно больших $n$ стремится к нулю \cite[стр.~430]{IlinMA1}
        $$\sum_{n\ge 1}\probability{A_n} < +\infty
        \Rightarrow\lim\limits_{n\to\infty}\sum_{k\ge n}\probability{A_k}
            =\lim\limits_{n\to\infty}r_n=0$$

        Мощность пересечения двух множеств не больше,
        чем мощность каждого из них.
        Значит, вероятность верхнего предела не больше,
        чем вероятность какого-либо объединения, которое присутствует в формуле.
        Ничто не мешает выбрать объединение,
        не содержащее сколь угодно много первых событий последовательности
        \cite[стр.~327]{Shiryayev1}
        $$\probability{\varlimsup\limits_{n\to\infty} A_n}
            =\probability{\bigcap_{n\ge 1}\bigcup_{k\ge n} A_k}
            \le\lim\limits_{n\to\infty}\probability{\bigcup_{k\ge n} A_k}$$

        Знаем, что вероятность объединения случайных не больше,
        чем сумма вероятностей случайных событий.
        Тут видим, что пригодилось свойство сходимости ряда и вероятность того,
        что произойдёт бесконечно много событий, не больше нуля
        $$\probability{\varlimsup\limits_{n\to\infty} A_n}
            \le\lim\limits_{n\to\infty}\probability{\bigcup_{k\ge n} A_k}
            \le\lim\limits_{n\to\infty}\sum_{k\ge n}\probability{A_k}=0$$
    \end{enumerate}
\end{proof}
\subsection{Аксиомы теории вероятности}
Для дальнейшей работы нужно как-то систематизировать случайные события,
с которыми будем работать, поскольку неудобно иметь дело со всеми подмножествами
множества элементарных исходов.
\begin{definition}[Алгебра]\index{алгебра}
    Класс $\mathcal{A}$ подмножеств множества элементарных событий $\Omega$
    ($\mathcal{A}\subset2^\Omega$)
    называется алгеброй, если выполняются следующие свойства
    \begin{enumerate}
        \item Если множество принадлежит классу,
            то его дополнение тоже является элементом класса
            $$A\in\mathcal{A}\Rightarrow\stcomp{A}\in\mathcal{A}$$
        \item Множество элементарных исходов принадлежит классу 
            $$\Omega\in\mathcal{A}$$
        \item Класс замкнут относительно операции пересечения
            $$A,B\in\mathcal{A}\Rightarrow A\cap B\in\mathcal{A}$$
    \end{enumerate}
\end{definition}

\begin{remark}Нетрудно заметить,
    что необходимость наличия множества элементарных исходов идентично
    требованию вхождения пустого множества в алгебру. Для этого достаточно
    воспользоваться первым свойством
    $$\stcomp{\emptyset}=\Omega\in\mathcal{A}
            \Leftrightarrow\stcomp{\Omega}=\emptyset\in\mathcal{A}$$
\end{remark}

\begin{remark}Пользуясь тем же свойством и правилом де Моргана, легко показать,
    что из замкнутости относительно пересечений
    следует замкнутость относительно любого конечного числа
    теоретико-множественных операций
    \begin{align*}
        A,B\in\mathcal{A}
        \Leftrightarrow
        \begin{cases}
            \stcomp{A},\stcomp{B}\in\mathcal{A}
            \Leftrightarrow\stcomp{A}\cap\stcomp{B}\in\mathcal{A}
            \Leftrightarrow\stcomp{A\cup B}\in\mathcal{A}
            \Leftrightarrow A\cup B\in\mathcal{A}\\
            A, \stcomp{B}\in\mathcal{A}
            \Leftrightarrow A\cap\stcomp{B}\in\mathcal{A}
            \Leftrightarrow A\setminus B\in\mathcal{A}
        \end{cases}
    \end{align*}
\end{remark}

Введём альтернативное определение алгебры на основе полученных данных
\begin{definition}[Алгебра]\index{алгебра}
    Класс $\mathcal{A}\subset2^\Omega$ называется алгеброй,
    если выполняются следующие свойства
    \begin{enumerate}
        \item Если множество принадлежит классу,
            то его дополнение тоже является элементом класса
            $$A\in\mathcal{A}\Rightarrow\stcomp{A}\in\mathcal{A}$$
        \item Пустое множество принадлежит классу
            $$\emptyset\in\mathcal{A}$$
        \item Класс замкнут относительно операции объединения
            $$A,B\in\mathcal{A}\Rightarrow A\cup B\in\mathcal{A}$$
    \end{enumerate}
\end{definition}

